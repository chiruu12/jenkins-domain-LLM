### **Project Plan: Pivoting to Agentic Architecture**

This document outlines the revised project plan for GSoC'25 project Jenkins Domain specific LLM based on actual Jenkins usage using ci.jenkins.io data. The primary objective is to transition from the static, finetuned LLM prototype to a flexible, universal agentic architecture. This shift prioritizes robustness, user choice, and extensibility, laying the groundwork for a more powerful and maintainable diagnostic tool. Which can be evolved over the time and would help lower the entry level bar for jenkins.

#### **1. Core Architecture**
*   **Multi-Provider LLM Support:** The system will be built to seamlessly integrate with multiple LLM providers not limited to OpenAI such as Anthropicâ€™s Claude and others. This flexibility allows users to choose models based on their specific requirements for performance, cost-efficiency, or data privacy. I also plan to explore mechanisms that allow users to integrate their own self-hosted LLMs such as those powered by vLLM or similar frameworks. This would give users full control over model deployment and they will be able to use there own fine tuned LLMs Also this would keep the fine tuned llm for jenkins open as we can use it with the agent.
![LLM_API.png](LLM_API.png)
*   **Native Tool-Use Requirement:** Any LLM integrated into the system must support native function calling (tool use) as a core capability. This is essential for enabling the agent to carry out autonomous, context-aware tasks and conduct meaningful investigations.

#### **2. Pipeline Refactoring: The `DiagnosisPipeline` Class**

The current `run_diagnosis_pipeline` function will be refactored into a `DiagnosisPipeline` class to better manage state and handle interactions more intelligently.
![Pipeline_workflow.png](Pipeline_workflow.png)
*   **Differentiated Interaction Handling:** The pipeline will distinguish between the initial analysis and subsequent interactions.
    *   **Initial Diagnosis:** The `critic_agent` will be invoked *only* on the first response generated by the primary diagnostic agent. This ensures the initial, most critical analysis is of the highest possible quality.
    *   **Asymmetrical Model Strategy:** We will explore using a powerful, state-of-the-art model (e.g., Gemini 1.5 Pro) for the `critic_agent` and a smaller, faster model for the main agent. This strategy optimizes for both quality and cost-efficiency.
    *   **Follow-up Conversation:** After the initial critiqued report, the user will converse directly with the main agent, bypassing the critic for a faster, more fluid interaction.

##### **2.1. Agent Operating Modes**

To cater to different user needs and expertise levels, the agent will support several operating modes, which can be selected by the user:

*   **Standard Diagnosis Mode:** The default mode. Provides a comprehensive report including a clear root cause, supporting evidence extracted from logs and files, and a detailed, actionable suggested fix.
*   **Quick Summary Mode:** For experienced users who need a fast pointer. The agent will return only a one or two-sentence summary of the most likely root cause, omitting the detailed evidence and solution steps.
*   **Interactive Debugging Mode:** A conversational approach where the agent, instead of providing a full report, asks clarifying questions to narrow down the problem. For example: "I've detected a `compilation error`. Should I first examine the `changelog.xml` for recent code changes or inspect the `pom.xml` for dependency issues?"
*   **Learning Mode:** Aimed at users new to Jenkins. In addition to the fix, the agent explains the underlying concepts of the error (e.g., "What is a `DependencyConflictException` and why does it occur?") and provides links to relevant Jenkins documentation.

#### **3. Tooling Enhancements**

*   **Recursive File System Access:** The `read_file_from_workspace` tool will be upgraded to recursively navigate subdirectories. This is essential for locating test reports and other critical files often nested within folders like `target/reports/`.
*   **MCP-based Build Analysis Tool:** We will develop a new tool which will be used to intract with [MCP plugin](https://github.com/jenkinsci/mcp-server-plugin). with a few more methods .This tool will consolidate data gathering into two primary functions:
    1.  `get_build_artifacts(build_id)`: Fetches relevant files for a given build.
    2.  `get_build_metadata(build_id)`: Retrieves structured metadata (parameters, result, duration, etc.).
*   **Custom Tool Extensibility:** The architecture will allow users to integrate their own MCP-compliant plugins. We will provide documentation and a clear template specifying the schema and instructions the agent needs to effectively use custom tools.

#### **4. Data-Driven Optimization: Log & Token Reduction**

To enhance performance and reduce operational costs, we will implement a data-driven strategy for minimizing log size before it is sent to the LLM.

*   **Analysis:** We will analyze the `ci.jenkins.io` dataset to identify common boilerplate, redundant log sections, and patterns that can be summarized without losing critical diagnostic information.
*   **Experimentation & Validation:** Several reduction techniques will be developed and tested. Their effectiveness will be measured by comparing the diagnostic accuracy of the agent using shortened logs versus full logs. The goal is to find the optimal balance between token reduction and information fidelity.
*   **User Configuration:** The final implementation will provide users with options to control the level of log reduction (e.g., 'Basic', 'Aggressive').

#### **5. Evolving Plan**

This plan outlines the core objectives for the project. It is a living document that will evolve as we make progress, gather data from our experiments, and receive feedback. The primary focus remains on building a robust, flexible, and genuinely useful tool for the Jenkins community.
