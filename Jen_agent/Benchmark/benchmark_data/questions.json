[
  {
    "question_id": "doc_01",
    "source_file": "benchmark_data/source_files/doc_01_php.txt",
    "question": "To improve my build times, I want to enable the results caching features for both CodeSniffer and PHPStan. What are the specific configuration snippets I need to add to my `phpcs.xml` and `phpstan.neon` files, and what is the critical instruction I must follow if I am using multiple CodeSniffer configurations in my pipeline?",
    "ground_truth_context": "Most web applications are changed and adapted quite frequently and quickly.\nTheir environment, for example the size and the behaviour of the user base, are\nconstantly changing. What was sufficient yesterday can be insufficient today.\nEspecially in a web environment it is important to monitor and continuously\nimprove the internal quality not only when developing, but also when\nmaintaining the software.\n\nThis guide provides a basic configuration for testing and reporting for PHP\nprojects with Jenkins.\n\nIn addition to running and reporting tests, you'll get reports on test run\ntimes, test coverage (including visualizations), and static analysis checks,\nincluding trend graphs, and new and fixed issues compared to the master /\nreference branch.\n\nUse the *pipeline step reference* link on the plugin pages for full\ndocumentation and options for Jenkinsfile.\n\n\n== Configuring PHP Tools\n\nThis guide uses Jenkinsfile based pipelines and assumes you already have a\nbasic Jenkinsfile.\n\nThis guide assumes that you already have each of the tools mentioned\nconfigured for use outside of Jenkins. Only the necessary configuration\noptions for working with Jenkins are mentioned.\n\nThis guide uses the `build/` directory for storing generated logs and reports.\n\nIt's assumed that all tools configuration files are in the repository root and\nPHP code is in the `src` subdirectory.\n\n=== PHPUnit Test & Coverage Reports\n\nThe following configuration will set up 3 reports for PHPUnit tests:\n\n* Pass/fail monitoring via the plugin:xunit[xUnit plugin]\n* Coverage stats via the plugin:coverage[Coverage plugin] (using the cobertura parser)\n* HTML coverage report via the plugin:htmlpublisher[HTML Publisher plugin]\n\nIn the PHPUnit config file (`phpunit.xml` or `phpunit.xml.dist`):\n\n[source,xml]\n----\n<phpunit>\n    <coverage>\n        <include>\n            <directory suffix=\".php\">src</directory>\n        </include>\n        <report>\n            <html outputDirectory=\"build/coverage\" />\n            <cobertura outputFile=\"build/logs/cobertura.xml\"/>\n        </report>\n    </coverage>\n    <logging>\n        <junit outputFile=\"build/logs/junit.xml\" />\n    </logging>\n</phpunit>\n----\n\nIn the Jenkinsfile:\n\n[source,groovy]\n----\nstage('Unit Tests') {\n    steps {\n        sh 'vendor/bin/phpunit'\n        xunit([\n            thresholds: [\n                failed ( failureThreshold: \"0\" ),\n                skipped ( unstableThreshold: \"0\" )\n            ],\n            tools: [\n                PHPUnit(pattern: 'build/logs/junit.xml', stopProcessingIfError: true, failIfNotNew: true)\n            ]\n        ])\n        publishHTML([\n            allowMissing: false,\n            alwaysLinkToLastBuild: false,\n            keepAll: false,\n            reportDir: 'build/coverage',\n            reportFiles: 'index.html',\n            reportName: 'Coverage Report (HTML)',\n            reportTitles: ''\n        ])\n        discoverGitReferenceBuild()\n        recordCoverage(tools: [[parser: 'COBERTURA', pattern: 'build/logs/cobertura.xml']])\n    }\n}\n----\n\n=== PHPStan and CodeSniffer Static Analysis Reports\n\nIn this example, PHPCS is shown running with 2 different configurations (mainly\nto show this can be done).\n\nReports are processed using the CheckStyle format report and the\nplugin:warnings-ng[Warnings Next Generation plugin]\n\nThis is done because PHPCompatibility checks are run across the `vendor/`\ndirectory to aid in monitoring potential problems for version updates.\n\nThis example setup shows running the static analysis tools in parallel, which\nmay result in faster build times.\n\nIn Jenkinsfile:\n[source,groovy]\n----\nstages {\n    stage('Static Analysis') {\n        parallel {\n          stage('CodeSniffer') {\n              steps {\n                  sh 'vendor/bin/phpcs --standard=phpcs.xml .'\n              }\n          }\n          stage('PHP Compatibility Checks') {\n              steps {\n                  sh 'vendor/bin/phpcs --standard=phpcs-compatibility.xml .'\n              }\n          }\n          stage('PHPStan') {\n              steps {\n                  sh 'vendor/bin/phpstan analyse --error-format=checkstyle --no-progress -n . > build/logs/phpstan.checkstyle.xml'\n              }\n          }\n        }\n    }\n    post {\n        always {\n            recordIssues([\n                sourceCodeEncoding: 'UTF-8',\n                enabledForFailure: true,\n                aggregatingResults: true,\n                blameDisabled: true,\n                referenceJobName: \"repo-name/master\",\n                tools: [\n                    phpCodeSniffer(id: 'phpcs', name: 'CodeSniffer', pattern: 'build/logs/phpcs.checkstyle.xml', reportEncoding: 'UTF-8'),\n                    phpStan(id: 'phpstan', name: 'PHPStan', pattern: 'build/logs/phpstan.checkstyle.xml', reportEncoding: 'UTF-8'),\n                    phpCodeSniffer(id: 'phpcompat', name: 'PHP Compatibility', pattern: 'build/logs/phpcs-compat.checkstyle.xml', reportEncoding: 'UTF-8')\n                ]\n            ])\n        }\n    }\n}\n----\n\nYou'll want to change the `repo-name` in the `referenceJobName` directive to\nmatch your repository. This tells Jenkins which job to compare the results\nagainst for branches and PR jobs.\n\nSet the report location in CodeSniffers configuration file (`phpcs.xml`):\n[source,xml]\n----\n<ruleset name=\"Default\">\n    <arg name=\"report-checkstyle\" value=\"build/logs/phpcs.checkstyle.xml\" />\n</ruleset>\n----\n\n==== Ignoring tool run failures / tuning failure conditions\nIf you want the build to pass regardless of the results of tools (ie. ignore\nthe exit code), you can append `|| exit 0` to the end of the `sh` command.\n\nAlternatively, for CodeSniffer you can add the following into the configuration\nfile (`phpcs.xml`):\n[source,xml]\n----\n<ruleset name=\"default\">\n    <config name=\"ignore_errors_on_exit\" value=\"1\" />\n    <config name=\"ignore_warnings_on_exit\" value=\"1\" />\n</ruleset>\n----\n\nYou can then fine-tune the failure conditions using the\nlink:/doc/pipeline/steps/warnings-ng/[Warnings-NG pipeline configuration]\n\n==== Results Caching\n\nYou can improve build times (for each run after the first) using caching\nfeatures available in both CodeSniffer and PHPStan.\n\nIn CodeSniffers configuration file (`phpcs.xml`):\n[source,xml]\n----\n<ruleset name=\"default\">\n    <arg name=\"cache\" value=\"build/cache/codesniffer.phpcs\" />\n</ruleset>\n----\n\nIf you have multiple CodeSniffer configurations as in the example Jenkinsfile\nabove, be sure to set different cache paths.\n\nIn PHPStan's configuration file (`phpstan.neon`):\n[source]\n----\nparameters:\n    tmpDir: build/cache/phpstan\n----\n"
  },
  {
    "question_id": "doc_02",
    "source_file": "benchmark_data/source_files/doc_02_2017-06-27-speaker-blog-SAS-jenkins-world.txt",
    "question": "I've created a shared library function in a file named `gbuild.groovy` within the `vars` directory, structured with the `def call(args)` syntax as recommended. To use this in my pipeline, what is the specific line of code required to invoke this function with the arguments 'clean compileJava', and what is the complete annotation I must add beforehand to load the library if it's named 'Utilities2'?",
    "ground_truth_context": "NOTE: This is a guest post by Brent Laster, Senior Manager, Research and Development at\nlink:https://www.sas.com/en_us/home.html[SAS].\n\nlink:/doc/book/pipeline[Jenkins Pipeline]\nhas fundamentally changed how users can orchestrate their pipelines and workflows.\nEssentially, anything that you can do in a script or program can now be done in a `Jenkinsfile` or in a pipeline script created within the application.\nBut just because you can do nearly anything directly in those mechanisms doesn't mean you necessarily should.\n\nIn some cases, it's better to abstract the functionality out separately from your main Pipeline.\nPreviously, the main way to do this in Jenkins itself was through creating plugins.\nWith Jenkins 2 and the tight incorporation of Pipeline, we now have another approach \u2013 shared libraries.\n\n[WARNING]\n--\nBrent will be\nlink:https://jenkinsworld20162017.sched.com/event/ALMq/extending-your-pipeline-with-shared-libraries-global-functions-and-external-code[presenting]\nmore of this topic at link:https://www.cloudbees.com/jenkinsworld/home[Jenkins World] in\nAugust, register with the code `JWFOSS` for a 30% discount off your pass.\n--\n\nlink:/doc/book/pipeline/shared-libraries[Shared libraries]\nprovide solutions for a number of situations that can be challenging or time-consuming to deal with in Pipeline.\nAmong them:\n\n* Providing common routines that can be accessed across a number of pipelines or within a designated scope (more on scope later)\n* Abstracting out complex or restricted code\n* Providing a means to execute scripted code from calls in declarative pipelines (where scripted code is not normally allowed)\n* Simplifying calls in a script to custom code that only differ by calling parameters\n\nTo understand how to use shared libraries in Pipeline, we first need to understand how they are constructed.\nA shared library for Jenkins consists of a source code repository with a structure like the one below:\n\nimage:/images/post-images/2017-06-27/jw-speaker-blog-sas-1.png[role=center]\n\nEach of the top-level directories has its own purpose.\n\nThe *resources* directory can have non-groovy resources that get loaded via the `libraryResource` step.\nThink of this as a place to store supporting data files such as json files.\n\nThe *src* directory uses a structure similar to the standard Java `src` layout.\nThis area is added to the `classpath` when a Pipeline that includes this shared library is executed.\n\nThe *vars* directory holds global variables that should be accessible from pipeline scripts.\nA corresponding `.txt` file can be included that defines documentation for objects here.\nIf found, this will be pulled in as part of the documentation in the Jenkins application.\n\nAlthough you might think that it would always be best to define library functions in the src structure, it actually works better in many cases to define them in the vars area.\nThe notion of a global variable may not correspond very well to a global function, but you can think of it as the function being a global value that can be pulled in and used in your pipeline.\nIn fact, to work in a declarative style pipeline, having your function in the vars area is the only option.\n\nLet's look at a simple function that we can create for a shared library.\nIn this case, we'll just wrap picking up the location of the Gradle installation from Jenkins and calling the corresponding executable with whatever tasks are passed in as arguments.\nThe code is below:\n\n./vars/gbuild.groovy\n[source, groovy]\n----\ndef call(args) {\n      sh \"${tool 'gradle3'}/bin/gradle ${args}\"\n}\n----\n\nNotice that we are using a structured form here with the def call syntax.\nThis allows us to simply invoke the routine in our pipeline (assuming we have loaded the shared library) based on the name of the file in the vars area.\nFor example, since we named this file *gbuild.groovy*, then we can invoke it in our pipeline via a step like this:\n\n[source, groovy]\n----\ngbuild 'clean compileJava'\n----\n\nSo, how do we get our shared library loaded to use in our pipeline?\nThe shared library itself is just code in the structure outlined above committed/pushed into a source code repository that Jenkins can access.\nIn our example, we'll assume we've staged, committed, and pushed this code into a local Git repository on the system at `/opt/git/shared-library.git`.\n\nLike most other things in Jenkins, we need to first tell Jenkins where this shared library can be found and how to reference it \"globally\" so that pipelines can reference it specifically.\n\nFirst, though, we need to decide at what scope you want this shared library to be available.\nThe most common case is making it a \"global shared library\" so that all Pipelines can access it.\nHowever, we also have the option of only making shared libraries available for projects in a particular Jenkins *Folder* structure,\nor those in a *Multibranch Pipeline*, or those in a *GitHub Organization* pipeline project.\n\nTo keep it simple, we'll just define ours to be globally available to all pipelines.\nDoing this is a two-step process.\nWe first tell Jenkins what we want to call the library and define some default behavior for Jenkins related to the library,\nsuch as whether we wanted it loaded implicitly for all pipelines.\nThis is done in the *Global Pipeline Libraries* section of the *Configure System* page.\n\nimage:/images/post-images/2017-06-27/jw-speaker-blog-sas-2.png[role=center, width=800]\n\nFor the second part, we need to tell Jenkins where the actual source repository for the shared library is located.\nSCM plugins that have been modified to understand how to work with shared libraries are called \"*Modern SCM*\".\nThe git plugin in one of these updated plugin, so we just supply the information in the same *Configure System* page.\n\nimage:/images/post-images/2017-06-27/jw-speaker-blog-sas-3.png[role=center]\n\nAfter configuring Jenkins so that it can find the shared library repository, we can load the shared library into our pipeline using the `@Library('<library name>')` annotation.\nSince link:https://docs.oracle.com/javase/1.5.0/docs/guide/language/annotations.html[Annotations]\nare designed to annotate something that follows them,\nwe need to either include a specific import statement, or, if we want to include everything, we can use an underscore character as a placeholder.\nSo our basic step to load the library in a pipeline would be:\n\n[source, groovy]\n----\n@Library('Utilities2') _\n----\n\nBased on this step, when Jenkins runs our Pipeline, it will first go out to the repository that holds the shared library and clone down a copy to use.\nThe log output during this part of the pipeline execution would look something like this:\n\n[source]\n----\nLoading library Utilities2@master\n > git rev-parse --is-inside-work-tree # timeout=10\nSetting origin to /opt/git/shared-libraries\n > git config remote.origin.url /opt/git/shared-libraries # timeout=10\nFetching origin...\nFetching upstream changes from origin\n > git --version # timeout=10\nusing GIT_SSH to set credentials Jenkins2 SSH\n > git fetch --tags --progress origin +refs/heads/*:refs/remotes/origin/*\n > git rev-parse master^{commit} # timeout=10\n > git rev-parse origin/master^{commit} # timeout=10\nCloning the remote Git repository\nCloning repository /opt/git/shared-libraries\n----\n\nThen Pipeline can call our shared library `gbuild` function and translate it to the desired Gradle build commands.\n\n[source]\n----\nFirst time build.\nSkipping changelog.\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] stage\n[Pipeline] { (Compile)\n[Pipeline] tool\n[Pipeline] sh\n[gsummit17_lab2-4T357CUTJORMC2TIF7WW5LMRR37F7PM2QRUHXUNSRTWTTRHB3XGA]\nRunning shell script\n+ /usr/share/gradle/bin/gradle clean compileJava -x test\nStarting a Gradle Daemon (subsequent builds will be faster)\n----\n\nThis is a very basic illustration of how using shared libraries work.\nThere is much more detail and functionality surrounding shared libraries, and extending your pipeline in general, than we can cover here.\n\nBe sure to catch my talk on\nlink:https://jenkinsworld20162017.sched.com/event/ALMq/extending-your-pipeline-with-shared-libraries-global-functions-and-external-code[Extending your Pipeline with Shared Libraries, Global Functions and External Code]\nat link:https://www.cloudbees.com/jenkinsworld[Jenkins World 2017].\nAlso, watch for my new book on\nlink:https://www.amazon.com/Jenkins-Deployment-Pipeline-Generation-Automation/dp/1491979593/ref=sr_1_2?ie=UTF8&qid=1497984947&sr=8-2&keywords=Brent+laster[Jenkins 2 Up and Running]\nwhich will have a dedicated chapter on this \u2013 expected to be available later this year from O'Reilly.\n"
  },
  {
    "question_id": "doc_03",
    "source_file": "benchmark_data/source_files/doc_03_git-credentials-binding.txt",
    "question": "I am using the `gitSshPrivateKey` binding in my Jenkins pipeline and need to ensure it works across different build agents which may have different versions of command-line git installed. How does the binding's method for handling SSH authentication differ for git versions 2.3 and newer compared to versions older than 2.3, and what specific environment variables are used in each case?",
    "ground_truth_context": "=== Abstract\n\nAllow Jenkins Pipeline users to run authenticated git commands in sh, bat, and powershell.\n\nThis project idea proposes to implement two new credential bindings that contribute files and environment variables to sh, bat, and powershell steps so that they can use command line git to perform authenticated operations.\nThe Jira issue requesting support for authenticated git operations (JENKINS-28335) is one of the top five most highly voted Jenkins enhancement requests.\n\nThe two credential bindings will be `gitSshPrivateKey` and `gitUsernamePassword`.\nThey will be implemented in the git plugin with automated tests to confirm the bindings are behaving as expected on the wide range of command line git versions and operating systems supported by the git plugin.\n\n=== Rationale\n\nThe Jenkins git plugin uses Jenkins credentials to fetch a repository and checkout a branch for freestyle, pipeline, and multibranch pipeline jobs.\nIt is also able to use Jenkins credentials to push tags and commits back to the repository from a freestyle job.\nIt supports a wide range of command line git versions, from git 1.8.3 (CentOS 7) through the current release of command line git (2.30.0, Debian testing, Windows, ...).\nIt supports ssh private keys with and without passphrases for ssh protocol authentication and supports usernames and passwords or API tokens for https protocol authentication.\n\nThe git plugin is not able to push tags or commits from a pipeline job or a multibranch pipeline job.\nIt is not able to perform other git operations that require authentication like remote branch creation or deletion.\nThe git plugin also does not provide authenticated access to all the command line options offered with the most recent versions of command line git.\nFor example, there is no support in the git plugin for the `--single-branch` option or for the `--recurse-submodules` option.\n\nWith the git credentials binding, Pipeline users will be able to push merge results, commits, and tags from a Pipeline job.\nThey will be able to create and delete remote branches.\nThey will be able to use the git command line options of their choice, including `--single-branch` and `--recurse-submodules`.\nUsers will be able to run authenticated git commands in their Jenkins Pipelines without modifying the git plugin.\n\n=== Implementation\nBoth `gitUsernamePassword` and `gitSshPrivateKey` bindings depend on the https://plugins.jenkins.io/credentials/[Credential Plugin]\nto retrieve user's credential using the Credentials API.\n\nThe https://plugins.jenkins.io/credentials-binding/[Credentials Binding Plugin] is used\nto bind Git specific environment variables with script(sh,bat,powershell) / terminal commands depending upon the current CLI-git version installed on\nsystem which is being used to perform git operation that requires authentication.\n\nThe bindings only provide authentication support for the command line git implementation.\nOther Git implementations inside the git client plugin such as `JGit` and `JGit with Apache HTTP Client` are not supported.\nUsers are provided with a dropbox which lists all the Git-Tool implementation of\nCLI-Git configured in Jenkins `Global System Configuration`.\n\nBoth the bindings works on behalf of the user to provide git authentication support, without complicated steps to pass the credentials to command line git.\n\nNOTE:: If no CLI-Git implemented Git-Tool is available in `Global System Configuration` then by default JGit\nimplemented Git-Tool will be used.\n\n==== Git Username and Password Binding\n\nThe `gitUsernamePassword` implementation uses the Jenkins username and password\nvalues retrieved through Credential API, to access a remote repository  over *HTTP* protocol.\nThe binding uses the `GIT_ASKPASS` environment variable to provide credentials requested by a git operation in a pipeline job/freestyle project.\nExecutable script(sh,bat,powershell) is attached/bound to the `GIT_ASKPASS` variable, which is invoked when asked for the user\u2019s credentials by HTTP server.\n\nPipeline Job:: Using Git Username and Password Binding in a Pipeline Job\n\nimage::/images/gsoc/2021/git-credentials/usernamepassword-binding-pipeline-job.png[Git Username and Password in Pipeline Job]\n\nFreeStyle Project:: Using Git Username and Password Binding in a FreeStyle-Project\n\nimage::/images/gsoc/2021/git-credentials/usernamepassword-binding-freestyle-project.png[Git Username and Password in FreeStyle Project]\n\nIMPORTANT: Two variable bindings `GIT_USERNAME` and `GIT_PASSWORD` provide the username and password respectively.\nThese variable bindings are also accessible when using `JGit/JGit with Apache HTTP Client` Git-Tool\nimplementations in both freestyle project and pipeline job.\n\n==== Git SSH Private Key Binding\n\nThe `gitSshPrivateKey` implementation provides git authentication support over *SSH* protocol\nusing private key and passphrase credentials of a user. The binding uses two git specific environment\nvariables depending upon the minimum CLI-git version\n\n** `GIT_SSH_COMMAND` - If version is greater than or equal to 2.3, then the GIT_SSH_COMMAND environment variable provides the ssh command including\nnecessary options which are: path to the private key and host key checking, to authenticate and connect to the git server without using an executable script.\n\n** `SSH_ASKPASS` - If version is less than 2.3, an executable script is attached to the variable which provides the\nssh command including necessary options which are: path to the private key and host key checking, to authenticate and connect to the git server\n\nSupport for private key formats\n\n** The following key formats are supported through Jenkins plugins\n\n* `BouncyCastle API Plugin` - Supports decryption of PKCS#8 PEM encoded and PEM private keys.\n* `SSHD Plugin` - Provides a transitive dependency i.e. Apache SSHD-Core v2.7.0, which supports decryption of\nOpenSSH/RFC4716 formatted private keys.\n\nSupport for encryption algorithms\n\n* The following encryption algorithms are supported in various formats discussed above\n\n** RSA\n** DSA\n** ECDSA\n** ED25519\n\n===== Decryption of private keys\n\nThe passphrase protected private key needs to be decrypted before it can be used to perform the\ngit authentication operation over *SSH* protocol, if not decrypted then a prompt is displayed to\nthe user asking for the passphrase of the private key being used in the current job/project, which is not an expected behaviour since\nthe passphrase is already provided by the user through Jenkins https://plugins.jenkins.io/credentials/[Credential Plugin].\n\nTo tackle this issue, the BouncyCastle API plugin and SSHD plugin are used to provide decryption support\nfor the various private formats mentioned above.\n\nPipeline Job:: Using Git SSH Private Key in a Pipeline Job\n\nimage::/images/gsoc/2021/git-credentials/ssh-private-key-pipeline-job.png[Git SSH Private Key in Pipeline Job]\n\nFreeStyle Project:: Using Git SSH Private Key Binding in a FreeStyle-Project\n\nimage::/images/gsoc/2021/git-credentials/ssh-private-key-freestyle-job.png[Git SSH Private Key in FreeStyle Project]\n\nNOTE:: Unlike GitUsernamePassword binding, no variable bindings are supported by gitSshPrivateKey binding.\n\n=== Office hours\n\nThe Office hours are scheduled twice a week each Wednesday and Friday at 2:00 UTC, with regular https://docs.google.com/document/d/1gZneYIDWrT5S-1ACG641wfvxs7vnDC0RCYqy-EuuhwY/edit?usp=sharing[meeting notes] available for anyone to read.\n\n=== Links\n\n* link:https://groups.google.com/g/jenkinsci-gsoc-all-public/c/VdUhhM1Noxc/m/Zk4yajsFAwAJ[Jenkins GSoC mailing list discussion of git credentials pipeline task]\n* link:https://issues.jenkins.io/browse/JENKINS-28335[JENKINS-28335] - Pipeline step to run Git commands with credentials & tool\n* link:https://issues.jenkins.io/browse/JENKINS-47733[JENKINS-47733] - Add a `withGit` pipeline step that provides git credentials\n* link:https://issues.jenkins.io/browse/JENKINS-36496[JENKINS-36496] - Support git publisher with Pipeline\n"
  },
  {
    "question_id": "doc_04",
    "source_file": "benchmark_data/source_files/doc_04_2022-10-10-plugin-health-scoring-system-report.txt",
    "question": "During Phase 2 of the plugin health scoring project, what two key processes were configured to run on a schedule, and what was the primary advantage of implementing this scheduling?",
    "ground_truth_context": "image::/images/gsoc/2022/plugin-health-score/introducing-the-plugin-health-scoring-system.png[GSoC, height=400, role=center, float=center]\n\nThe goal of this blog is to showcase the work done during the Google Summer of Code 2022 coding phases.\nFor a detailed description of the project, please see the link:/projects/gsoc/2022/projects/plugin-health-scoring-system/[project page].\n\n---\n\n== Overview\n\n. <<About Project>>\n. <<Phase 1>>\n. <<Phase 2>>\n. <<Next Steps>>\n. <<Acknowledgments>>\n. <<Useful Links>>\n\n---\n\n== About Project\n\nPlugin maintenance is an extremely important phase of a plugin's lifecycle.\nJenkins is constantly developing, which raises the need for thousands of plugins to catch up with the latest developments. \nThis allows them to stay useful for a broader set of users.\n\nWe aim to fulfill this need, by introducing a metric system to calculate the health score of Jenkins plugins. \nThis health score measures the plugin's development maturity level with the help of accurate numeric figures. \nThis score attempts to provide an accurate picture of how much care and help a plugin needs, and makes it easier for contributors to contribute.\nThis score also allows users to make a conscious decision before installing or using a plugin.\n\nThere were two coding phases in the GSoC 2022:\n\n---\n\n== Phase 1\n\nIn this phase, we worked on setting up the project and followed best practices while doing so.\nThe whole application is dockerized so that it is easier for anyone to spin up this project and test it out locally.\nThere's continuous integration (CI) in place for the project to make sure that new changes are tested automatically.\nThe useful details from the Jenkins Update Center are stored inside the database to run analysis without constantly polling the Update Center.\n\n=== Deliverables\n\n* Create a spring boot project connected with a PostgreSQL DB (link:https://github.com/jenkins-infra/plugin-health-scoring/pull/3[PR])\n* Dockerize the whole application (link:https://github.com/jenkins-infra/plugin-health-scoring/pull/7[PR])\n* Setup continuous integration for the project (link:https://github.com/jenkins-infra/plugin-health-scoring/pull/10[PR])\n* Store plugin details from the update center, inside the DB in JSON format (link:https://github.com/jenkins-infra/plugin-health-scoring/pull/18[PR])\n\n=== Resources\n\n* link:https://github.com/jenkins-infra/plugin-health-scoring/milestone/1?closed=1[View Milestone 1]\n* Jenkins Online Meetup Phase 1: link:https://docs.google.com/presentation/d/1t2vuNn1NFpDusnw0m4vdFw6WBQMeU6kccv_K1v2L6R0/edit#slide=id.g13dcaed2105_0_0[Slides]\n* Jenkins Online Meetup Phase 1: Demo and Presentation\n\nvideo::loLSNdCv6K4[youtube,width=800,height=420,start=1089]\n\n---\n\n== Phase 2\n\nIn this phase, the probe engine for the probes was designed.\nProcesses like reading the update center and executing the probe engine are now running on a schedule, without the need to restart the application.\nProbes created at this time are getting run by the probe engine, and are listed on the UI to highlight the current state of the project.\nThanks to the helm chart that has been created to allow an easy deployment on Kubernetes, the site link:https://plugin-health.jenkins.io[plugin-health.jenkins.io] is live.\n\n=== Deliverables\n\n* Design the Probe engine for the probes (link:https://github.com/jenkins-infra/plugin-health-scoring/pull/19[PR])\n* Schedule the reading of the update center and probe engine execution (link:https://github.com/jenkins-infra/plugin-health-scoring/pull/20[PR#1] and link:https://github.com/jenkins-infra/plugin-health-scoring/pull/30[PR#2])\n* List the available probes of the application (link:https://github.com/jenkins-infra/plugin-health-scoring/pull/27[PR])\n* Add a probe (link:https://github.com/jenkins-infra/plugin-health-scoring/pull/33[PR])\n* Create a Helm chart to deploy the application on Kubernetes (link:https://github.com/jenkins-infra/helm-charts/pull/212[PR])\n* Visit link:https://plugin-health.jenkins.io[plugin-health.jenkins.io] to view a list of active probes. A big thanks to the Jenkins Infrastructure team (especially link:/blog/authors/hlemeur[Herv\u00e9 Le Meur] and link:/blog/authors/dduportal[Damien Duportal]) for their help and support throughout.\n\n=== Resources\n\n* link:https://github.com/jenkins-infra/plugin-health-scoring/milestone/2?closed=1[View Milestone 2]\n* Jenkins Online Meetup Phase 2: link:https://docs.google.com/presentation/d/1HOHRVFOfH07TnBfbGh3xAqakA3NfmKni_7FYyCx-llw/edit#slide=id.p[Slides]\n* Jenkins Online Meetup Phase 2: Demo and Presentation\n\nvideo::fM2SMbppRxw[youtube,width=800,height=420,start=342]\n\n---\n\n== Next Steps\n\n- Add more probes to the project.\n- Generate the plugin health scores based on the data extracted by the probes.\n- Deploy the health scores via a JSON file, similar to how Jenkins Update Center does it.\n- Render the detailed report of the health score of each plugin by fetching the JSON data generated above.\n- [Stretch Goal] Display Plugin health score on Plugin Manager.\n\n---\n\n== Acknowledgments\n\n* I'm extremely grateful to have been given this opportunity to contribute to the Jenkins project. I owe it to my mentors for being able to help take this project forward and learn lots of things along the way. Shoutout to link:/blog/authors/alecharp[Adrien Lecharpentier] and link:/blog/authors/jleon/[Jake Leon]. They invested tremendous time and energy in mentoring me and driving this project forward. They synced with me weekly and made sure that I was learning and that we were taking this project forward, 1 PR at a time.\n\n* I asked all kinds of questions about this project, and Jake has been kind enough to answer all of them and help me understand this project and its future with his expertise. And a BIG shoutout to him for devoting his time to helping me prepare for my presentations by offering many tips on making effective slides and speaking well. His coaching helped me put across my points more powerfully, and made it all so easy.\n\n* I also want to thank Adrien for being one of the best mentors I've ever had. The amount of time he spent moving this project forward and sharing his expertise with me is unparalleled. And for that, I'm deeply grateful to be mentored by him. It's an absolute privilege to get this opportunity to learn from him.\n\n* Also, thanks to the org admins, link:/blog/authors/jmmeessen[Jean-Marc Meessen], link:/blog/authors/alyssat[Alyssa Tong], and link:/blog/authors/krisstern/[Kris Stern], for always keeping me and other contributors on our toes and assisting us with any blockers and concerns by organizing weekly stand-up calls.\n\n---\n\n== Useful Links\n\n- link:https://plugin-health.jenkins.io[plugin-health.jenkins.io]\n- link:https://github.com/jenkins-infra/plugin-health-scoring[GitHub repository]\n- link:https://docs.google.com/document/d/1Dxyli1LPlHdFxLoE9zFtr_3bTjnwQDMZGCxcGS79Z_I/edit[Architecture Diagram]\n- link:https://docs.google.com/document/d/1HTbcWh5C1KrCgEzgqeVEPyfr1H5fH5eTj8KpbWrWsSY/edit#heading=h.efprktbggbop[GSoC Proposal Document]\n- Use the link:https://app.gitter.im/#/room/#jenkinsci_GSoC-Plugin_Health_Score:gitter.im[Gitter channel] or link:https://community.jenkins.io[community.jenkins.io] in case you have any question(s) or feedback.\n\n---\n"
  },
  {
    "question_id": "doc_05",
    "source_file": "benchmark_data/source_files/doc_05_2016-08-31-scaling-jenkins-at-jenkins-world.txt",
    "question": "I want to build a continuous delivery system for my microservices using Jenkins and Kubernetes. Based on the provided text, which session would demonstrate how to implement the end-to-end pipeline, and which other session would provide a comparative analysis of Kubernetes against other container cluster technologies like Docker Swarm and Mesos?",
    "ground_truth_context": "[NOTE]\n--\nThis is a guest post by link:https://github.com/rtyler[R. Tyler Croy], who is a\nlong-time contributor to Jenkins and the primary contact for Jenkins project\ninfrastructure. He is also a Jenkins Evangelist at\nlink:https://cloudbees.com[CloudBees, Inc.]\n--\n\nimage:/images/conferences/Jenkins-World_125x125.png[Jenkins World, role=right]\n\n\nI find the topic of \"scaling Jenkins\" to be incredibly interesting because,\nmore often than not, scaling Jenkins isn't just about scaling a single instance\nbut rather scaling an _organization_ and its continuous delivery processes. In\nmany cases when people talk about \"scaling Jenkins\" they're talking about\n\"Jenkins as a Service\" or \"Continuous Delivery as a Service\" which introduces a\nmuch broader scope, and also more organization-specific requirements, to the\nproblem.\n\nOne of my favorite parts of a big conference like\nlink:https://www.cloudbees.com/jenkinsworld/home[Jenkins World] is getting to\nsee how other people are solving similar problems at different organizations,\nin essence:\n\"link:https://english.stackexchange.com/questions/120739/a-peek-into-the-sausage-factory[how\nthe sausage is made].\" This year's Jenkins World will be no different, with a number\nof sessions by developers and engineers from the companies leading the way,\nscaling continuous delivery and Jenkins.\n\n\n[CAUTION]\n--\nRegister for link:https://www.cloudbees.com/jenkinsworld/home[Jenkins World] in\nSeptember with the code `JWFOSS` for a 20% discount off your pass.\n--\n\nIn the realm of \"scaling Jenkins\" the following sessions stand-out to me as\n\"must-attend\" for those interested in the space:\n\n\nlink:https://www.cloudbees.com/jenkinsops-initiative-streamline-and-automate-jenkins[*JenkinsOps:\nAn Initiative to Streamline and Automate Jenkins*]\n\n_September 14th 4:15 PM - 5:00 PM, Exhibit Hall A-1_\n\n[quote, Paul Miles and Grant Dickie of NPR]\n--\nimage:/images/post-images/scaling-jenkins-at-jenkinsworld/159px-National_Public_Radio_logo.svg.png[role=right]\nNPR\u2019s Digital Media team uses Jenkins to build, test and deploy code to various\nstaging and production environments. As the complexity of the software\ncomponents, environments and tests have grown - both generally and due to our\nquest to achieve continuous deployment - management of Jenkins has become a\nchallenge. In this talk, we share information about our \u201cJenkinsOps\u201d effort\nwhich has allowed us to automate many of the administrative tasks necessary to\nmanage feature code branches, handle deployments, run tests and configure our\nenvironments properly.\n--\n\n\nlink:https://www.cloudbees.com/thinking-inside-container-continuous-delivery-story[*Thinking\nInside the Container: A Continuous Delivery Story]*\n\n_September 15th 1:30 PM - 2:15 PM, Exhibit Hall C_\n\n[quote, Maxfield F Stewart of Riot Games]\n--\nimage:/images/post-images/scaling-jenkins-at-jenkinsworld/Riot_Games_logo.png[role=left]\nAt Riot Games, we build a lot of software. Come learn how we built an\nintegrated Docker solution using Jenkins that accepts Docker images submitted\nas build environments by engineers around the company. Our containerized farm\nnow creates over 10,000 containers per week and handles nearly 1,000 jobs at a\nrate of about 100 jobs per hour. All this is done with readily available, open\nsource Jenkins plugins. We\u2019ll explore lessons learned, best practices and how\nto scale and build your own system, as well as why we chose to solve the\nproblem this way\u2026and whether or not we succeeded!\n--\n\n\nlink:https://www.cloudbees.com/how-do-continuous-delivery-jenkins-pipeline-docker-and-kubernetes[*How\nto Do Continuous Delivery with Jenkins Pipeline, Docker and Kubernetes*]\n\n_September 15th 2:30 PM - 3:15 PM, Great America J_\n\n[quote, James Strachan of Red Hat]\n--\nimage:/images/post-images/pipeline-at-jenkinsworld/redhat.png[role=right]\nIn this talk, we\u2019ll show how to use Jenkins Pipeline together with Docker and\nKubernetes to implement a complete end-to-end continuous delivery and\ncontinuous improvement system for microservices and monolithic applications\nusing open source software. We\u2019ll demonstrate how to easily create new\nmicroservices projects or import existing projects, have them automatically\nbuilt, system and integration tested, staged and then deployed. Once deployed,\nwe will also see how to manage and update applications using continuous\ndelivery practices along with integrated ChatOps - all completely automated!\n--\n\n\n\n\nlink:https://www.cloudbees.com/scaling-jenkins-docker-swarm-kubernetes-or-mesos[*Scaling\nJenkins with Docker: Swarm, Kubernetes or Mesos?*]\n\n_September 15th 2:30 PM - 3:15 PM, Exhibit Hall C_\n\n[quote, Carlos Sanchez of CloudBees]\n--\nimage:/images/post-images/scaling-jenkins-at-jenkinsworld/320px-CloudBees_official_logo.png[role=right]\nThe Jenkins platform can be dynamically scaled by using several Docker cluster\nand orchestration platforms, using containers to run agents and jobs and also\nisolating job execution. But which cluster technology should be used? Docker\nSwarm? Apache Mesos? Kubernetes? How do they compare? All of them can be used\nto dynamically run jobs inside containers. This talk will cover these main\ncontainer clusters, outlining the pros and cons of each, the current state of\nthe art of the technologies and Jenkins support. I believe people will be very\ninterested in learning about the multiple options available.\n--\n\nlink:https://www.cloudbees.com/so-you-want-build-worlds-biggest-jenkins-cluster[*So,\nYou Want to Build the World's Biggest Jenkins Cluster?*]\n\n_September 15th 3:45 PM - 4:30 PM, Exhibit Hall C_\n\n[quote, Stephen Connolly of CloudBees]\n--\nHow can we do it? We start with some real world results realized by Jenkins\nusers who have built large clusters and review how they got there. Next, we\nwill do experiments scaling some individual sub-components of Jenkins in\nisolation and see what challenges we will face when integrated. The famous\nlarge, distributed systems undoubtedly faced problems scaling - and we can\nlearn from them, too. The result will be recipes for building Jenkins\nclusters with different scaling capabilities. After all of this, you can\nbuild the biggest Jenkins cluster in the world\u2026or maybe just make your own\nJenkins cluster more efficient.\n--\n\n\n\nlink:https://www.cloudbees.com/jenkins-splunk-and-splunking-jenkins[*Jenkins at\nSplunk and Splunking Jenkins*]\n\n_September 15th 3:45 PM - 4:30 PM, Exhibit Hall A-1_\n\n[quote, Bill Houston of Splunk]\n--\nimage:/images/post-images/scaling-jenkins-at-jenkinsworld/splunk-logo-300x100.gif[role=right]\nThis session will highlight how Splunk uses Jenkins to provide an end-to-end\nsolution in the development CI system. Attendees will see how test results are\ndelivered to a Splunk indexer, where they can be analyzed and presented in a\nvariety of ways. This session will also include a live demonstration.\n--\n\n\nlink:https://www.cloudbees.com/jenkins-inside-google[*Jenkins inside Google*]\n\n_September 15th 4:45 PM - 5:30 PM, Exhibit Hall C_\n\n[quote, David Hoover of Google]\n--\nimage:/images/post-images/scaling-jenkins-at-jenkinsworld/272px-Google_2015_logo.svg.png[role=right]\nLast year, we presented our initial investigations and stress testing as we\nprepared to deploy a large-scale Jenkins installation at Google. Now, with a\nyear of real-world use under our belts, we\u2019ll discuss how our expectations held\nup, what new issues we encountered and how we have addressed them.\n--\n\n\nIn addition to these, we will also be hosting a\nlink:https://www.meetup.com/jenkinsmeetup/events/232811529/[Jenkins World\nContributor Summit] where \"scaling\" relevant topics such as \"Storage\nPluggability\" will be discussed.\n\n\nThe Jenkins World link:https://www.cloudbees.com/juc/agenda[agenda] is packed\nwith even more sessions, so it should be a very informational event for\neverybody; hope to see you there!\n"
  },
  {
    "question_id": "doc_06",
    "source_file": "benchmark_data/source_files/doc_06_2023-05-02-android-and-jenkins-releases.txt",
    "question": "I am trying to automate my release process and want to reuse the release notes generated by the `gh` tool for my Google Play Store submission. According to the document, what is the specific shell command pipeline used to generate and format the `internal.txt` release notes file, and what is the final character limit that this process enforces on the content?",
    "ground_truth_context": "The link:/blog/2023/04/07/android-and-jenkins-discovery/[previous blog post] of this series discusses what I think makes CI/CD for mobile app development a unique kind of animal, and my first steps in building Android apps with Jenkins.\nWe were left with a working declarative pipeline per branch, one Docker image per branch too, and an application binary ready to be deployed.\nReady?\n\n== Release management\n\nI was able to find the binaries in the workspace in a matter of seconds, but there is no release available, only binaries.\nThis means there are some manual steps required to create a versioned release that we can deliver to test users, for example.\n\nWe can manually create a release within GitHub and then copy-paste the binaries from Jenkins' artifact archives to the GitHub release page.\nWe can also do the same for the Google Play Store.\nHowever, this approach is neither efficient nor error-proof.\n\nIn regards to having a release on the Github repository at the same time as on Google Play, it really depends on the app and its audience.\nFor the purposes of this article, let's assume it's okay.\n\n=== Prerequisites\n\nTo automate the release process, we need to determine the criteria for a version number, how to update the version number, and what constitutes a release.\nWe can use the \"link:https://github.com/dipien/semantic-version-gradle-plugin[Semantic Version]\" Gradle plugin, which has a strict set of rules to guide us.\nThis plugin allows us to link:https://github.com/dipien/semantic-version-gradle-plugin#incrementing-the-project-version[increment] the patch, minor, or major version using Gradle commands.\nWe can also use link:https://github.com/dipien/semantic-version-gradle-plugin#version-classifier[classifiers] such as snapshot, beta, alpha, or any other version classifier to define a version name.\n\n[source,groovy]\n----\nversion = \"1.1.11\"\n\napply plugin: \"com.dipien.android.semantic-version\"\n----\n\nI then searched for a Jenkins plugin that would create a GitHub release.\nAs the saying goes,\n\n[quote]\nThere's a plugin for that\n\nbut unfortunately, I couldn't find one that meets my needs.\nWhile there is a plugin called link:https://plugins.jenkins.io/git-changelog/[Git Changelog] that can merge commit messages to produce a readable version of the changes, it doesn't create the release.\n\n=== GitHub release\n\nIf you want to stay on the Jenkins side, there isn't a plugin this time.\nHowever, there are various ways to create a release.\nYou can use the link:https://docs.github.com/en/rest?apiVersion=2022-11-28[GitHub REST API] or the link:https://cli.github.com/[`gh`] command, which can handle all the heavy lifting for us.\nTherefore, let's go back to the drawing board and add the command to our Docker image.\n\n[source,dockerfile]\n----\n# Install GitHub command line tool\nENV GITHUB_TOKEN $GITHUB_TOKEN\nRUN curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg && \\\n    chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg && \\\n    echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main\" | tee /etc/apt/sources.list.d/github-cli.list > /dev/null && \\\n    apt update && apt install -y --no-install-recommends gh\n----\n\nOnce that's done, we need to use link:https://docs.github.com/en/apps/creating-github-apps/authenticating-with-a-github-app/about-authentication-with-a-github-app[GitHub App authentication] to enable `gh` to use our credentials.\nTo do this, we have to install the link:https://plugins.jenkins.io/github-branch-source/[GitHub Branch Source plugin] and then create a link:https://www.jenkins.io/blog/2020/04/16/github-app-authentication/[GitHub Application].\n\nThe link:https://github.com/jenkinsci/github-branch-source-plugin/blob/master/docs/github-app.adoc[existing documentation] on GitHub is exactly what we need, so a link to this should suffice.\nThe only fields you need to prepare and fill out at this stage are:\n\n- Github App name - i.e. `Jenkins-<team name>`\n- Homepage URL - your company's domain or a GitHub repository\n- Webhook URL - your jenkins instance, for example, `https://<jenkins-host>/github-webhook/`\n\nAt that moment, I link:https://github.com/gounthar/MyFirstAndroidAppBuiltByJenkins/blob/main/jenkins/create-release.sh[queried] GitHub using `gh` to determine \nwhether the release already existed, and create it if not.\n\nMy choice of how to create the release was entirely arbitrary: I decided to create a release when the version ended with `\"RELEASE\"`, a draft release when there was no suffix, and a pre-release when the version ended with `\"ALPHA\"` or `\"BETA\"`.\n\n[source,bash]\n----\nsuffix=$(echo $versionName | sed 's/.*-//')\ncase $suffix in\n    ALPHA|BETA)\n        echo \"Time to do a prerelease\"\n        GH_OPTS=\"$GH_OPTS-p\"\n        ;;\n    SNAPSHOT)\n        echo \"This is a snapshot, we won't release anything\"\n        GH_OPTS=\"$GH_OPTS DO_NOT_RELEASE\"\n        ;;\n    RELEASE)\n        echo \"This a real release, so no need to use -d or -p\";;\n    *)\n        echo \"Unknown suffix \\\"$suffix\\\", so we'll do a draft release\"\n        GH_OPTS=\"$GH_OPTS-d\"\n        ;;\nesac\n----\n\nThis is good enough for my use case.\n\nThe `gh` command does a nice job of preparing a release change log, so I'm relying on it.\nIf we're not building on the main branch, the release is not finalized, so I can still tidy it up later.\nIt's great to be able to create a release as soon as it's required, even when it's not necessary\u2026\n\nimage:/images/post-images/2023/05/02/2023-05-02-android-and-jenkins-releases/too-many-releases.png[Too many releases, role=center, width=839]\n\nIt looks like I may have gone a little too far with the automatic release creation, don't you think?\n\nNow, what about using that workflow to create a release on the Play Store?\n\n=== Google Play Store release\n\nThe version is already handled by the semantic plugin, and the release notes are almost ready to go.\nNow, we just need to find the right plugin to push our app to the Google Play Store.\nLuckily, we have a plugin for that, called link:https://github.com/Triple-T/gradle-play-publisher[`com.github.triplet.play`].\nThis time, it's a link:https://plugins.gradle.org/plugin/com.github.triplet.play[Gradle plugin] instead of a Jenkins plugin.\n\nThe first step to getting your app on the Play Store is to pay the $25 developer account fee.\nAfter that, you need to register your app, import the EULA (there are link:https://termly.io/products/eula-generator/[free websites] to generate that), upload the required paperwork, and then upload the signed app.\nSince the app is not signed yet, we'll need to do that first.\n\n\n==== Signing the app from the command line\n\nThere are different ways to sign your app - from the command line using `apksigner` for APKs, `jarsigner` for app bundles, or you can configure Gradle to sign it during the build.\nIn any case, you need to generate a private key using `keytool` before signing the app.\n\n[source,bash]\n----\n keytool -genkey -v -keystore my-release-key.jks -keyalg RSA -validity 10000 -alias my-alias\n----\n\nLet's quickly review how to sign an apk:\n\n1. Align the unsigned APK using link:https://developer.android.com/tools/zipalign[`zipalign`]:\n+\n[source,bash]\n----\nzipalign -v -p 4 my-app-unsigned.apk my-app-unsigned-aligned.apk\n----\n+\n`zipalign` ensures that all uncompressed data starts with a particular byte alignment relative to the start of the file, which may reduce the amount of RAM consumed by an app.\n2. Sign your APK with your previously generated private key using link:https://developer.android.com/tools/apksigner[`apksigner`]:\n+\n[source,bash]\n----\napksigner sign --ks my-release-key.jks --out my-app-release.apk my-app-unsigned-aligned.apk\n----\n+\nThis example outputs the signed APK at `my-app-release.apk` after signing it with a private key and certificate, that are stored in a single KeyStore file: `my-release-key.jks`.\n\nNow, let's discuss how to sign an application bundle (located in `app/build/outputs/bundle/debug`) thanks to Gradle.\n\n[source,bash]\n----\njarsigner -verbose -sigalg SHA256withRSA -keystore ../../../../../my-release-key.jks app-debug.aab my-alias\n----\n\n==== Signing the app from Gradle\n\nOpen the module-level `build.gradle` file and add the `signingConfigs {}` block with entries for `storeFile`, `storePassword`, `keyAlias` and `keyPassword`.\nThen, pass that object to the `signingConfig` property in your build type.\nFor example:\n\n[source,groovy]\n----\n signingConfigs {\n        release {\n            // You need to specify either an absolute path or include the\n            // keystore file in the same directory as the build.gradle file.\n            storeFile file(\"my-release-key.jks\")\n            storePassword \"password\"\n            keyAlias \"my-alias\"\n            keyPassword \"password\"\n        }\n    }\n\n    buildTypes {\n        release {\n            minifyEnabled false\n            proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'\n            signingConfig signingConfigs.release\n        }\n    }\n----\n\nFrom now on, when you create the bundle with Gradle, it will be signed, self-signed, which is not what we're aiming for.\nWe still need to upload the icon, a summary, screenshots, banners, and other boilerplate content\u2026\nThe next step is to create a GCP project.\n\n==== Creating a GCP project\n\nvideo::Vdw1LgBcy3o[youtube, width=839, height=473, role=center]\n\nYou have to link:https://developers.google.com/android-publisher/getting_started#enable[enable the Android Publisher API] for that project.\n\nvideo::eXJBIkHNB48[youtube, width=839, height=473, role=center]\n\nThen, you have to link:https://developers.google.com/android-publisher/getting_started#existing[link] your Google Play developer account to the GCP project.\n\nvideo::XaokL2ku4JA[youtube, width=839, height=473, role=center]\n\nAfter this, you need to link:https://cloud.google.com/iam/docs/service-accounts-create[create a service account].\n\nvideo::hAHvZe1XklU[youtube, width=839, height=473, role=center]\n\nThen create a link:https://cloud.google.com/iam/docs/keys-create-delete[key].\n\nvideo::LdMSK1d63Sw[youtube, width=839, height=473, role=center]\n\nTo set up the necessary credentials for publishing our app to the Play Store, we'll need to create an environment variable in Jenkins.\nTo do this, we first need to install the link:https://plugins.jenkins.io/envinject/[Environment Injector plugin].\nOnce that's done, we can grant the necessary permissions to our service account so that it can publish the app on our behalf.\n\nvideo::LXVydeeMnSU[youtube, width=839, height=473, role=center]\n\nAnd we're finally ready to publish our app thanks to Gradle on Jenkins.\n\n==== Publishing the app\n\nThe `gradlew` tasks group `publishing` tells us we have a `publishBundle` task that uploads App Bundle for all variants.\n\n[source,bash]\n----\n./gradlew tasks --group publishing\n\n> Task :tasks\n\n------------------------------------------------------------\nTasks runnable from root project 'My First Built by Jenkins Applications'\n------------------------------------------------------------\n\nPublishing tasks\n----------------\n[...]\npublishBundle - Uploads App Bundle for all variants.\n   See https://github.com/Triple-T/gradle-play-publisher#publishing-an-app-bundle\n[...]\nBUILD SUCCESSFUL in 1s\n1 actionable task: 1 executed\n----\n\nAs we did not store the generated `jks` file in the repo, we have to use a variable to hold the value.\nOn your machine, it would work with something like:\n\n[source,bash]\n----\nexport ANDROID_PUBLISHER_CREDENTIALS=`cat *json`\n----\n\nOn Jenkins, we will create a secret.\n\nvideo::XkORY9nbgak[youtube, width=839, height=473, role=center]\n\nThe secret is now available under the `android-publisher-credentials` key.\n\nThe triplet link:https://github.com/Triple-T/gradle-play-publisher#common-configuration[documentation] tells us that we can set up a configuration in the build.gradle file like:\n\n[source,groovy]\n----\nplay {\n    // Overrides defaults\n    track.set(\"internal\")\n    updatePriority.set(2)\n    releaseStatus.set(ReleaseStatus.DRAFT)\n    // ...\n}\n----\n\nGradle Play Publisher supports uploading both the App Bundle and APK, and can promote those artifacts to different tracks.\nYou can customize how your artifacts are published using several options:\n\n* `track`: The target stage for an artifact, such as `internal`/`alpha`/`beta`/`production` or any custom track.\n** Defaults to internal\n* `releaseStatus`: The type of release, such as `ReleaseStatus.COMPLETED`, `ReleaseStatus.DRAFT`, `ReleaseStatus.HALTED`, or `ReleaseStatus.IN_PROGRESS`.\n** Defaults to `ReleaseStatus.COMPLETED`\n* `userFraction`: The percentage of users who will receive a staged release.\n** This is only applicable where `releaseStatus=[IN_PROGRESS/HALTED]`.\n** defaults to `0.1` (10%)\n* `updatePriority`: Sets the update priority for a new release.\nRefer to link:https://developer.android.com/guide/playcore/in-app-updates[Google's documentation] for more information.\n** Defaults to the API value\n\nFurthermore, according to the link:https://github.com/Triple-T/gradle-play-publisher#uploading-release-notes[documentation], you need to supply a release notes file.\nTo do so, you need to add a file under `src/[sourceSet]/play/release-notes/[language]/[track].txt`. +\nHere, `sourceSet` is a full variant name, `language` is one of the Play Store supported codes, and `track` is the channel you want these release notes to apply to.\nIf no channel is specified, the default channel will be used.\n\nAs an example, let's assume you have these two different release notes:\n\n[source,bash]\n----\nsrc/main/play/release-notes/en-US/default.txt\n.../beta.txt\n----\n\nWhen you publish to the beta channel, the `beta.txt` release notes will be uploaded.\nFor any other channel, `default.txt` will be uploaded.\n\nFor our use case, we'll link:https://github.com/gounthar/MyFirstAndroidAppBuiltByJenkins/blob/main/jenkins/create-gps-release.sh[use] the `internal` track, and start from the release notes generated via the `gh` tool to produce a shorter version, limited to 500 characters as specified by Google.\n\n[source,bash]\n----\ngh release view v${versionName} | grep -A 500 \"\\-\\-\" | grep -v \"\\-\\-\" | sed 's/http.*[/]/#/' > $releaseNotesDir/internal.txt\n    content=$(cat < \"$releaseNotesDir/internal.txt\" && echo .) && content=${content%.} && printf %s \"${content:0:500}\" > \"$releaseNotesDir/internal.txt\"\n----\n\nHave we completed all the necessary steps?\n\nWe now have an Android application that builds, has undergone static analysis, and is automatically pushed to both GitHub and the Google Play Store.\nHowever, there is still much left to cover, which we will explore in upcoming episodes.\n"
  },
  {
    "question_id": "doc_07",
    "source_file": "benchmark_data/source_files/doc_07_index.txt",
    "question": "I'm a GSoC contributor having a communication difficulty with one of the org admins that I need to address privately. According to the document, what is the specific contact method I should use for this matter, and for a separate, complex technical question, which channel is recommended for long-form discussions over the Gitter channel?",
    "ground_truth_context": "// image:/images/gsoc/jenkins-gsoc-logo_small.png[Jenkins GSoC, role=center, float=left]\nlink:https://developers.google.com/open-source/gsoc/[Google Summer of Code]\n(GSoC) is a global, online program focused on bringing students and new contributors into open source software development. GSoC Contributors work with an open source organization on a 12+ weeks-long programming project under the guidance of dedicated mentors.\n\nGSoC contributors accepted into the program receive a stipend and are sponsored by Google, to work on well-defined projects to improve or enhance the Jenkins project.\nIn exchange, numerous Jenkins community members volunteer as \"mentors\" for the selected GSoC contributors to help integrate them into the open source community and succeed in completing their projects.\n\nimage:/images/gsoc/opengraph.png[Jenkins GSoC, role=center, float=center]\n\n== GSoC 2025\n\n// We are planning to participate in Google Summer of Code in 2025. +\n\nWe are participating in Google Summer of Code in 2025. +\n// See our link:https://docs.google.com/document/d/1FYOBo12qz24Vxq0TxWuv9ElHH_rHP51ouMsPms4tTmw/edit?usp=sharing[Jenkins GSoC Mentoring Org Application Form].\nGoogle has accepted us as a mentoring organization in Google Summer of Code 2025.\nSee our link:https://summerofcode.withgoogle.com/programs/2025/organizations/jenkins-wp[Jenkins organization page on the GSoC website].\n\n// Uncomment when application is worked on and submitted (Feb 2025)\n//(link:./2025/application[Jenkins GSoC Organisation Application Form])\n\nThe five selected projects for 2025 are:\n\n* link:/projects/gsoc/2025/projects/ai-powered-chatbot-for-quick-access-to-jenkins-resources[AI-Powered Chatbot for Quick Access to Jenkins Resources] with link:https://github.com/giovanni-vaccarino/[Giovanni Vaccarino] as the GSoC contributor.\n\n* link:/projects/gsoc/2025/projects/complete-alternative-jenkins-io-build-retooling[Complete build retooling of jenkins.io] with link:https://github.com/biru-codeastromer/[Birajit Saikia] as the GSoC contributor.\n\n* link:/projects/gsoc/2025/projects/domain-specific-LLM-based-on-jenkins-usage-using-ci-jenkins-io-data[Domain-specific LLM based on actual Jenkins usage using ci.jenkins.io data] with link:https://github.com/chiruu12/[Chirag Gupta] as the GSoC contributor.\n\n* link:/projects/gsoc/2025/projects/improving-tekton-client-plugin[Improving Tekton Client Plugin for Jenkins] with link:https://github.com/maeveho25/[Maeve Ho] as the GSoC contributor.\n\n* link:/projects/gsoc/2025/projects/plugin-modernizer-improvements[Improving Plugin Modernizer] with link:https://github.com/CodexRaunak/[Raunak Madan] as the GSoC contributor.\n\nThey were proposed and selected from these link:./2025/project-ideas[project ideas].\n\n// We have finalised a list of 11 project ideas, 8 of which are accepted ones.\n// Add your ideas by submitting an ad-hoc pull request as explained in our previous link:/blog/2022/11/16/gsoc-2023/[GSoC blog post].\n\n// The 2025 GSoC project ideas link:./2025/project-ideas[can be found here].\n\nNOTE: Every year, there are changes in how GSoC is organized.\nJenkins GSoC documentation may be outdated in some places, please refer to the https://summerofcode.withgoogle.com/[official GSoC website] as a source of truth.\nOur documentation will be updated over time to reflect the changes in the GSoC program, please report any issues you encounter via our GitHub issue tracker.\n\nThe 2025 GSoC midterm presentations have been delivered and are available in link:https://youtu.be/serD66DmEeU[a singular recording on the Jenkins Youtube channel].\n\n== GSoC Contributors\n\n* link:/projects/gsoc/contributors[Information and application guidelines for GSoC contributors]\n// * Online Meetup: Introduction to Jenkins in GSoC\n// (link:https://bit.ly/3pbJFuC[slides],\n// link:https://youtu.be/GDRTgEvIVBc[video])\n* link:https://summerofcode.withgoogle.com/programs/2025/organizations/jenkins-wp[Jenkins organization page on the GSoC website]\n* link:https://summerofcode.withgoogle.com/[Google Summer of Code portal]\n\n== Mentors\n\nMentors are volunteers who help GSoC contributors to succeed in their projects.\nIf you are interested in contributing to GSoC as a mentor, and have had either some GSoC contributor experience or have done mentoring before, please do not hesitate to reach out to us.\nWe are always looking for new mentors to help us with the program.\n\n* link:/projects/gsoc/mentors[Information for mentors]\n* link:/projects/gsoc/proposing-project-ideas[HOWTO: Propose a project idea]\n* link:/projects/gsoc/roles-and-responsibilities[Roles and Responsibilities]\n* link:https://summerofcode.withgoogle.com/[Google Summer of Code portal]\n* link:https://community.jenkins.io/c/contributing/gsoc-mentors/25[Mentor's Dedicated Discourse group]\n\n== Org Admins\n\nOrg Admins are the people managing the GSoC program for the Jenkins Organization.\nFor 2025, our Org Admins are:\n\n* Alyssa Tong\n* Kris Stern\n* Bruno Verachten\n\nThe following checklists and documents describe the role:\n\n* link:https://docs.google.com/document/d/1tShnTyka5fdBxaE0c93ptu-J_XTlSf3tKwJemhx5_nA/edit?usp=sharing[Org Admin runbook for the Jenkins project]\n* link:https://developers.google.com/open-source/gsoc/help/oa-tips[Org Admin tips by Google]\n\n== Contacts\n\n* We use the link:/sigs/gsoc[GSoC SIG] for communications about GSoC.\nProjects may also have their own mailing lists, chats, and meetings.\nPlease take a look at the details on each of the project pages.\n* We use link:https://community.jenkins.io/c/contributing/gsoc/6[Discourse] for discussions.\n  This is the **recommended** channel for communications.\n* There is also a link:https://app.gitter.im/#/room/#jenkinsci_gsoc-sig:gitter.im[GSoC Gitter channel] for real-time communications, but it is better to use Discourse to request technical feedback or to have long-form discussions.\n* For private matters such as communication difficulties with mentors, GSoC contributors, or Org Admins,\n  please use this mailto:gsoc-jenkins-org-admin@googlegroups.com[group email].\n\n=== GSoC Discourse\n\nPublic communication channel: link:https://community.jenkins.io/c/contributing/gsoc/6[GSoC Discourse].\n\nThe purpose of GSoC Discourse is for all public communications on GSoC such as new mentor and new GSoC contributor introductions, project proposal questions and discussions, process and timeline related questions.\n\n=== Chats\n\n* link:https://app.gitter.im/#/room/#jenkinsci_gsoc-sig:gitter.im[GSoC Gitter channel] for organizational topics related to Jenkins in GSoC\n* Project-specific chats, see project and project idea pages\n* link:/chat/[Common developer chats] for technical topics\n\n=== Office hours\n\nAlthough we use Discourse as the main communication channel, we will have regular \"office hours\" video calls.\nDuring these time slots Jenkins GSoC org admins and mentors are available for any GSoC-related questions.\n\n// * Schedule: Weekly 30 minutes meetings. Office hours will be held on Thursdays at 13:00 UTC.\n//   Use the link:/event-calendar[Jenkins event calendar] to view the meeting time in your own time zone.\n// * link:https://docs.google.com/document/d/1UykfAHpPYtSx-r_PQIRikz2QUrX1SG-ySriz20rVmE0/edit?usp=sharing[Agenda]\n// * Meetings are commonly recorded on-demand and posted link:https://www.youtube.com/playlist?list=PLN7ajX_VdyaODwGnSZzxjV6-6mqRfcoBe[here].\n\n// This meeting will be used for Q&A with GSoC applicants/contributors and mentors before the announcement of accepted projects as well as during the GSoC program.\n// You can add the office hours to your calendar when you visit the link:/event-calendar[Jenkins event calendar].\n// More slots may be added on-demand, e.g. for project-specific discussions.\n\nIn addition to these organization-wide meetings, each GSoC project will hold regular meetings during community bonding and coding phases.\n// Please take a look at the project pages for the schedule.\n\n== Previous years\n\n* link:/projects/gsoc/2024[GSoC 2024] - 5 contributor projects\n* link:/projects/gsoc/2023[GSoC 2023] - 4 contributor projects\n* link:/projects/gsoc/2022[GSoC 2022] - 4 contributor projects\n* link:/projects/gsoc/2021[GSoC 2021] - 5 contributor projects\n* link:/projects/gsoc/2020[GSoC 2020] - 7 contributor projects\n* link:/projects/gsoc/2019[GSoC 2019] - 7 contributor projects\n* link:/projects/gsoc/2018[GSoC 2018] - 3 contributor projects\n* link:/projects/gsoc/gsoc2017[GSoC 2017] - not accepted\n* link:/projects/gsoc/gsoc2016[GSoC 2016] - 5 contributor projects\n* link:https://wiki.jenkins.io/display/JENKINS/Google+Summer+of+Code+2009[GSoC 2009] - as Hudson, not accepted\n\n== References, 2025\n\n* link:./2025/project-ideas[GSoC 2025 project ideas]\n// * link:https://summerofcode.withgoogle.com/programs/2025/organizations/jenkins-wp/[Jenkins page on the GSoC website]\n// * link:/blog/2025/02/23/gsoc2025-announcement/[Jenkins GSoC 2025 announcement]\n// * link:https://opensource.googleblog.com/2022/11/get-ready-for-google-summer-of-code-2023.html[Google GSoC 2025 announcement blog]\n\n\n== GSoC Do's and Don'ts\nWe have a set of guidelines for GSoC contributors and mentors to help them succeed in the program. For details see:\n\n* link:/projects/gsoc/dos-and-donts[GSoC Do's and Don'ts]\n\n== References\n\nYou can find more information about GSoC in Jenkins below.\n\n* link:/sigs/gsoc[Jenkins GSoC Special Interest Group]\n* link:/sigs/advocacy-and-outreach/outreach-programs/[Other outreach programs in Jenkins]\n* link:https://summerofcode.withgoogle.com/[Google Summer of Code portal]\n"
  },
  {
    "question_id": "doc_08",
    "source_file": "benchmark_data/source_files/doc_08_2021-07-31-remoting-monitoring-phase-1.txt",
    "question": "I'm trying to understand the best way to deploy the monitoring program for my Jenkins agents. I initially thought about sending it from the controller over the remoting channel once the agent is connected. Can you explain the two main drawbacks of this approach that led to the decision to instead install the monitoring engine during the agent provisioning phase?",
    "ground_truth_context": "image:/images/post-images/2021-07-31-remoting-monitoring-phase-1/opengraph.png[Remoting Monitoring with OpenTelemetry]\n\n== Goal\n\nimage:/images/post-images/2021-07-31-remoting-monitoring-phase-1/goal.png[Goal of Remoting Monitoring with OpenTelemetry, align=\"center\", width=700]\n\n*The goal of this project:*\n\n* collect telemetry data(metrics, traces, logs) of remoting module with\nOpenTelemetry.\n* send the telemetry data to OpenTelemetry Protocol endpoint\n\nWhich OpenTelemetry endpoint to use and how to visualize the data are up to\nusers.\n\n== OpenTelemetry\n\nimage:https://cncf-branding.netlify.app/img/projects/opentelemetry/horizontal/color/opentelemetry-horizontal-color.png[OpenTelemetry Logo, link=https://opentelemetry.io/, width=300]\n\n*An observability framework for cloud-native software*\n\n____\nOpenTelemetry is a collection of tools, APIs, and SDKs.\nYou can use it to instrument, generate, collect, and export telemetry\ndata(metrics, logs, and traces) for analysis in order to understand your\nsoftware's performance and behavior.\n____\n\n== Phase 1 summary\n\n=== User survey\n\nOur team conducted a user survey to understand the pain point regarding Jenkins\nremoting.\n\n.Fig 1. What agent type/plugins do you use?\n[caption=\"Figure 1:\"]\nimage:/images/post-images/2021-07-31-remoting-monitoring-phase-1/user-survey.png[End user survey result, width=700]\n\nFig 1 shows what types of agent users use, and 17 unique respondents out of\n28 use docker for agent. So I'm planning to publish a docker image to\ndemonstrate how we can build Docker image with our monitoring feature.\n\nThis survey and investigation of JIRA tickets of past two years also tell me five\ncommon causes of agent unavailability.\n\n* *Configuration mistakes*\n** Jenkins agent settings, e.g. misuse of \"tunnel connection through\" option.\n** Platform settings, e.g. invalid port setting of Kubernetes' helm template.\n** Network settings, e.g. Load balancer misconfiguration.\n* *Uncontrolled shutdown of nodes* for downscaling.\n* *Timeout during provisioning* a new node.\n* *Firewall, antivirus software or other network component kill the connection*\n* *Lack of hardware resources*, e.g. memory, temp space, etc...\n\nWe also heard valuable user voice in the survey.\n\n.What areas would you like to see better in Jenkins monitoring?\n____\nI have created a bunch of adhoc monitoring jobs to check on the agent's health\nand send e-mail. Would be nice to have this consolidated.\n____\n\n____\nHaving archive of nodes with the access to their logs/events would have been\nnice.\n____\n\nI hope that implementing these feature with OpenTelemetry, which is expected to\nbecome the industry standard for observability, will bring great monitoring\nexperience to Jenkins community.\n\n=== Proof of Concept\n\n==== How to deliver the monitoring program to agents\n\n===== 1. Sending monitoring program to the agent over remoting\n\nimage:/images/post-images/2021-07-31-remoting-monitoring-phase-1/sending-monitoring-program-via-remoting.png[Sending monitoring program via remoting]\n\nIn my first implementation, I prepared a Jenkins plugin and send the\nmonitoring program from Jenkins controller. However, this approach have\nfollowing disadvantages.\n\n. We cannot collect telemetry data before the initial connection.\nWe are likely to encounter a problem while provisioning a new node,\nso it's important to observe agents' telemetry data from the beginning.\n. Some agent restarters (e.g. link:https://javadoc.jenkins.io/jenkins/slaves/restarter/UnixSlaveRestarter.html[UnixSlaveRestarter])\nrestart agent completely when reconnecting. It means that the agent lost\nmonitoring program every time the connection closed, and we cannot collect\ntelemetry data after the connection is lost before a new connection is\nestablished.\n\nSo we decided to take the next approach.\n\n===== 2. Install monitoring engine when provisioning a new agent\n\nimage:/images/post-images/2021-07-31-remoting-monitoring-phase-1/install-monitoring-engine-when-provisioning.png[Installing monitoring engine when provisioning]\n\nIn this approach, user will download the monitoring program called monitoring\nengine, which is a JAR file, and place it in the agent node when provisioning.\n\n==== How to instrument remoting to produce remoting trace\n\n===== Add instrumentation extension point to remoting\n\nPull Request: https://github.com/jenkinsci/remoting/pull/471\n\nThis approach makes the agent launch command more complicated,\nand we have to overcome this problem.\n\n\n=== Current State\n\n==== Metrics\n\nWe currently support the following metrics and planning to support more.\n\n[cols=\"2,1,1,3,8\"]\n|===\n|metrics|unit| label | key | description\n|system.cpu.load|1||\n|System CPU load. See `com.sun.management.OperatingSystemMXBean.getSystemCpuLoad`\n\n|system.cpu.load.average.1m|||\n|System CPU load average 1 minute See `java.lang.management.OperatingSystemMXBean.getSystemLoadAverage`\n\n|system.memory.usage|bytes|state|`used`, `free`\n|\nsee `com.sun.management.OperatingSystemMXBean.getTotalPhysicalMemorySize`\nand `com.sun.management.OperatingSystemMXBean.getFreePhysicalMemorySize`\n\n|system.memory.utilization|1||\n|\nSystem memory utilization,\nsee `com.sun.management.OperatingSystemMXBean.getTotalPhysicalMemorySize`\nand `com.sun.management.OperatingSystemMXBean.getFreePhysicalMemorySize`.\nReport 0% if no physical memory is discovered by the JVM.\n\n|system.paging.usage|bytes|state|`used`, `free`\n|\nsee `com.sun.management.OperatingSystemMXBean.getFreeSwapSpaceSize`\nand `com.sun.management.OperatingSystemMXBean.getTotalSwapSpaceSize`.\n\n|system.paging.utilization|1||\n|\nsee `com.sun.management.OperatingSystemMXBean.getFreeSwapSpaceSize`\nand `com.sun.management.OperatingSystemMXBean.getTotalSwapSpaceSize`.\nReport 0% if no swap memory is discovered by the JVM.\n\n|process.cpu.load|%||\n|Process CPU load. See `com.sun.management.OperatingSystemMXBean.getProcessCpuLoad`.\n\n|process.cpu.time|ns||\n|Process CPU time. See `com.sun.management.OperatingSystemMXBean.getProcessCpuTime`.\n\n.2+|runtime.jvm.memory.area .2+|bytes|type|`used`, `committed`, `max`\n.2+|see link:https://docs.oracle.com/en/java/javase/11/docs/api/java.management/java/lang/management/MemoryUsage.html[MemoryUsage]\n|area|`heap`, `non_heap`\n\n.2+|runtime.jvm.memory.pool .2+|bytes|type|`used`, `committed`, `max`\n.2+|see link:https://docs.oracle.com/en/java/javase/11/docs/api/java.management/java/lang/management/MemoryUsage.html[MemoryUsage]\n|pool|`PS Eden Space`, `G1 Old Gen`...\n\n|runtime.jvm.gc.time|ms|gc| `G1 Young Generation`, `G1 Old Generation`, ...\n|see link:https://docs.oracle.com/en/java/javase/11/docs/api/jdk.management/com/sun/management/GarbageCollectorMXBean.html[GarbageCollectorMXBean]\n\n|runtime.jvm.gc.count|1|gc| `G1 Young Generation`, `G1 Old Generation`, ...\n|see link:https://docs.oracle.com/en/java/javase/11/docs/api/jdk.management/com/sun/management/GarbageCollectorMXBean.html[GarbageCollectorMXBean]\n\n|===\n\n==== Traces\n\nWe tried several approaches to instrument remoting module, but good approach is not established yet.\n\nHere is a draft documentation of the spans to collect. link:https://docs.google.com/document/d/1gjRamLWz3NwenVifC5pYyBMmxsUjl9MjspZF0mRYeaI/edit#heading=h.6xn68iwvd7gz[Google Doc]\n\n==== Logs\n\nComing soon!\n\n=== Metric and span demo visualization\n\nOur team created a demo example with Docker compose and visualized the metrics and spans.\n\n*_Click to open in new tab_*\n\nimage:/images/post-images/2021-07-31-remoting-monitoring-phase-1/prometheus-metrics.png[prometheus metric visualization, width=40%, link=/images/post-images/2021-07-31-remoting-monitoring-phase-1/prometheus-metrics.png, window=_blank]\nimage:/images/post-images/2021-07-31-remoting-monitoring-phase-1/jaeger-spans.png[jaeger span visualization, width=55%, link=/images/post-images/2021-07-31-remoting-monitoring-phase-1/jaeger-spans.png, window=_blank]\n\n== Google Summer of Code Midterm Demo\n\n.Our project demo starts with 8:20\nvideo::_D0hiA1Cgz8[youtube,width=400,height=300,start=514]\n\n== Next Step\n\n* Log support\n* Alpha release!\n"
  },
  {
    "question_id": "doc_09",
    "source_file": "benchmark_data/source_files/doc_09_2020-07-27-machine-learning-plugin-coding-phase2.txt",
    "question": "According to the project's discussion on future improvements for the Machine Learning plugin, what was the concluded strategy for implementing multi-language support, specifically regarding how the plugin should dynamically select the correct kernel for a given script file?",
    "ground_truth_context": "image::/images/gsoc/jenkins-gsoc-logo_small.png[align=\"center\"]\n\nWelcome back folks!\n\nThis blog post is about my coding phase 2 in Jenkins link:/projects/gsoc/2020/projects/machine-learning/[Machine Learning Plugin] for this GSoC 2020.\nAfter successfully passing the evaluation and demo in the phase 1, our team went ahead for facing the challenges in phase 2.\n\n== Summary\n\nThis phase of coding was well spent by documentation and by fixing many bugs.\nAs the main feature of connecting to an IPython Kernel is done in phase 1, we were able to focus on fixing minor/major bugs and documenting for the users.\nAccording to the link:https://issues.jenkins.io/browse/JENKINS-62927[JENKINS-62927] issue, a Docker agent was built to facilitate users without concerning plugin dependencies in python.\nIn the act of deprecation of Python 2, we ported our plugin to support Python 3.\nWe have tested our plugin in Conda, venv and Windows environments.\nMachine learning plugin has successfully passed the end to end test. A feature for a code editor is needed for further discussion/analysis as we have done a simple editor that may be useful in other ways in the future. link:https://github.com/jenkinsci/machine-learning-plugin/pull/35[PR#35]\n\n== Main features of Machine Learning plugin\n\n- Run Jupyter notebook, (Zeppelin) JSON and Python files\n- Run Python code directly\n- Convert Jupyter Notebooks to Python and JSON\n- Configure IPython kernel properties\n- Support to execute Notebooks/Python on Agent\n- Support for Windows and Linux\n\n== Upcoming features\n\n- Extract graph/map/images from the code\n- Save artifacts according to the step name\n- Generate reports for corresponding build\n\n== Future improvements\n\n- Usage of JupyterRestClient\n- Support for multiple language kernels\n\n* Note : There is no commitment on future improvements during GSoC period\n\n=== Docker agent\n\nThe following Dockerfile can be used to build the Docker container as an agent for the Machine Learning plugin. This docker agent can be used to run  notebooks or python scripts.\n\n.Dockerfile\n[source]\n----\nFROM jenkins/agent:latest\n\nMAINTAINER Loghi <loghijiaha@gmail.com>\n\nUSER root\n\nRUN apt update && apt install --no-install-recommends python3 -y \\\n    python3-pip \\\n    && rm -rf /var/lib/apt/lists/*\n\nCOPY requirements.txt /requirements.txt\n\nRUN pip3 install --upgrade pip setuptools && \\\n    pip3 install --no-cache-dir -r /requirements.txt && \\\n    ln -sf /usr/bin/python3 /usr/bin/python && \\\n    ln -sf /usr/bin/pip3 /usr/bin/pip\n\nUSER jenkins\n----\n\n\n=== Ported to Python 3\n\nAs discussed in the previous meeting, we concluded that the plugin should support Python 3 as Python 2.7+ has been deprecated since the beginning of 2020. Pull request for docker agent should be also ported to Python 3 support.\n\n=== Jupyter Rest Client API\n\nThe Jupyter Notebook server API seemed to be promising that it can be also used to run notebooks and codes. There were 3 api implementations that were merged in the master. But we had to focus on what was proposed in the design document and had to finish all must-have issues/works. Jupyter REST client was left for future implementation. It is also a good start to contribute to the plugin from the community.\n\n\n=== Fixed bugs for running in agent\n\nThere were a few bugs related to the file path of notebooks while building a job. The major problem was caused by the python dependencies needed to connect to a IPython kernel. All issues/bugs were fixed before the timeline given.\n\n=== R support as a future improvement\n\nThis is what we tried to give a glimpse of knowledge that this plugin can be extended for multi language support in the future. There was a conclusion that the kernel should be selected dynamically using extension of the script file(like `eval_model.rb` or `train_model.r`), instead of scripting the same code for each kernel.\n\n=== Documentation and End to End testing\n\nA well explained documentation was published in the repository. A guided tutorial to run a notebook checked out from a git repo in an agent was included in the link:https://github.com/jenkinsci/machine-learning-plugin/blob/master/docs/ML-docker-agent.adoc[docs] page. Mentors helped to test our plugin in both Linux and Windows.\n\n\n=== Code editor with rebuild feature\n\nCode editor was filtered as a nice to have feature in the design document. After grabbing the idea of Jenkinsfile replay editor, I could do the same for the code. At the same time, when we are getting the source code from git, it is not an elegant way of editing code in the original code. After the discussion, we had to leave the PR open that may have use cases in the future if needed.\n\n=== Jenkins LTS update\n\nThe plugin has been updated to support Jenkins LTS 2.204.1 as 2.164.3 had some problems with installing pipeline supported API/plugin\n\n== Installation for experimental version\n\n. Enable the link:/doc/developer/publishing/releasing-experimental-updates/#using-the-experimental-update-center[experimental update center]\n. Search for `Machine Learning Plugin` and check the box along it.\n. Click on `Install without restart`\n\nThe plugin should now be installed on your system.\n\n== Resources\n\n* link:/blog/2020/06/03/machine-learning-plugin-community-bonding/[Community Bonding blog post]\n* link:/blog/2020/06/30/machine-learning-plugin-coding-phase1/[Phase 1 blog post]\n* link:https://github.com/jenkinsci/machine-learning-plugin.git[Github]\n* link:/projects/gsoc/2020/projects/machine-learning/[Project page]\n* link:https://docs.google.com/document/d/10FjktNmWpdjgbGg3tEViadV_JNevn9W0sMOu-bF8m-o/edit?usp=sharing[Design document]\n"
  },
  {
    "question_id": "doc_10",
    "source_file": "benchmark_data/source_files/doc_10_2017-04-05-say-hello-blueocean-1-0.txt",
    "question": "My team is considering adopting Blue Ocean, but my manager is concerned about troubleshooting and integration with our existing GitHub workflow. Based on this document, what feature directly addresses the problem of having to scan through logs to find issues, and how does the GitHub integration work to provide status updates on feature branches and pull requests?",
    "ground_truth_context": "Back in May 2016 link:/blog/2016/05/26/introducing-blue-ocean/[we announced our intent]\nto rethink the Jenkins User experience with the Blue Ocean project and today\nthe Jenkins project are pleased to announce the general\navailability of Blue Ocean 1.0.\n\nBlue Ocean is an entirely new, modern and fun way for developers to use Jenkins\nthat has been built from the ground up to help teams of any size approach\nContinuous Delivery. Easily installed as a plugin for Jenkins and integrated\nwith Jenkins Pipeline, it is available from today for production use.\n\nSince the start of the beta at Jenkins World 2016 in September there are now\nover 7400+ installations making use of Blue Ocean. This wouldn\u2019t be possible\nwithout the support of the entire Jenkins developer and\nuser community - so thank you for your support!\n\nBlue Ocean is available today from the update center and also as a\nDocker image - link:/projects/blueocean[why not give it a try?]\n\n++++\n<center>\n<iframe width=\"853\" height=\"480\"\nsrc=\"https://www.youtube-nocookie.com/embed/k_fVlU1FwP4?rel=0\" frameborder=\"0\"\nallowfullscreen></iframe>\n</center>\n<br>\n++++\n\n*Visual Pipeline Editing* - Team members of any skill level can create continuous\ndelivery pipelines from start to finish, with just several clicks, using the\nintuitive, visual pipeline editor. Any pipeline created with the visual editor\ncan also be edited in your favorite text editor\nbringing all the benefits of Pipeline as Code.\n\nimage:/images/blueocean/press/pipeline-editor.png[Editor, role=center]\n\n*Pipeline Visualization* - Developers can visually represent pipelines in a way\nthat anyone on the team can understand - even your boss's boss - improving\nclarity into the continuous delivery process for the whole organization.\nThe visualization helps you focus on what the pipeline does, not how it does it.\n\nimage:/images/blueocean/press/pipeline-visualization.png[Pipeline visualization, role=center]\n\n*Pinpoint Troubleshooting* - Blue Ocean enables developers to locate automation\nproblems instantly, without endlessly scanning through logs or navigating\nthrough many screens, so you can get back to building the next big thing.\n\nimage:/images/blueocean/press/pipeline-diagnosis.png[Pinpoint Troubleshooting, role=center]\n\n*GitHub and Git Integration* - Pipelines are created for all feature branches\nand pull requests, with their status reported back to GitHub.\nThe whole team has visibility into whether changes need work or are good to go.\n\nimage:/images/blueocean/press/github-status.png[Github integration, role=center]\n\n*Personalization* \u2013 Every team member can make Jenkins their own by customizing\nthe dashboard so that they only see those pipelines that matter to them.\nFavoriting any pipeline or branch in Blue Ocean will show a favourite card on\nthe dashboard so you can see its status at a glance.\n\nimage:/images/blueocean/press/personalization.png[Personalized dashboard, role=center]\n\nJust one more thing \u2013 I\u2019d like to pay special thanks to:\n\n- *The Core team* \u2013 to Keith Zantow, Thorsten Scherler, Tom Fennelly,\nIvan Meredith, Josh McDonald, Vivek Pandey, Brody Maclean and Cliff Meyers.\nEach of and everyone of you have brought your own passion, expertise and flair\nto the project \u2013 and it shows. It\u2019s been crazy fun and I hope working on\nBlue Ocean is something you look back on fondly.\n- *Jenkins Developers* past and present \u2013 we recognise that we are standing on\nthe shoulders of giants and none of this wouldn\u2019t be possible without your\nhard work and dedication to free & open source software and Jenkins.\nHere\u2019s to the next 10 years \ud83c\udf7b !\n- *CloudBees* \u2013 in particular, Sacha Labourey (CEO), Harpreet Singh\n(VP of Product) and Spike Washburn (VP of Engineering) whose dedication to\nJenkins, Open Source and continued faith in the vision and team made all of\nthis possible, and of course Bob Bickel (Advisor) who dared us to dream big.\n- *Michael Neale* \u2013 who drank all the kool-aide and is just as obsessed with\nand dedicated to Blue Ocean as I am. This project would never have shipped\nwithout his hand steady at the tiller. I couldn\u2019t ask for a better friend\nand partner-in-crime.\n- *Tyler Croy* \u2013 for guiding the project and myself on how to do open source\nThe Right Way\u2122. Tyler works tirelessly behind the scenes to to make Jenkins\nawesome and it wouldn\u2019t be possible to keep this show running without\nhis help and sage-like advice.\n- *Kohsuke Kawaguchi* \u2013 For creating Jenkins, getting Blue Ocean off of\nthe ground, his tour of Tokyo and above all, his trust.\n- *Jenkins Users* \u2013 your enthusiasm for better development tools which\nkept our spirits and momentum up when the days grew long and things\nlooked tough. We couldn\u2019t ask for a better, more appreciative or\npassionate group of people. Hopefully we\u2019ve done our job and you can get\nback to building your next big thing!\n\nNext stop, some well needed rest & recovery then back to to making\nJenkins one of the experiences for software developers worldwide!\n\nIf you\u2019re interested in joining us to make Blue Ocean a great user experience\nfor Jenkins, please join the Blue Ocean development\nteam on link:https://app.gitter.im/#/room/#jenkinsci_blueocean-plugin:gitter.im[Gitter]!\n"
  },
  {
    "question_id": "doc_11",
    "source_file": "benchmark_data/source_files/doc_11_jenkinsfile.txt",
    "question": "My Declarative Pipeline passes a user-provided parameter to an `sh` step and a credential to a `bat` step. I'm encountering two security issues: first, special characters in the parameter can execute arbitrary commands, and second, a credential containing a '%' character is getting corrupted and is no longer masked in the console log. According to the document, what is the underlying Groovy string interpolation issue causing both of these problems, and what is the correct syntax I should use for both the `sh` and `bat` steps to securely handle these variables?",
    "ground_truth_context": "\n\nThis section builds on the information covered in link:../getting-started[Getting started with Pipeline] and introduces more useful steps, common patterns, and demonstrates some non-trivial `Jenkinsfile` examples.\n\nCreating a `Jenkinsfile`, which is checked into source control footnote:scm[https://en.wikipedia.org/wiki/Source_control_management], provides a number of immediate benefits:\n\n* Code review/iteration on the Pipeline\n* Audit trail for the Pipeline\n* Single source of truth footnote:[https://en.wikipedia.org/wiki/Single_Source_of_Truth] for the Pipeline, which can be viewed and edited by multiple members of the project.\n\nPipeline supports link:../syntax[two syntaxes], Declarative (introduced in Pipeline 2.5) and Scripted Pipeline.\nBoth of which support building continuous delivery pipelines.\nBoth may be used to define a Pipeline in either the web UI or with a `Jenkinsfile`, though it's generally considered a best practice to create a `Jenkinsfile` and check the file into the source control repository.\n\n\n== Creating a Jenkinsfile\n\nAs discussed in the link:../getting-started#defining-a-pipeline-in-scm[Defining a Pipeline in SCM], a `Jenkinsfile` is a text file that contains the definition of a Jenkins Pipeline and is checked into source control.\nConsider the following Pipeline which implements a basic three-stage continuous delivery pipeline.\n\n[pipeline]\n----\n// Declarative //\npipeline {\n    agent any\n\n    stages {\n        stage('Build') {\n            steps {\n                echo 'Building..'\n            }\n        }\n        stage('Test') {\n            steps {\n                echo 'Testing..'\n            }\n        }\n        stage('Deploy') {\n            steps {\n                echo 'Deploying....'\n            }\n        }\n    }\n}\n// Script //\nnode {\n    stage('Build') {\n        echo 'Building....'\n    }\n    stage('Test') {\n        echo 'Testing....'\n    }\n    stage('Deploy') {\n        echo 'Deploying....'\n    }\n}\n----\n\nNot all Pipelines will have these same three stages, but it is a good starting point to define them for most projects.\nThe sections below will demonstrate the creation and execution of a simple Pipeline in a test installation of Jenkins.\n\n[NOTE]\n====\nIt is assumed that there is already a source control repository set up for the project and a Pipeline has been defined in Jenkins following <<getting-started#defining-a-pipeline-in-scm, these instructions>>.\n====\n\nUsing a text editor, ideally one which supports link:http://groovy-lang.org[Groovy] syntax highlighting, create a new `Jenkinsfile` in the root directory of the project.\n\n\nThe Declarative Pipeline example above contains the minimum necessary structure to implement a continuous delivery pipeline.\nThe <<syntax#agent, agent directive>>, which is required, instructs Jenkins to allocate an executor and workspace for the Pipeline.\nWithout an `agent` directive, not only is the Declarative Pipeline not valid, it would not be capable of doing any work!\nBy default the `agent` directive ensures that the source repository is checked out and made available for steps in the subsequent stages.\n\nThe <<syntax#stages, stages directive>> and <<syntax#steps, steps directives>> are also required for a valid Declarative Pipeline as they instruct Jenkins what to execute and in which stage it should be executed.\n\n\nFor more advanced usage with Scripted Pipeline, the example above `node` is a crucial first step as it allocates an executor and workspace for the Pipeline.\nIn essence, without `node`, a Pipeline cannot do any work! From within `node`, the first order of business will be to checkout the source code for this project.\nSince the `Jenkinsfile` is being pulled directly from source control, Pipeline provides a quick and easy way to access the right revision of the source code.\n\n[role=scripted-pipeline]\n[pipeline]\n----\n// Script //\nnode {\n    checkout scm // <1>\n    /* .. snip .. */\n}\n// Declarative not yet implemented //\n----\n<1> The `checkout` step will checkout code from source control; `scm` is a special variable which instructs the `checkout` step to clone the specific revision which triggered this Pipeline run.\n\n\n\n=== Build\n\nFor many projects the beginning of \"work\" in the Pipeline would be the \"build\" stage.\nTypically this stage of the Pipeline will be where source code is assembled, compiled, or packaged.\nThe `Jenkinsfile` is *not* a replacement for an existing build tool such as GNU/Make, Maven, Gradle, or others, but rather can be viewed as a glue layer to bind the multiple phases of a project's development lifecycle (build, test, deploy) together.\n\nJenkins has a number of plugins for invoking practically any build tool in general use, but this example will simply invoke `make` from a shell step (`sh`).\nThe `sh` step assumes the system is Unix/Linux-based, for Windows-based systems the `bat` could be used instead.\n\n[pipeline]\n----\n// Declarative //\npipeline {\n    agent any\n\n    stages {\n        stage('Build') {\n            steps {\n                sh 'make' // <1>\n                archiveArtifacts artifacts: '**/target/*.jar', fingerprint: true // <2>\n            }\n        }\n    }\n}\n// Script //\nnode {\n    stage('Build') {\n        sh 'make' // <1>\n        archiveArtifacts artifacts: '**/target/*.jar', fingerprint: true // <2>\n    }\n}\n----\n<1> The `sh` step invokes the `make` command and will only continue if a zero exit code is returned by the command.\nAny non-zero exit code will fail the Pipeline.\n<2> `archiveArtifacts` captures the files built matching the include pattern (`+**/target/*.jar+`) and saves them to the Jenkins controller for later retrieval.\n\n\n[TIP]\n====\nArchiving artifacts is not a substitute for using external artifact repositories such as Artifactory or Nexus and should be considered only for basic reporting and file archival.\n====\n\n\n=== Test\n\nRunning automated tests is a crucial component of any successful continuous delivery process.\nAs such, Jenkins has a number of test recording, reporting, and visualization facilities provided by a link:https://plugins.jenkins.io/?labels=report[number of plugins].\nAt a fundamental level, when there are test failures, it is useful to have Jenkins record the failures for reporting and visualization in the web UI.\nThe example below uses the `junit` step, provided by the plugin:junit[JUnit plugin].\n\nIn the example below, if tests fail, the Pipeline is marked \"unstable\", as denoted by a yellow ball in the web UI.\nBased on the recorded test reports, Jenkins can also provide historical trend analysis and visualization.\n\n[pipeline]\n----\n// Declarative //\npipeline {\n    agent any\n\n    stages {\n        stage('Test') {\n            steps {\n                /* `make check` returns non-zero on test failures,\n                * using `true` to allow the Pipeline to continue nonetheless\n                */\n                sh 'make check || true' // <1>\n                junit '**/target/*.xml' // <2>\n            }\n        }\n    }\n}\n// Script //\nnode {\n    /* .. snip .. */\n    stage('Test') {\n        /* `make check` returns non-zero on test failures,\n         * using `true` to allow the Pipeline to continue nonetheless\n         */\n        sh 'make check || true' // <1>\n        junit '**/target/*.xml' // <2>\n    }\n    /* .. snip .. */\n}\n----\n<1> Using an inline shell conditional (`sh 'make check || true'`) ensures that the `sh` step always sees a zero exit code, giving the `junit` step the opportunity to capture and process the test reports.\nAlternative approaches to this are covered in more detail in the <<handling-failure>> section below.\n<2> `junit` captures and associates the JUnit XML files matching the inclusion pattern (`+**/target/*.xml+`).\n\n\n=== Deploy\n\nDeployment can imply a variety of steps, depending on the project or organization requirements, and may be anything from publishing built artifacts to an Artifactory server, to pushing code to a production system.\n\nAt this stage of the example Pipeline, both the \"Build\" and \"Test\" stages have successfully executed.\nIn essence, the \"Deploy\" stage will only execute assuming previous stages completed successfully, otherwise the Pipeline would have exited early.\n\n[pipeline]\n----\n// Declarative //\npipeline {\n    agent any\n\n    stages {\n        stage('Deploy') {\n            when {\n              expression {\n                currentBuild.result == null || currentBuild.result == 'SUCCESS' // <1>\n              }\n            }\n            steps {\n                sh 'make publish'\n            }\n        }\n    }\n}\n// Script //\nnode {\n    /* .. snip .. */\n    stage('Deploy') {\n        if (currentBuild.result == null || currentBuild.result == 'SUCCESS') { // <1>\n            sh 'make publish'\n        }\n    }\n    /* .. snip .. */\n}\n----\n<1> Accessing the `currentBuild.result` variable allows the Pipeline to determine if there were any test failures.\nIn which case, the value would be `UNSTABLE`.\n\nAssuming everything has executed successfully in the example Jenkins Pipeline, each successful Pipeline run will have associated build artifacts archived, test results reported upon and the full console output all in Jenkins.\n\n\nA Scripted Pipeline can include conditional tests (shown above), loops, try/catch/finally blocks, and even functions.\nThe next section will cover this advanced Scripted Pipeline syntax in more detail.\n\n\n== Working with your Jenkinsfile\n\nThe following sections provide details about handling:\n\n* specific Pipeline syntax in your `Jenkinsfile` and\n* features and functionality of Pipeline syntax which are essential in building your application or Pipeline project.\n\n\n[[using-environment-variables]]\n=== Using environment variables\n\nJenkins Pipeline exposes environment variables via the global variable `env`, which is available from anywhere within a `Jenkinsfile`.\nThe full list of environment variables accessible from within Jenkins Pipeline is documented at $\\{YOUR_JENKINS_URL}/pipeline-syntax/globals#env and includes:\n\nBUILD_ID:: The current build ID, identical to BUILD_NUMBER for builds created in Jenkins versions 1.597+.\nBUILD_NUMBER:: The current build number, such as \"153\".\nBUILD_TAG:: String of jenkins-$\\{JOB_NAME}-$\\{BUILD_NUMBER}. Convenient to put into a resource file, a jar file, etc for easier identification.\nBUILD_URL:: The URL where the results of this build can be found (for example, \\http://buildserver/jenkins/job/MyJobName/17/).\nEXECUTOR_NUMBER:: The unique number that identifies the current executor (among executors of the same machine) performing this build. This is the number you see in the \"build executor status\", except that the number starts from 0, not 1.\nJAVA_HOME:: If your job is configured to use a specific JDK, this variable is set to the JAVA_HOME of the specified JDK. When this variable is set, PATH is also updated to include the bin subdirectory of JAVA_HOME.\nJENKINS_URL:: Full URL of Jenkins, such as \\https://example.com:port/jenkins/ (NOTE: only available if Jenkins URL set in \"System Configuration\").\nJOB_NAME:: Name of the project of this build, such as \"foo\" or \"foo/bar\".\nNODE_NAME:: The name of the node the current build is running on. Set to 'master' for the Jenkins controller.\nWORKSPACE:: The absolute path of the workspace.\n\nReferencing or using these environment variables can be accomplished like accessing any key in a Groovy link:http://groovy-lang.org/syntax.html#_maps[Map], for example:\n\n[pipeline]\n----\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Example') {\n            steps {\n                echo \"Running ${env.BUILD_ID} on ${env.JENKINS_URL}\"\n            }\n        }\n    }\n}\n// Script //\nnode {\n    echo \"Running ${env.BUILD_ID} on ${env.JENKINS_URL}\"\n}\n----\n\n\n==== Setting environment variables\n\nSetting an environment variable within a Jenkins Pipeline is accomplished differently depending on whether Declarative or Scripted Pipeline is used.\n\nDeclarative Pipeline supports an <<syntax#environment, environment>> directive, whereas users of Scripted Pipeline must use the `withEnv` step.\n\n[pipeline]\n----\n// Declarative //\npipeline {\n    agent any\n    environment { // <1>\n        CC = 'clang'\n    }\n    stages {\n        stage('Example') {\n            environment { // <2>\n                DEBUG_FLAGS = '-g'\n            }\n            steps {\n                sh 'printenv'\n            }\n        }\n    }\n}\n// Script //\nnode {\n    /* .. snip .. */\n    withEnv([\"PATH+MAVEN=${tool 'M3'}/bin\"]) {\n        sh 'mvn -B verify'\n    }\n}\n----\n<1> An `environment` directive used in the top-level `pipeline` block will apply to all steps within the Pipeline.\n<2> An `environment` directive defined within a `stage` will only apply the given environment variables to steps within the `stage`.\n\n\n==== Setting environment variables dynamically\n\nEnvironment variables can be set at run time and can be used by shell scripts (`sh`), Windows batch scripts (`bat`) and PowerShell scripts (`powershell`).\nEach script can either `returnStatus` or `returnStdout`.\nlink:/doc/pipeline/steps/workflow-durable-task-step[More information on scripts].\n\nBelow is an example in a declarative pipeline using `sh` (shell) with both `returnStatus` and `returnStdout`.\n\n[pipeline]\n----\n// Declarative //\npipeline {\n    agent any // <1>\n    environment {\n        // Using returnStdout\n        CC = \"\"\"${sh(\n                returnStdout: true,\n                script: 'echo \"clang\"'\n            )}\"\"\" // <2>\n        // Using returnStatus\n        EXIT_STATUS = \"\"\"${sh(\n                returnStatus: true,\n                script: 'exit 1'\n            )}\"\"\"\n    }\n    stages {\n        stage('Example') {\n            environment {\n                DEBUG_FLAGS = '-g'\n            }\n            steps {\n                sh 'printenv'\n            }\n        }\n    }\n}\n// Script //\n----\n<1> An `agent` must be set at the top level of the pipeline.\nThis will fail if agent is set as `agent none`.\n<2> When using `returnStdout` a trailing whitespace will be appended to the returned string.\nUse `.trim()` to remove this.\n\n=== Handling credentials\n\nCredentials\nlink:../../using/using-credentials#configuring-credentials[configured in Jenkins] can be handled in Pipelines for immediate use.\nRead more about using credentials in Jenkins on the link:../../using/using-credentials[Using credentials] page.\n\n.The correct way to handle credentials in Jenkins\nvideo::yfjtMIDgmfs[youtube,width=800,height=420]\n\n\n==== For secret text, usernames and passwords, and secret files\n\nJenkins' declarative Pipeline syntax has the `credentials()` helper method (used within the <<syntax#environment,`environment`>> directive) which supports <<#secret-text,secret text>>, <<#usernames-and-passwords,username and password>>, as well as <<#secret-files,secret file>> credentials.\nIf you want to handle other types of credentials, refer to the <<#for-other-credential-types, For other credential types>> section.\n\n\n===== Secret text\n\nThe following Pipeline code shows an example of how to create a Pipeline using environment variables for secret text credentials.\n\nIn this example, two secret text credentials are assigned to separate environment variables to access Amazon Web Services (AWS).\nThese credentials would have been configured in Jenkins with their respective credential IDs `jenkins-aws-secret-key-id` and `jenkins-aws-secret-access-key`.\n\n[pipeline]\n----\n// Declarative //\npipeline {\n    agent {\n        // Define agent details here\n    }\n    environment {\n        AWS_ACCESS_KEY_ID     = credentials('jenkins-aws-secret-key-id')\n        AWS_SECRET_ACCESS_KEY = credentials('jenkins-aws-secret-access-key')\n    }\n    stages {\n        stage('Example stage 1') {\n            steps {\n                // // <1>\n            }\n        }\n        stage('Example stage 2') {\n            steps {\n                // // <2>\n            }\n        }\n    }\n}\n// Script //\n----\n<1> You can reference the two credential environment variables (defined in this Pipeline's <<syntax#environment,`environment`>> directive), within this stage's steps using the syntax `$AWS_ACCESS_KEY_ID` and `$AWS_SECRET_ACCESS_KEY`.\nFor example, here you can authenticate to AWS using the secret text credentials assigned to these credential variables.\nTo maintain the security and anonymity of these credentials, if the job displays the value of these credential variables from within the Pipeline (such as `echo $AWS_SECRET_ACCESS_KEY`), Jenkins only returns the value \"`+****+`\" to reduce the risk of secret information being disclosed to the console output and any logs.\nAny sensitive information in credential IDs themselves (such as usernames) are also returned as \"`+****+`\" in the Pipeline run's output.\nThis only reduces the risk of **accidental exposure**.\nIt does not prevent a malicious user from capturing the credential value by other means.\nA Pipeline that uses credentials can also disclose those credentials.\nDon't allow untrusted Pipeline jobs to use trusted credentials.\n<2> In this Pipeline example, the credentials assigned to the two `AWS_...` environment variables are scoped globally for the entire Pipeline, so these credential variables could also be used in this stage's steps.\nIf, however, the `environment` directive in this Pipeline were moved to a specific stage (as is the case in the <<#usernames-and-passwords,Usernames and passwords>> Pipeline example below), then these `AWS_...` environment variables would only be scoped to the steps in that stage.\n\nTIP: Storing static AWS keys in Jenkins credentials is not very secure.\nIf you can run Jenkins itself in AWS (at least the agent), it is preferable to use IAM roles for a link:https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[computer] or link:https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html[EKS service account].\nIt is also possible to use link:https://github.com/jenkinsci/oidc-provider-plugin#accessing-aws[web identity federation].\n\n===== Usernames and passwords\n\nThe following Pipeline code snippets show an example of how to create a Pipeline using environment variables for username and password credentials.\n\nIn this example, username and password credentials are assigned to environment variables to access a Bitbucket repository in a common account or team for your organization; these credentials would have been configured in Jenkins with the credential ID `jenkins-bitbucket-common-creds`.\n\nWhen setting the credential environment variable in the <<syntax#environment, `environment`>> directive:\n\n[source,groovy]\n----\nenvironment {\n    BITBUCKET_COMMON_CREDS = credentials('jenkins-bitbucket-common-creds')\n}\n----\n\nthis actually sets the following three environment variables:\n\n* `BITBUCKET_COMMON_CREDS` - contains a username and a password separated by a colon in the format `username:password`.\n* `BITBUCKET_COMMON_CREDS_USR` - an additional variable containing the username component only.\n* `BITBUCKET_COMMON_CREDS_PSW` - an additional variable containing the password component only.\n\n[NOTE]\n====\nBy convention, variable names for environment variables are typically specified in capital case, with individual words separated by underscores\nYou can, however, specify any legitimate variable name using lower case characters.\nBear in mind that the additional environment variables created by the `credentials()` method (above) will always be appended with `_USR` and `_PSW` (i.e. in the format of an underscore followed by three capital letters).\n====\n\nThe following code snippet shows the example Pipeline in its entirety:\n\n[pipeline]\n----\n// Declarative //\npipeline {\n    agent {\n        // Define agent details here\n    }\n    stages {\n        stage('Example stage 1') {\n            environment {\n                BITBUCKET_COMMON_CREDS = credentials('jenkins-bitbucket-common-creds')\n            }\n            steps {\n                // // <1>\n            }\n        }\n        stage('Example stage 2') {\n            steps {\n                // // <2>\n            }\n        }\n    }\n}\n// Script //\n----\n<1> The following credential environment variables (defined in this Pipeline's <<syntax#environment,`environment`>> directive) are available within this stage's steps and can be referenced using the syntax:\n* `$BITBUCKET_COMMON_CREDS`\n* `$BITBUCKET_COMMON_CREDS_USR`\n* `$BITBUCKET_COMMON_CREDS_PSW`\n\n+\nFor example, here you can authenticate to Bitbucket with the username and password assigned to these credential variables.\nTo maintain the security and anonymity of these credentials, if the job displays the value of these credential variables from within the Pipeline the same behavior described in the <<#secret-text,Secret text>> example above applies to these username and password credential variable types too.\nThis only reduces the risk of **accidental exposure**.\nIt does not prevent a malicious user from capturing the credential value by other means.\nA Pipeline that uses credentials can also disclose those credentials.\nDon't allow untrusted Pipeline jobs to use trusted credentials.\n<2> In this Pipeline example, the credentials assigned to the three `BITBUCKET_COMMON_CREDS...` environment variables are scoped only to `Example stage 1`, so these credential variables are not available for use in this `Example stage 2` stage's steps.\nIf, however, the `environment` directive in this Pipeline were moved immediately within the <<syntax#declarative-pipeline,`pipeline`>> block (as is the case in the <<#secret-text,Secret text>> Pipeline example above), then these `BITBUCKET_COMMON_CREDS...` environment variables would be scoped globally and could be used in any stage's steps.\n\n\n===== Secret files\n\nA secret file is a credential which is stored in a file and uploaded to Jenkins.\nSecret files are used for credentials that are:\n\n* too unwieldy to enter directly into Jenkins, and/or\n* in binary format, such as a GPG file.\n\nIn this example, we use a Kubernetes config file that has been configured as a secret file credential named `my-kubeconfig`.\n\n[pipeline]\n----\n// Declarative //\npipeline {\n    agent {\n        // Define agent details here\n    }\n    environment {\n        // The MY_KUBECONFIG environment variable will be assigned the value of a temporary file.\n        // For example:\n        //   /home/user/.jenkins/workspace/cred_test@tmp/secretFiles/546a5cf3-9b56-4165-a0fd-19e2afe6b31f/kubeconfig.txt\n        MY_KUBECONFIG = credentials('my-kubeconfig')\n    }\n    stages {\n        stage('Example stage 1') {\n            steps {\n                sh(\"kubectl --kubeconfig $MY_KUBECONFIG get pods\")\n            }\n        }\n    }\n}\n// Script //\n----\n\n==== For other credential types\n\nIf you need to set credentials in a Pipeline for anything other than secret text, usernames and passwords, or <<#for-secret-text-usernames-and-passwords-and-secret-files,secret files>> like SSH keys or certificates, use Jenkins' *Snippet Generator* feature, which you can access through Jenkins' classic UI.\n\nTo access the *Snippet Generator* for your Pipeline project/item:\n\n. From the Jenkins Dashboard, select the name of your Pipeline project/item.\n. In the left navigation pane, select *Pipeline Syntax* and ensure that the *Snippet Generator* option is available at the top of the navigation pane.\n. From the *Sample Step* field, choose *withCredentials: Bind credentials to variables*.\n. Under *Bindings*, click *Add* and choose from the dropdown:\n  * *SSH User Private Key* - to handle link:http://www.snailbook.com/protocols.html[SSH public/private key pair credentials], from which you can specify:\n    ** *Key File Variable* - the name of the environment variable that will be bound to these credentials.\n       Jenkins actually assigns this temporary variable to the secure location of the private key file required in the SSH public/private key pair authentication process.\n    ** *Passphrase Variable* ( _Optional_ ) - the name of the environment variable that will be bound to the link:https://tools.ietf.org/html/rfc4251#section-9.4.4[passphrase] associated with the SSH public/private key pair.\n    ** *Username Variable* ( _Optional_ ) - the name of the environment variable that will be bound to username associated with the SSH public/private key pair.\n    ** *Credentials* - choose the SSH public/private key credentials stored in Jenkins.\n       The value of this field is the credential ID, which Jenkins writes out to the generated snippet.\n  * *Certificate* - to handle link:https://tools.ietf.org/html/rfc7292[PKCS#12 certificates], from which you can specify:\n    ** *Keystore Variable* - the name of the environment variable that will be bound to these credentials.\n       Jenkins actually assigns this temporary variable to the secure location of the certificate's keystore required in the certificate authentication process.\n    ** *Password Variable* ( _Optional_ ) - the name of the environment variable that will be bound to the password associated with the certificate.\n    ** *Alias Variable* ( _Optional_ ) - the name of the environment variable that will be bound to the unique alias associated with the certificate.\n    ** *Credentials* - choose the certificate credentials stored in Jenkins.\n       The value of this field is the credential ID, which Jenkins writes out to the generated snippet.\n  * *Docker client certificate* - to handle Docker Host Certificate Authentication.\n. Click *Generate Pipeline Script* and Jenkins generates a `withCredentials(...) { ... }` Pipeline step snippet for the credentials you specified, which you can then copy and paste into your Declarative or Scripted Pipeline code. +\n  *Notes:*\n  * The *Credentials* fields (above) show the names of credentials configured in Jenkins.\n    However, these values are converted to credential IDs after clicking *Generate Pipeline Script*. [[withcredentials-script-examples]]\n  * To combine more than one credential in a single `withCredentials(...) { ... }` Pipeline step, see <<#combining-credentials-in-one-step,Combining credentials in one step>> (below) for details.\n\n*SSH User Private Key example*\n\n[source,groovy]\n----\nwithCredentials(bindings: [sshUserPrivateKey(credentialsId: 'jenkins-ssh-key-for-abc', \\\n                                             keyFileVariable: 'SSH_KEY_FOR_ABC', \\\n                                             passphraseVariable: '', \\\n                                             usernameVariable: '')]) {\n  // some block\n}\n----\nThe optional `passphraseVariable` and `usernameVariable` definitions can be deleted in your final Pipeline code.\n\n*Certificate example*\n\n[source,groovy]\n----\nwithCredentials(bindings: [certificate(aliasVariable: '', \\\n                                       credentialsId: 'jenkins-certificate-for-xyz', \\\n                                       keystoreVariable: 'CERTIFICATE_FOR_XYZ', \\\n                                       passwordVariable: 'XYZ-CERTIFICATE-PASSWORD')]) {\n  // some block\n}\n----\nThe optional `aliasVariable` and `passwordVariable` variable definitions can be deleted in your final Pipeline code.\n\nThe following code snippet shows an example Pipeline in its entirety, which implements the *SSH User Private Key* and *Certificate* snippets above:\n\n[pipeline]\n----\n// Declarative //\npipeline {\n    agent {\n        // define agent details\n    }\n    stages {\n        stage('Example stage 1') {\n            steps {\n                withCredentials(bindings: [sshUserPrivateKey(credentialsId: 'jenkins-ssh-key-for-abc', \\\n                                                             keyFileVariable: 'SSH_KEY_FOR_ABC')]) {\n                  // // <1>\n                }\n                withCredentials(bindings: [certificate(credentialsId: 'jenkins-certificate-for-xyz', \\\n                                                       keystoreVariable: 'CERTIFICATE_FOR_XYZ', \\\n                                                       passwordVariable: 'XYZ-CERTIFICATE-PASSWORD')]) {\n                  // // <2>\n                }\n            }\n        }\n        stage('Example stage 2') {\n            steps {\n                // // <3>\n            }\n        }\n    }\n}\n// Script //\n----\n<1> Within this step, you can reference the credential environment variable with the syntax `$SSH_KEY_FOR_ABC`.\nFor example, here you can authenticate to the ABC application with its configured SSH public/private key pair credentials, whose *SSH User Private Key* file is assigned to `$SSH_KEY_FOR_ABC`.\n<2> Within this step, you can reference the credential environment variable with the syntax `$CERTIFICATE_FOR_XYZ` and `$XYZ-CERTIFICATE-PASSWORD`.\nFor example, here you can authenticate to the XYZ application with its configured certificate credentials, whose *Certificate*'s keystore file and password are assigned to the variables `$CERTIFICATE_FOR_XYZ` and `$XYZ-CERTIFICATE-PASSWORD`, respectively.\n<3> In this Pipeline example, the credentials assigned to the `$SSH_KEY_FOR_ABC`, `$CERTIFICATE_FOR_XYZ` and `$XYZ-CERTIFICATE-PASSWORD` environment variables are scoped only within their respective `withCredentials( ... ) { ... }` steps, so these credential variables are not available for use in this `Example stage 2` stage's steps.\n\nTo maintain the security and anonymity of these credentials, if you attempt to retrieve the value of these credential variables from within these `withCredentials( ... ) { ... }` steps, the same behavior described in the <<#secret-text,Secret text>> example (above) applies to these SSH public/private key pair credential and certificate variable types too.\nThis only reduces the risk of **accidental exposure**.\nIt does not prevent a malicious user from capturing the credential value by other means.\nA Pipeline that uses credentials can also disclose those credentials.\nDon't allow untrusted Pipeline jobs to use trusted credentials.\n\n[NOTE]\n====\n* When using the *Sample Step* field's *withCredentials: Bind credentials to variables* option in the *Snippet Generator*, only credentials which your current Pipeline project/item has access to can be selected from any *Credentials* field's list.\nWhile you can manually write a `withCredentials( ... ) { ... }` step for your Pipeline (like the examples <<#withcredentials-script-examples,above>>), using the *Snippet Generator* is recommended to avoid specifying credentials that are out of scope for this Pipeline project/item, which when run, will make the step fail.\n* You can also use the *Snippet Generator* to generate `withCredentials( ... ) { ... }` steps to handle secret text, usernames and passwords and secret files.\nHowever, if you only need to handle these types of credentials, it is recommended you use the relevant procedure described in the section <<#for-secret-text-usernames-and-passwords-and-secret-files,above>> for improved Pipeline code readability.\n* The use of **single-quotes** instead of **double-quotes** to define the `script` (the implicit parameter to `sh`) in Groovy above.\nThe single-quotes will cause the secret to be expanded by the shell as an environment variable.\nThe double-quotes are potentially less secure as the secret is interpolated by Groovy, and so typical operating system process listings will accidentally disclose it :\n```\nnode {\n  withCredentials([string(credentialsId: 'mytoken', variable: 'TOKEN')]) {\n    sh /* WRONG! */ \"\"\"\n      set +x\n      curl -H 'Token: $TOKEN' https://some.api/\n    \"\"\"\n    sh /* CORRECT */ '''\n      set +x\n      curl -H 'Token: $TOKEN' https://some.api/\n    '''\n  }\n}\n```\n====\n\n\n===== Combining credentials in one step\n\nUsing the *Snippet Generator*, you can make multiple credentials available within a single `withCredentials( ... ) { ... }` step by doing the following:\n\n. From the Jenkins Dashboard, select the name of your Pipeline project/item.\n. In the left navigation pane, select *Pipeline Syntax* and ensure that the *Snippet Generator* option is available at the top of the navigation pane.\n. From the *Sample Step* field, choose *withCredentials: Bind credentials to variables*.\n. Click *Add* under *Bindings*.\n. Choose the credential type to add to the `withCredentials( ... ) { ... }` step from the dropdown list.\n. Specify the credential *Bindings* details.\n  Read more above these in the procedure under <<#for-other-credential-types,For other credential types>> (above).\n. Repeat from \"Click *Add* ...\" (above) for each (set of) credential/s to add to the `withCredentials( ... ) { ... }` step.\n. Select *Generate Pipeline Script* to generate the final `withCredentials( ... ) { ... }` step snippet.\n\n\n=== String interpolation\n\nJenkins Pipeline uses rules identical to link:http://groovy-lang.org[Groovy] for string interpolation.\nGroovy's String interpolation support can be confusing to many newcomers to the language.\nWhile Groovy supports declaring a string with either single quotes, or double quotes, for example:\n\n[source,groovy]\n----\ndef singlyQuoted = 'Hello'\ndef doublyQuoted = \"World\"\n----\n\nOnly the latter string will support the dollar-sign (`$`) based string\ninterpolation, for example:\n\n[source,groovy]\n----\ndef username = 'Jenkins'\necho 'Hello Mr. ${username}'\necho \"I said, Hello Mr. ${username}\"\n----\n\nWould result in:\n\n[source]\n----\nHello Mr. ${username}\nI said, Hello Mr. Jenkins\n----\n\nUnderstanding how to use string interpolation is vital for using some of\nPipeline's more advanced features.\n\n==== Interpolation of sensitive environment variables\n\n[WARNING]\n======\nGroovy string interpolation should [red]*never* be used with credentials.\n======\n\nGroovy string interpolation can leak sensitive environment variables (i.e. credentials, see: <<Handling credentials>>).\nThis is because the sensitive environment variable will be interpolated during Groovy evaluation, and the environment variable's value could be made available earlier than intended, resulting in sensitive data leaking in various contexts.\n\nFor example, consider a sensitive environment variable passed to the `sh` step.\n\n[pipeline]\n----\n// Declarative //\npipeline {\n    agent any\n    environment {\n        EXAMPLE_CREDS = credentials('example-credentials-id')\n    }\n    stages {\n        stage('Example') {\n            steps {\n                /* WRONG! */\n                sh(\"curl -u ${EXAMPLE_CREDS_USR}:${EXAMPLE_CREDS_PSW} https://example.com/\")\n            }\n        }\n    }\n}\n// Script //\n----\nShould Groovy perform the interpolation, the sensitive value will be injected directly into the arguments of the `sh` step, which among other issues, means that the literal value will be visible as an argument to the `sh` process on the agent in OS process listings.\nUsing single-quotes instead of double-quotes when referencing these sensitive environment variables prevents this type of leaking.\n\n[pipeline]\n----\n// Declarative //\npipeline {\n    agent any\n    environment {\n        EXAMPLE_CREDS = credentials('example-credentials-id')\n    }\n    stages {\n        stage('Example') {\n            steps {\n                /* CORRECT */\n                sh('curl -u $EXAMPLE_CREDS_USR:$EXAMPLE_CREDS_PSW https://example.com/')\n            }\n        }\n    }\n}\n// Script //\n----\n\n\n==== Injection via interpolation\n\n[WARNING]\n======\nGroovy string interpolation can inject rogue commands into command interpreters via special characters.\n======\n\nAnother note of caution.\nUsing Groovy string interpolation for user-controlled variables with steps that pass their arguments to command interpreters such as the `sh`, `bat`, `powershell`, or `pwsh` steps can result in problems analogous to SQL injection.\nThis occurs when a user-controlled variable (generally an environment variable, usually a parameter passed to the build) that contains special characters (e.g. `/ \\ $ & % ^ > < | ;`) is passed to the `sh`, `bat`, `powershell`, or `pwsh` steps using Groovy interpolation.\nFor a simple example:\n\n[pipeline]\n----\n// Declarative //\npipeline {\n  agent any\n  parameters {\n    string(name: 'STATEMENT', defaultValue: 'hello; ls /', description: 'What should I say?')\n  }\n  stages {\n    stage('Example') {\n      steps {\n        /* WRONG! */\n        sh(\"echo ${STATEMENT}\")\n      }\n    }\n  }\n}\n// Script //\n----\n\nIn this example, the argument to the `sh` step is evaluated by Groovy, and `STATEMENT` is interpolated directly into the argument as if `sh('echo hello; ls /')` has been written in the Pipeline.\nWhen this is processed on the agent, rather than echoing the value `hello; ls /`, it will echo `hello` then proceed to list the entire root directory of the agent.\nAny user able to control a variable interpolated by such a step would be able to make the `sh` step run arbitrary code on the agent.\nTo avoid this problem, make sure arguments to steps such as `sh` or `bat` that reference parameters or other user-controlled environment variables use single quotes to avoid Groovy interpolation.\n\n[pipeline]\n----\n// Declarative //\npipeline {\n  agent any\n  parameters {\n    string(name: 'STATEMENT', defaultValue: 'hello; ls /', description: 'What should I say?')\n  }\n  stages {\n    stage('Example') {\n      steps {\n        /* CORRECT */\n        sh('echo ${STATEMENT}')\n      }\n    }\n  }\n}\n// Script //\n----\n\nCredential mangling is another issue that can occur when credentials that contain special characters are passed to a step using Groovy interpolation.\nWhen the credential value is mangled, it is no longer valid and will no longer be masked in the console log.\n\n[pipeline]\n----\n// Declarative //\npipeline {\n  agent any\n  environment {\n    EXAMPLE_KEY = credentials('example-credentials-id') // Secret value is 'sec%ret'\n  }\n  stages {\n    stage('Example') {\n      steps {\n          /* WRONG! */\n          bat \"echo ${EXAMPLE_KEY}\"\n      }\n    }\n  }\n}\n// Script //\n----\n\nHere, the `bat` step receives `echo sec%ret` and the Windows batch shell will simply drop the `%` and print out the value `secret`.\nBecause there is a single character difference, the value `secret` will not be masked.\nThough the value is not the same as the actual credential, this is still a significant exposure of sensitive information.\nAgain, single-quotes avoids this issue.\n\n[pipeline]\n----\n// Declarative //\npipeline {\n  agent any\n  environment {\n    EXAMPLE_KEY = credentials('example-credentials-id') // Secret value is 'sec%ret'\n  }\n  stages {\n    stage('Example') {\n      steps {\n          /* CORRECT */\n          bat 'echo %EXAMPLE_KEY%'\n      }\n    }\n  }\n}\n// Script //\n----\n\n\n=== Handling parameters\n\nDeclarative Pipeline supports parameters out-of-the-box, allowing the Pipeline to accept user-specified parameters at runtime via the <<syntax#parameters, parameters directive>>.\nConfiguring parameters with Scripted Pipeline is done with the `properties` step, which can be found in the Snippet Generator.\n\nIf you configured your pipeline to accept parameters using the *Build with Parameters* option, those parameters are accessible as members of the `params` variable.\n\nAssuming that a String parameter named \"Greeting\" has been configured in the `Jenkinsfile`, it can access that parameter via `${params.Greeting}`:\n\n[pipeline]\n----\n// Declarative //\npipeline {\n    agent any\n    parameters {\n        string(name: 'Greeting', defaultValue: 'Hello', description: 'How should I greet the world?')\n    }\n    stages {\n        stage('Example') {\n            steps {\n                echo \"${params.Greeting} World!\"\n            }\n        }\n    }\n}\n// Script //\nproperties([parameters([string(defaultValue: 'Hello', description: 'How should I greet the world?', name: 'Greeting')])])\n\nnode {\n    echo \"${params.Greeting} World!\"\n}\n----\n\n\n=== Handling failure\n\nDeclarative Pipeline supports robust failure handling by default via its <<syntax#post, post section>> which allows declaring a number of different \"post conditions\" such as: `always`, `unstable`, `success`, `failure`, and `changed`.\nThe <<syntax#post, Pipeline Syntax>> section provides more detail on how to use the various post conditions.\n\n[pipeline]\n----\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Test') {\n            steps {\n                sh 'make check'\n            }\n        }\n    }\n    post {\n        always {\n            junit '**/target/*.xml'\n        }\n        failure {\n            mail to: team@example.com, subject: 'The Pipeline failed :('\n        }\n    }\n}\n// Script //\nnode {\n    /* .. snip .. */\n    stage('Test') {\n        try {\n            sh 'make check'\n        }\n        finally {\n            junit '**/target/*.xml'\n        }\n    }\n    /* .. snip .. */\n}\n----\n\n\nScripted Pipeline however relies on Groovy's built-in `try`/`catch`/`finally` semantics for handling failures during execution of the Pipeline.\n\nIn the <<test>> example above, the `sh` step was modified to never return a non-zero exit code (`sh 'make check || true'`).\nThis approach, while valid, means the following stages need to check `currentBuild.result` to know if there has been a test failure or not.\n\nAn alternative way of handling this, which preserves the early-exit behavior of failures in Pipeline, while still giving `junit` the chance to capture test reports, is to use a series of `try`/`finally` blocks:\n\n==== Error-handling steps\n\nJenkins Pipelines provide dedicated steps for flexible error handling, allowing you to control how your Pipeline responds to errors and warnings.\nThese steps help you surface errors and warnings clearly in Jenkins, giving you control over whether the Pipeline fails, continues, or simply reports a warning.\nFor more information, refer to:\n\n* link:/doc/pipeline/steps/workflow-basic-steps/#catcherror-catch-error-and-set-build-result-to-failure[catchError]\n* link:/doc/pipeline/steps/workflow-basic-steps/#error-error-signal[error]\n* link:/doc/pipeline/steps/workflow-basic-steps/#unstable-set-stage-result-to-unstable[unstable]\n* link:/doc/pipeline/steps/workflow-basic-steps/#warnerror-catch-error-and-set-build-and-stage-result-to-unstable[warnError]\n\n=== Using multiple agents\n\nIn all the previous examples, only a single agent has been used.\nThis means Jenkins will allocate an executor wherever one is available, regardless of how it is labeled or configured.\nNot only can this behavior be overridden, but Pipeline allows utilizing multiple agents in the Jenkins environment from within the _same_ `Jenkinsfile`, which can be helpful for more advanced use-cases such as executing builds/tests across multiple platforms.\n\nIn the example below, the \"Build\" stage will be performed on one agent and the built results will be reused on two subsequent agents, labelled \"linux\" and \"windows\" respectively, during the \"Test\" stage.\n\n[pipeline]\n----\n// Declarative //\npipeline {\n    agent none\n    stages {\n        stage('Build') {\n            agent any\n            steps {\n                checkout scm\n                sh 'make'\n                stash includes: '**/target/*.jar', name: 'app' // <1>\n            }\n        }\n        stage('Test on Linux') {\n            agent { // <2>\n                label 'linux'\n            }\n            steps {\n                unstash 'app' // <3>\n                sh 'make check'\n            }\n            post {\n                always {\n                    junit '**/target/*.xml'\n                }\n            }\n        }\n        stage('Test on Windows') {\n            agent {\n                label 'windows'\n            }\n            steps {\n                unstash 'app'\n                bat 'make check' // <4>\n            }\n            post {\n                always {\n                    junit '**/target/*.xml'\n                }\n            }\n        }\n    }\n}\n// Script //\nstage('Build') {\n    node {\n        checkout scm\n        sh 'make'\n        stash includes: '**/target/*.jar', name: 'app' // <1>\n    }\n}\n\nstage('Test') {\n    node('linux') { // <2>\n        checkout scm\n        try {\n            unstash 'app' // <3>\n            sh 'make check'\n        }\n        finally {\n            junit '**/target/*.xml'\n        }\n    }\n    node('windows') {\n        checkout scm\n        try {\n            unstash 'app'\n            bat 'make check' // <4>\n        }\n        finally {\n            junit '**/target/*.xml'\n        }\n    }\n}\n----\n<1> The `stash` step allows capturing files matching an inclusion pattern (`+**/target/*.jar+`) for reuse within the _same_ Pipeline.\nOnce the Pipeline has completed its execution, stashed files are deleted from the Jenkins controller.\n<2> The parameter in `agent`/`node` allows for any valid Jenkins label expression.\nConsult the <<syntax#, Pipeline Syntax>> section for more details.\n<3> `unstash` will retrieve the named \"stash\" from the Jenkins controller into the Pipeline's current workspace.\n<4> The `bat` script allows for executing batch scripts on Windows-based platforms.\n\n=== Optional step arguments\n\nPipeline follows the Groovy language convention of allowing parentheses to be omitted around method arguments.\n\nMany Pipeline steps also use the named-parameter syntax as a shorthand for creating a Map in Groovy, which uses the syntax `[key1: value1, key2: value2]`.\nMaking statements like the following functionally equivalent:\n\n[source, groovy]\n----\ngit url: 'git://example.com/amazing-project.git', branch: 'master'\ngit([url: 'git://example.com/amazing-project.git', branch: 'master'])\n----\n\nFor convenience, when calling steps taking only one parameter (or only one mandatory parameter), the parameter name may be omitted, for example:\n\n[source, groovy]\n----\nsh 'echo hello' /* short form  */\nsh([script: 'echo hello'])  /* long form */\n----\n\n\n=== Advanced Scripted Pipeline\n\nScripted Pipeline is a domain-specific language footnote:dsl[https://en.wikipedia.org/wiki/Domain-specific_language] based on Groovy, most link:http://groovy-lang.org/semantics.html[Groovy syntax] can be used in Scripted Pipeline without modification.\n\n\n==== Parallel execution\n////\nNOTE: This is only under \"Advanced Scripted Pipeline\" temporarily until some cleaner parallel syntax is supported for Declarative Pipeline.\nRight now (20170201) parallel in Declarative is indistinguishable from script { } based stuff.\n////\n\nThe example in the <<using-multiple-agents,section above>> runs tests across two different platforms in a linear series.\nIn practice, if the `make check` execution takes 30 minutes to complete, the \"Test\" stage would now take 60 minutes to complete!\n\nFortunately, Pipeline has built-in functionality for executing portions of Scripted Pipeline in parallel, implemented in the aptly named `parallel` step.\n\nRefactoring the example above to use the `parallel` step:\n\n[pipeline]\n----\n// Script //\nstage('Build') {\n    /* .. snip .. */\n}\n\nstage('Test') {\n    parallel linux: {\n        node('linux') {\n            checkout scm\n            try {\n                unstash 'app'\n                sh 'make check'\n            }\n            finally {\n                junit '**/target/*.xml'\n            }\n        }\n    },\n    windows: {\n        node('windows') {\n            /* .. snip .. */\n        }\n    }\n}\n// Declarative not yet implemented //\n----\n\nInstead of executing the tests on the \"linux\" and \"windows\" labelled nodes in series, they will now execute in parallel assuming the requisite capacity exists in the Jenkins environment.\n"
  },
  {
    "question_id": "doc_12",
    "source_file": "benchmark_data/source_files/doc_12_2023-01-12-jenkins-newsletter.txt",
    "question": "My team is migrating our Jenkins setup to use the latest official container images. According to the platform modernization update, what script has been removed from these images, what new CPU architectures are now supported, and what is the new mandatory requirement for container configuration to handle lifecycle changes?",
    "ground_truth_context": "image:/images/post-images/2023/01/12/jenkins-newsletter/recap.png[Jenkins 2022 recap Newsletter]\n\n2022 was a fruitful year for Jenkins!\nAcross the Jenkins project, we experienced growth and strong contributions.\nWe want to share deep gratitude to the corporate sponsorships and individual contributions that made it possible to take Jenkins to the next level.\nWe also look forward to welcoming new friends to collaborate with us in working together to make Jenkins even better.\nThere's still a lot to do within the project, and in 2023, we plan to integrate many more improvements, while sustaining a diversified, inclusive, and welcoming community.\n\nHappy reading!\n\nGot Inspiration?\nWe would love to highlight your cool Jenkins innovations.\nShare https://docs.google.com/forms/d/e/1FAIpQLScMCGOMtn2hGpfXsbyssGhVW1LwlW4LkXCIaKINKDQU2m6ieg/viewform[your story], and you could be in the next Jenkins newsletter.\n\n== Highlights\n\n* New board members and new officers <<elected,elected>>\n* <<modern-ui,UI modernized>> with new themes, icons, menus, forms, and buttons\n* <<platform,Java 11>> replaces Java 8 as minimum supported Java version\n* Java 17 is supported\n* <<security-fixes,Security fixes>> and security process improvements\n* <<documentation,Pipeline documentation>> improvements in both layout and content\n* Jenkins in <<outreach,Google Summer of Code 2023>> is accepting project ideas and volunteer mentors\n\n[[elected]]\nimage:/images/post-images/2023/01/12/jenkins-newsletter/governance.png[Governance Update]\n\nContributed by: author:markewaite[Mark Waite]\n\nThe Jenkins governance board thanks author:ewelinawilkosz[Ewelina Wilkosz] and author:halkeye[Gavin Mogan] for their two years of service as board members.\nWe're so glad to have talented people serving on the Jenkins governance board.\n\nDecember 2022 brought two new members to the Jenkins governance board.\n\nWe welcome author:uhafner[Dr. Ullrich Hafner] of the Department of Computer Science and Mathematics at the Munich University of Applied Sciences as a new member of the board.\nIn his role as professor, he tries to win new Jenkins contributors by letting students develop new features and test cases in their student projects and theses.\nHe has been an active contributor in the Jenkins project since 2007, mostly in https://github.com/jenkinsci/acceptance-test-harness[the acceptance test harness] and the static code analysis suite (which is now replaced by the plugin:warnings-ng[Warnings Next Generation Plugin]).\n\nimage:/images/avatars/uhafner.jpg[image,width=230,height=230]\n\nWe also welcome link:https://github.com/NotMyFault[Alexander Brandes] as a new member of the board.\nAlexander is a Jenkins Core maintainer and the maintainer of the plugin:jobConfigHistory[Job Configuration History] and plugin:ionicons-api[Ionicons API] plugins.\n\nHe is a release team member and actively involved in Jenkins Long Term Support releases and weekly releases.\nHe served as release lead for five of the twelve Jenkins LTS releases in 2022.\n\nIn addition to these two new governance board members, we welcome the new documentation officer, author:kmartens27[Kevin Martens].\nKevin leads Jenkins documentation office hours, reviews and merges documentation pull requests, and is actively involved in Jenkins Special Interest Groups.\n\nimage:/images/avatars/kmartens27.jpeg[image,width=230,height=230]\n\nWe're grateful for the Jenkins officers that are continuing their service for another year, including:\n\n* author:timja[Tim Jacomb] - Release Officer\n* author:wadeck[Wadeck Follonier] - Security Officer\n* author:dduportal[Damien Duportal] - Infrastructure Officer\n* author:alyssat[Alyssa Tong] - Events Officer\n\n[[security-fixes]]\nimage:/images/post-images/2023/01/12/jenkins-newsletter/security.png[Security Update]\n\nContributed by: author:wadeck[Wadeck Follonier]\n\nThe Jenkins security team was incredibly active this year, not only in resolving security concerns, but also providing insight to users through security advisories.\nThe information below provides overall statistics from the Security team in 2022.\n\n=== Publication\n\n* link:/security/advisories/#2022[16 Security advisories] (stable year over year).\n** Only 5 impacting Jenkins core (also stable).\n* Around 400 CVEs published, which was more than all previous years.\n\n=== Day to day:\n\n* Approximately 580 SECURITY tickets handled.\n** Which is ~20% of the total number of tickets since 2009.\n* Around 70 hosting requests proactively audited (introduced in Q2 of 2022).\n* Around 80 UI related PRs audited in Jenkins core (introduced in Q3 of 2022).\n\nWe had to deal with even more CVEs with fancy names like link:/blog/2022/03/31/spring-rce-CVE-2022-22965/[Spring4Shell].\nWe analyzed and understood them to confirm that they don't affect Jenkins.\n\n=== Delivery\n\n* General availability for the Jenkins custom rules in CodeQL (https://groups.google.com/g/jenkinsci-dev/c/OMe_zN8-Tkc/m/5Tf0OnNWAgAJ[message]).\n* Improved tooling for the SECURITY tickets handling.\n\nimage:/images/post-images/2023/01/12/jenkins-newsletter/infrastructure.png[Infrastructure Update]\n\nContributed by: author:dduportal[Damien Duportal]\n\n2022 was an eventful year for the Jenkins Infrastructure team as well, leading to various updates and improvements.\n\n* Ci.jenkins.io now has:\n** General availability for Windows 2022 server use.\n** JDK19 availability for developers, providing new functionalities and edge testing options.\n** Kubernetes has been upgraded to version 1.23 to support Azure, AWS, and DigitalOcean.\n* The link:https://jfrog.com/[JFrog] sponsored migration of link:https://repo.jenkins-ci.org/ui/[repo.jenkins-ci.org] to their new AWS platform, which provides improved performance for artifact downloads.\n* Download mirrors (link:https://get.jenkins.io/war/2.386/jenkins.war?mirrorstats[get.jenkins.io]):\n** A new download mirror for Jenkins was added in Asia. We want to thank link:https://servanamanaged.com/[Servana] for providing the mirror!\n** The mirror mirror.gruenehoelle.nl, located in the Netherlands, that had been available previously has been decommissioned.\nThank you for the service!\n\n* The Infrastructure team was also able to review and clean up unused Azure resources, leading to $1,000 of monthly savings!\n\n[[platform]]\nimage:/images/post-images/2023/01/12/jenkins-newsletter/platform-modernization.png[Platform Modernization Update]\n\nContributed by: author:gounthar[Bruno Verachten]\n\nSeveral upgrades were made to modernize the Jenkins platform.\nThese include:\n\n* Java 11 is now required for Jenkins platform and plugin development.\n** link:/blog/2022/12/14/require-java-11/[Build toolchain changes] arrived in parent pom 4.52.\n** Java 11 provides a better baseline to work from, ensuring that the benefits such as performance and memory improvements are felt across the platform.\n** Jenkins now has more Java 11 installations than Java 8 installations of Jenkins core!\n+\nimage:/images/post-images/2022-12-require-java-11/jvms.png[image,width=403,height=275]\n* Jenkins now fully supports Java 17.\n** Previously, Java 17 was only available in a preview mode, but with the LTS release of link:/changelog-stable/#v2.361.1[2.361.1], Java 17 functionality is fully available in Jenkins.\n* Migration of Linux installation packages from System V init to `systemd`.\n** Users have requested this migration since 2017.\nThe link:/blog/2022/03/25/systemd-migration/#motivation[goals of the migration] were achieved: to provide unification of service management implementation and better integration between Jenkins core and service management framework.\n** Thanks to author:basil[Basil Crow] for his work on the migration.\n* Staying on top of new backend and frontend dependency updates providing better testing, processing, and performance across Jenkins.\n* Container image updates:\n** Added new platform support, such as arm/v7 and aarch64.\n** Removed support for ppc64le.\n** Released the final, definitive version of the JDK8 containers.\n** Removed the deprecated install-plugins.sh script from Docker images.\n** There were also \"Exit\" and \"Restart\" link:/blog/2022/05/27/docker-image-new-lifecycle/[lifecycle changes] added to the Docker images. As a result, users must ensure they have a Container Restart Policy in their container.\n* The ANTLR 2 grammars and code were upgraded to ANTLR 4, making it easier for Jenkins to read and parse through various programming languages.\nThis means Jenkins core can now compile with more languages!\n** Thanks to author:slide_o_mix[Alex Earl] and author:basil[Basil Crow] for all of their hard work on completing this transition!\n** This was included in the 2.376 Jenkins weekly release.\n* Platform documentation\n** A short link:/doc/book/platform-information/support-policy-servlet-containers/[guide] about web containers and servlet container support was created.\n* Jenkins releases are now guided by release leads thanks to our release officer, author:timja[Tim Jacomb].\n2022 release leads have included:\n** link:https://github.com/timja[Tim Jacomb] - 2.361.4\n** link:https://github.com/cathychan[Cathy Chan] - 2.319.2 and 2.332.1\n** link:https://github.com/imonteroperez[Ildefonso Montero] - 2.319.3 and 2.332.2\n** link:https://github.com/krisstern[Kris Stern] - 2.361.1, 2.361.2, and 2.375.2\n** link:https://github.com/NotMyFault[Alexander Brandes] - 2.332.3, 2.346.1, 2.346.2, 2.346.3, 2.361.3, and 2.375.1\n* Platform Work In Progress:\n** For further development, experiments with RISC-V agents with JDK17/19/20 need to be performed.\n** Additional experiments with Windows 2022 server needs to be performed as well.\n\nimage:/images/post-images/2023/01/12/jenkins-newsletter/localization-simplification.png[Localization simplification Update]\n\n=== CrowdIn for plugin localization\nThanks to link:https://github.com/NotMyFault[Alexander Brandes] for helping get link:https://crowdin.com/enterprise[CrowdIn] connected with link:/doc/developer/crowdin/crowdin-integration/#setup-a-crowdin-project[Jenkins].\nThis will make the plugin localization process easier, allowing for any user to contribute to localizing plugin documentation.\nlink:https://crowdin.jenkins.io/[This page] shows the plugins that have localization work currently open.\nIt also provides some insight as to how many changes have been made and how many people have been contributing to the project.\n\nimage:/images/post-images/2023/01/12/jenkins-newsletter/jenkins-crowdin.png[Jenkins Crowdin]\n\n=== UTF-8 encoding\n\nThe Jenkins project also updated how it reads jelly files, making the transition to using UTF-8.\nThis was possible once the transition to Java 11 completed.\nBy utilizing UTF-8, developers and users can build more reliably and have modern property files read correctly.\nThis also aligns Jenkins' ability to read different types of property files, provided the encoding is the same.\n\n[[modern-ui]]\nimage:/images/post-images/2023/01/12/jenkins-newsletter/ui_ux.png[User Experience Update]\n\nContributed by: author:markewaite[Mark Waite]\n\nJenkins LTS and weekly releases in 2022 included significant user experience improvements thanks to the work of author:janfaracik[Jan Faracik], author:timja[Tim Jacomb], link:https://github.com/NotMyFault[Alexander Brandes], author:daniel-beck[Daniel Beck], and many others.\nTable layouts, menu entries, icons, themes, breadcrumbs, and more were updated to give Jenkins a new, fresh look in 2022.\n\nimage:/images/post-images/2023/01/12/jenkins-newsletter/jenkins-modern-look.png[jenkins modern look]\n\n=== Themes and icons\n\nJenkins now has much broader support for themes.\nThe plugin:dark-theme[dark theme] is now installed on over 6,000 Jenkins controllers worldwide.\nThe plugin:material-theme[material theme] is also available.\n\nThe link:/blog/2022/06/20/svg-icon-migration/[transition to scalable vector graphics (SVG) icons] improved the appearance of Jenkins icons.\nThe SVG icons are specifically selected to work well across a wide range of resolutions and across multiple themes.\n\n=== Menus and forms\n\nThe menus of configuration forms moved from the top of each configuration page to the side panel.\nThe side panel locations are more familiar for users and make better use of screen space that was previously empty.\n\n=== New look\n\nimage:/images/post-images/2023/01/12/jenkins-newsletter/jenkins-modern-look-2.png[jenkins modern look 2]\n\nThe improvements to look and feel have made Jenkins more comfortable for users and easier to navigate.\n\n=== What's next?\n\nTim Jacomb and Jan Faracik shared their ideas for further improvements to the Jenkins UI.\nWatch their DevOps World 2022 talk, link:https://www.techstrongevents.com/devops-world-2022/v/s-1130969?i=-sEhHYKccv3MgOrJkeyuyY4jp29rM6m-[\"Transformation of the Jenkins User Interface and Where It\u2019s Going Next\"] (registration required to view the video).\n\n[[documentation]]\nimage:/images/post-images/2023/01/12/jenkins-newsletter/jenkins-io-improvements.png[Jenkins io improvements Update]\n\nContributed by: author:kmartens27[Kevin Martens]\n\nThis year, the Jenkins project saw documentation contributions from new and seasoned Jenkins users.\nThese contributions included blog posts, documentation additions and updates, documentation migration, and other improvements.\nAll of this has helped expand and empower the Jenkins community.\n\nOver the year, Jenkins project saw 48 blog posts, submitted by 23 different authors.\nThere were 814 contributions throughout 2022.\nThese contributions are a result of the community and collaboration with various projects throughout the year, such as link:/blog/2022/04/11/She-Code-Africa-contributhon/[She Code Africa Contributhon], link:/blog/2022/10/31/jenkins-google-summer-of-code-archive-2022/[Google Summer of Code], and link:/blog/2022/11/17/hacktoberfest-recap/[Hacktoberfest].\nOur deepest gratitude and appreciation go out to all Jenkins contributors and the open-source community beyond.\n\n=== Pipeline Steps Reference\n\nThanks to the work of author:vihaanthora[Vihaan Thora], contributing via link:/blog/2022/10/10/pipeline-steps-improvement-gsoc-report/#project-specific-guidance[Google Summer of Code], the link:/doc/pipeline/steps/[Pipeline Steps] reference page provides simplified search for Pipeline steps.\nThe reference page is invaluable for developers when working in Jenkins and utilizing plugins.\nThe updates include search functionality, UI improvements, and faster page loading.\n\nimage:/images/post-images/2023/01/12/jenkins-newsletter/image5.png[image,width=624,height=388]\n\n=== Algolia search\n\nimage:/images/post-images/2023/01/12/jenkins-newsletter/image6.png[image,width=275,height=52]\n\nThe Jenkins documentation site search has been updated to use the latest version of https://www.algolia.com/[Algolia].\nWe recognize and thank author:halkeye[Gavin Mogan] for his work on site search and on the link:https://plugins.jenkins.io[plugins site].\nWe thank link:https://algolia.com[Algolia] for donating the search functionality.\nThe site search now provides more relevant results and suggestions for users.\nA visual update was included as part of the upgrade, resulting in the new look and feel.\n\nimage:/images/post-images/2023/01/12/jenkins-newsletter/image7.png[image,width=363,height=317]\n\n[[outreach]]\nimage:/images/post-images/2023/01/12/jenkins-newsletter/outreach-and-advocacy.png[Outreach and advocacy Update]\n\nContributed by: author:alyssat[Alyssa Tong]\n\nIn 2022, the Jenkins project was able to collaborate on and complete several projects.\nThis included launching two new sites for community engagement and involvement:\n\n* link:https://community.jenkins.io/[community.jenkins.io] now provides a space for community discourse and communication.\n* link:https://stories.jenkins.io/[stories.jenkins.io] is a site dedicated to sharing the experiences and stories of Jenkins users, developers, and contributors that Jenkins has impacted.\n\nThroughout the year, the Jenkins project participated in:\n\n* link:/sigs/gsoc/[Google Summer of Code 2022]\n* link:/blog/2022/04/11/She-Code-Africa-contributhon/[She Code Africa Contributhon 2022]\n* link:/events/hacktoberfest/[Hacktoberfest 2022]\n\nWe collaborated with new Jenkins users all over the globe, improved many areas of Jenkins, and celebrated the successes of the community!\n\nThe Jenkins project is also excited to share what's to come in 2023:\n\n* Jenkins in GSoC 2023 : link:/projects/gsoc/2023/project-ideas/[Call for Project Ideas] + link:/blog/2022/12/09/GSoC-the-gift-of-mentorship/[Call for Mentors].\n** link:https://www.youtube.com/watch?v=k_sTkGtTix8[A Guide to Better Preparations] is a great resource for potential GSoC candidates, who want to get started and increase their chance of getting accepted into the program.\n* https://fosdem.org/2023/[FOSDEM'23]: Jenkins will have a devstand at FOSDEM (Feb 4-5, 2023).\n* https://www.socallinuxexpo.org/scale/20x[SCALE 20x]: Jenkins will have a booth presence at SCALE (March 9-12, 2023).\n\nFinally, we want to link:/blog/2022/11/24/jenkins-sponsor-appreciation/[thank our partners and sponsors] over the year, as so much of this is possible with the help of their contributions.\n"
  },
  {
    "question_id": "doc_13",
    "source_file": "benchmark_data/source_files/doc_13_2016-05-26-introducing-blue-ocean.txt",
    "question": "As a plugin developer, I want to build a plugin with a modern, responsive UI that integrates with Blue Ocean. Based on the provided text, what specific web technology is mentioned that allows my plugin's UI to update in real time based on server state changes, and what three modern JavaScript technologies does the extended plugin toolchain support?",
    "ground_truth_context": "In recent years developers have become rapidly attracted to tools that are not\nonly functional but are designed to fit into their workflow seamlessly and are\na joy to use. This shift represents a higher standard of design and user\nexperience that Jenkins needs to rise to meet.\n\nWe are excited to share and invite the community to join us on a project we\u2019ve\nbeen thinking about over the last few months called Blue Ocean.\n\nBlue Ocean is a project that rethinks the user experience of Jenkins, modelling\nand presenting the process of software delivery by surfacing information that's\nimportant to development teams with as few clicks as possible, while still\nstaying true to the extensibility that is core to Jenkins.\n\nimage:/images/post-images/blueocean/pipeline-run.png[Pipeline execution, role=center]\n\n\nWhile this project is in the alpha stage of development, the intent is that\nJenkins users can install Blue Ocean side-by-side with the Jenkins Classic UI\nvia a plugin.\n\nNot all the features listed on this blog are complete but we will be hard at\nwork over the next few months preparing Blue Ocean for general use. We intend\nto provide regular updates on this blog as progress is made.\n\nBlue Ocean is link:https://github.com/cloudbees/blueocean[open source today]\nand we invite you to give us feedback and to contribute to the project.\n\n++++\n<center>\n<iframe width=\"853\" height=\"480\"\nsrc=\"https://www.youtube-nocookie.com/embed/3dITffteCD4?rel=0\" frameborder=\"0\"\nallowfullscreen></iframe>\n</center>\n++++\n\n\nBlue Ocean will provide development teams:\n\n\n==== New modern user experience\n\nThe UI aims to improve clarity, reduce clutter and navigational depth to make\nthe user experience very concise. A modern visual design gives developers much\nneeded relief throughout their daily usage and screens respond instantly to\nchanges on the server making manual page refreshes a thing of the past.\n\nimage:/images/post-images/blueocean/pipeline-dashboard.png[Project dashboard, role=center]\n\n\n==== Advanced Pipeline visualisations with built-in failure diagnosis\n\nlink:/solutions/pipeline[Pipelines] are visualised on screen along with the\nsteps and logs to allow simplified comprehension of the continuous delivery\npipeline \u2013 from the simple to the most sophisticated scenarios.\n\nScrolling through 10,000 line log files is a thing of the past. Blue Ocean\nbreaks down your log per step and calls out where your build failed.\n\nimage:/images/post-images/blueocean/failing-pipeline.png[Failing Pipeline, role=center]\n\n==== Branch and Pull Request awareness\n\nModern pipelines make use of multiple Git branches, and Blue Ocean is designed\nwith this in mind. Drop a link:/doc/pipeline[`Jenkinsfile` into your Git\nrepository] that defines your pipeline and Jenkins will automatically discover\nand start automating any \u00a0Branches and validating Pull Requests.\n\nJenkins will report the status of your pipeline right inside Github or\nBitbucket on all your commits, branches or pull requests.\n\nimage:/images/post-images/blueocean/pr-view.png[Pull request view, role=center]\n\n\n==== Personalised View\n\nFavourite any pipelines, branches or pull requests and see them appear on your\npersonalised dashboard. Intelligence is being built into the dashboard. Jobs\nthat need your attention, say a Pipeline waiting for approval or a failing job\nthat you have recently changed, appear on the top of the dashboard.\n\n\nimage:/images/post-images/blueocean/personalized-dashboard.png[Personalized dashboard, role=center]\n\n\nYou can read more about Blue Ocean and its goals on the\nlink:/projects/blueocean[project page] and developers should watch the\nlink:/content/mailing-lists[Developers list] for more information.\n\n---\n\nFor Jenkins developers and plugin authors:\n\n==== Jenkins Design \u201cLanguage\u201d\n\nThe Jenkins Design Language (JDL) is a set of standardised React components and\na style guide that help developers create plugins that retain the look and feel\nof Blue Ocean in an effortless way. We will be publishing more on the JDL,\nincluding the style guide and developer documentation, over the next few weeks.\n\n==== Modern JavaScript toolchain\n\nThe Jenkins plugin tool chain has been extended so that developers can use\nlink:https://medium.com/@rajaraodv/5-javascript-bad-parts-that-are-fixed-in-es6-c7c45d44fd81[ES6],\nlink:https://facebook.github.io/react/[React], link:https://www.npmjs.com/[NPM]\nin their plugins without endless yak-shaving. Jenkins\nlink:https://github.com/jenkinsci/js-modules[js-modules] are already in use in\nJenkins today, and this builds on this, using the same tooling.\n\n==== Client side Extension points\n\nClient Side plugins use Jenkins plugin infrastructure. The Blue Ocean libraries\nbuilt on ES6 and React.js provide an extensible client side component model\nthat looks familiar to developers who have built Jenkins plugins before. Client\nside extension points can help isolate failure, so one bad plugin doesn\u2019t take\na whole page down.\n\n==== Server Sent Events\n\nlink:https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events[Server Sent Events]\n(SSE) allow plugin developers to tap into changes of state on the server and make\ntheir UI update in real time (link:https://www.youtube.com/watch?v=EttzK5OOpv0[watch this for a\ndemo]).\n\n---\n\nTo make Blue Ocean a success, we're asking for help and support from Jenkins\ndevelopers and plugin authors. Please join in our Blue Ocean discussions on the\nlink:https://groups.google.com/g/jenkinsci-dev[Jenkins Developer\nmailing list] and the `#jenkins-ux` IRC channel on Freenode!\n\n\n== Links\n\n* link:/projects/blueocean[Blue Ocean project page]\n* link:https://github.com/cloudbees/blueocean[Blue Ocean GitHub repository]\n"
  },
  {
    "question_id": "doc_14",
    "source_file": "benchmark_data/source_files/doc_14_gitlab-support-for-multibranch-pipeline.txt",
    "question": "I'm trying to understand the new Merge Request handling in the GitLab plugins. Based on the project plan, what was the original limitation with fetching Merge Requests in the old plugin, and what specific new features were introduced in Phase 3 to fix webhook triggers, manage permissions for forked repositories, and allow builds to be triggered by comments?",
    "ground_truth_context": "Currently GitLab Plugin does not support Multibranch Pipeline jobs. The underlying API does\nnot implement calls to fetch Merge Requests during builds. Other problems with this plugin is\ndoesn't follow conventional SCM plugin design, doesn't support folder org, doesn't have separate\napi plugin etc. So this project is about solving issues with the GitLab Jenkins Integration by\nimproving the current GitLab Plugin and creating separate plugins for GitLab Api and GitLab\nBranch Source. One stretch goal is to add GitLab Pipeline support for Blueocean.\n\n=== Issues\n* No folder organisation support for GitLab\n* No Multibranch Pipeline Job support for GitLab\n* GitLab APIs currently used does not have all GitLab APIs features and limits the scope of future expansion\n* GitLab Plugin does not follow convention of SCM Plugins i.e. 3 separate plugins for api, build and branch Source\n* GitLab Plugin also does not leverage new SCM trait APIs, some features like auto-management of webhooks, password authentication are missing\n* No Pipeline Support for GitLab in Blueocean while GitHub and BitBucket are supported\n\n=== Solutions\n\n* [NEW] GitLab Api Plugin that wraps new GitLab Java Api repository which is actively maintained and has almost all GitLab Apis support\n* [NEW] GitLab Branch Source Plugin that supports Branch Source Functionality like Github BS, Bitbucket BS etc\n* [IMPROVED] GitLab Plugin that is lightweight and provides build triggers, web hooks management and other API support\n* [NEW] Pipeline Support for GitLab in Blueocean\n\nFor more details, see this Google Doc - https://docs.google.com/document/d/1YpuCC129U8KPXAwiXRXQ_4XWuLursPGl3rzQjz43-CY/edit?usp=sharing[Proposal]\n\n=== Evaluation Phase 1\n\n  . Complete implementation with documentation and plugin release of `GitLab API Plugin` that wraps the https://github.com/gmessner/gitlab4j-api/[gitlab4j-api] into a plugin +\n  - Wiki -  https://wiki.jenkins.io/display/JENKINS/GitLab+API+Plugin\n  - Repo - https://github.com/jenkinsci/gitlab-api-plugin\n  . Implementation of GitLab Server Configuration in `GitLab Branch Source Plugin` with JCasC support. The implementation was done inside the plugin to support new `GitLab API Plugin` and also use Java 8 streams.\n  - Features:\n  ** GitLab Personal Access Token Creator \n  ** Allows duplicate GitLab server entries with unique id\n  ** Supports GitLab Server versions above 11.0\n  ** Configure server via yaml (JCasC)\n  ** Supports GitLab API Plugin - abstracts api calls\n  ** Supports incremental tools - check if PRs work with downstream plugins\n  ** Supports Maven Checkstyle Plugin - enforces good coding style \n  ** Java 8 compatibility - streams API\n  ** Jenkins version - 2.150.3\n  ** 3 enhancement and fix release\n  - Repo - https://github.com/baymac/gitlab-branch-source-plugin\n\n==== Resources\n\n  . Blogs\n  - link:/blog/2019/06/29/phase-1-multibranch-pipeline-support-for-gitlab/[Coding phase 1 summary]\n  - https://baymac.github.io/2019/06/gsoc-coding-period-the-fourth-week[Fourth week]\n  - https://baymac.github.io/2019/06/gsoc-coding-period-the-mock-presentation-week[Third week]\n  - https://baymac.github.io/2019/06/gsoc-coding-period-the-second-week[Second week]\n  - https://baymac.github.io/2019/06/gsoc-coding-period-the-beginning[First week]\n  - https://baymac.github.io/2019/05/project-workflow-for-gsoc[Project workflow for GSoC]\n  - https://baymac.github.io/2019/03/intellij-setup-for-plugin-development[IntelliJ setup for Jenkins Plugin Development]\n  . Slides: https://drive.google.com/file/d/1c3UWwEb5rDmO6YEn5fU3qVbVW-opuUXb/view\n  . Demo: https://www.youtube.com/watch?v=ij6ByZqI67o\n\n=== Evaluation Phase 2\n\n  . Implementation of Branch Source part of `GitLab Branch Source Plugin` with Multibranch Pipeline and Folder Organization support.\n  - Features:\n  ** Checkout credentials to checkout over SSH/HTTPS\n  ** Groups/Subgroups support\n  ** Webhooks Support\n  ** Pipeline Status Notifier\n  ** Skip Notification - Doesn\u2019t notify GitLab about pipeline status [Trait]\n  ** WebHook Mode - Override default webhook management mode [Trait]\n  ** Checkout Over SSH - Use this mode to checkout over ssh [Trait]\n  ** Tag Discovery - Discover tags in the repository [Trait]\n  ** Reduced API Calls\n  ** 2 Alpha releases\n  - Repo - https://github.com/jenkinsci/gitlab-branch-source-plugin\n  - Wiki - https://wiki.jenkins.io/display/JENKINS/GitLab+Branch+Source+Plugin\n\n==== Resources\n\n  . Blogs\n  - https://baymac.github.io/2019/07/gsoc-coding-period-plugin-release-week[Ninth week]\n  - https://baymac.github.io/2019/07/gsoc-coding-period-plugin-hosting-week[Seventh week]\n  - https://baymac.github.io/2019/07/gsoc-coding-period-the-sixth-week[Sixth week]\n  - https://baymac.github.io/2019/06/gsoc-coding-period-the-presentation-week[Fifth week]\n  . Slides: https://docs.google.com/presentation/d/1fMiDiLi3L39hoaFz-qLLhWQXwb1U9864_Per3vTc1dk/edit?usp=sharing\n  . Demo: https://www.youtube.com/watch?v=tnoObQqGhyM\n\n=== Evaluation Phase 3\n\n  . Improvements to GitLab Branch Source Plugin, lots of improvements including major bugs fixes. Complete documentation in the repository documents.\n  - Features:\n  ** Web hook events trigger for Push/Merge Request/Tag Events fixed\n  ** Trusted Permission Strategy for MRs from forked projects\n  ** Add support for System Hooks to detect newly created projects\n  ** Add symbols to discovery traits for JCasC support\n  ** Merge Requests web hook trigger fix\n  ** Trigger Merge Request with comment trait\n  ** Log build status as comment trait\n  ** 3 beta releases and 1 GA release\n\n==== Resources\n\n  . Blogs\n  - link:/blog/2019/08/23/introducing-gitlab-branch-source-plugin/[Coding phase 3 summary]\n  - https://baymac.github.io/2019/07/gsoc-coding-period-second-presentation-week[Ninth Week]\n\n=== Meeting Schedule\n\n  * Weekdays - Tuesday and Friday\n  * Time - 04:00pm (UTC)\n\n=== Other links\n\nhttps://drive.google.com/file/d/1tk_8221juDRF2-k2hByYt4LdztNtcZtm/view[GSoC Proposal] +\nhttps://docs.google.com/document/d/12sICOnFXJXHEkqWV8yq6dy_ZcVs-5gL_zeDae8gnWdo/edit?usp=sharing[Daily Notes] +\nhttps://docs.google.com/document/d/12elprUjiou80z2W7SSbNTZiyguJ6LEj4Z718MdoA2_c/edit?usp=sharing[GSoC Process] +\nhttps://docs.google.com/document/d/1r_zQy5KpNNAO4KerFJrowWvGfFIU7xdEdqKgFenS3lI/edit?usp=sharing[Design Document] +\n"
  },
  {
    "question_id": "doc_15",
    "source_file": "benchmark_data/source_files/doc_15_2013-09-09-loader-io-plugin-developer-interview.txt",
    "question": "To enhance user experience and functionality, the developers of the loader.io plugin made specific implementation choices. How did they solve the problem of managing credentials for multiple environments and builds, and what unique feature did they create to provide a deep view into an application's performance over time?",
    "ground_truth_context": "'''''\n\n\nimage:https://jenkins-ci.org/sites/default/files/images/loaderio.png[image,width=150,height=150] +\n\n\n*Q: Tell us a bit about what your service and plugin do. Who is it for? What are the highlights of your plugin?* +\n\nA: https://loader.io[Loader.io] is a simple-to-use cloud-based load testing service. The service is designed for developers and people who need to ensure applications are performing as they should. It allows developers to perform large-scale load tests on demand, which lets them understand the scalability and performance of their applications. We realize Jenkins is the preferred build service for a lot of our users, and we know providing a way for them to implement, measure and improve application performance during the continuous build cycle is important. So we wrote a Jenkins plugin that allows load testing to be brought into the continuous build and deployment process with ease. +\n\n* +\nQ: Did you have to convince your boss/lawyers to open-source your plugin? What was the pitch?* +\n\nA: No, at SendGrid our focus is always to help make developers\u2019 lives easier, and when we can, we like to provide tools that they can hack on. Since the Jenkins platform is itself an open source project, following the same model to provide our plugin made perfect sense. In addition, we encourage others to build on our work, help improve it and ultimately make it better for everyone using it. +\n\n* +\nQ: How did you learn how to write a plugin? +\n* +\n\nA: We use the Jenkins platform ourselves, and we leverage a number of the plugins available. Having access to these and the Jenkins documentation gave us a great head start. It was an easy decision to write the Jenkins plugin for loader.io, and the Jenkins community provided both detailed instructions as well as support when we needed it. +\n\n* +\nQ: Any gotchas in the experience of developing a plugin that you want to share? +\n*\n\nA: The overall process of developing the plugin was straightforward and simple, but we did run into some scope creep in the middle of the dev process. We found that since the platform was so easy to write for, it made us keep adding more and more features. Usually this is good, but in the case of our project, we wanted to provide the most value as quickly as possible. So we scaled back, focused on solid execution for the most important features, and are already preparing to launch a new version with the things we reserved for post v1 availability. +\n\n* +\nQ: What is the reaction from users so far? +\n* +\n\nA: The users we\u2019ve spoken with love the plugin. In addition we\u2019ve already gotten great feedback from some community members on \u201cnice to have\u2019s\u201d in the plugin, some of which we\u2019re already working on. +\n\n* +\nQ: What tips do you share to those who are interested in writing plugins? +\n* +\n\nA: If you have a service that provides value in the build, deployment and post deployment process, then you should be writing a Jenkins plugin. Two things are important for anyone writing a plugin: 1) be sure the plugin you\u2019re writing is going to provide true value (if you need it yourself this is a good sign), and 2) make sure you understand the scope of the project and deliver core features and value first, then focus on some extra things. Providing a valuable plugin sooner than later will help you identify all the right additional features to include, especially when collecting live community feedback. +\n\nSome of the things we focused on early in the process were to identify the core features, and more importantly to make it very easy for users of Jenkins to install, use and interpret the loader.io plugin and results. We wanted to allow users to leverage our plugin for multiple environments and builds with system and global credentials. To do this, we decided to make use of the Credentials plugin (https://wiki.jenkins.io/display/JENKINS/Credentials+Plugin), which is a heavily-adopted plugin that provides a standardized API for plugins to store and retrieve credentials. This plugin allows our users to add and use different credentials in one single Jenkins environment. In addition, we created a new re-run feature which, when used with continuous build and testing, provides a deep view into the performance of an application over time. Finally, we wanted to bring the same UI experience users have in our environment into Jenkins, which we did by preserving the load test report model and making it function the same in the Jenkins UI. Doing this makes it easy for users to have consistency between the UIs and more easily understand the results regardless of where they\u2019re viewing them. +\n\nIt\u2019s very easy to write a Jenkins plugin - I hope these insights will encourage you to write your own. +\n\nps - We\u2019d love your feedback too. Check out our newly-released https://wiki.jenkins.io/display/JENKINS/loaderio[Jenkins plugin] for loader.io and let us know what you think.\n"
  },
  {
    "question_id": "doc_16",
    "source_file": "benchmark_data/source_files/doc_16_2017-03-21-toulousejam-pipeline-workshop.txt",
    "question": "I'm planning a workshop that requires provisioning numerous VMs for attendees and also relies on external sponsorships. Based on the \"Conclusion\" section of the document, what specific infrastructure problem related to cloud provider limits was encountered during the event, and what is the minimum recommended lead time to plan for when seeking answers from potential sponsors?",
    "ground_truth_context": "\nEarlier this month, a full-day event about Jenkins Pipeline was organized in link:https://www.google.fr/maps/place/Toulouse/@43.6006786,1.3628012,12z/data=!3m1!4b1!4m5!3m4!1s0x12aebb6fec7552ff:0x406f69c2f411030!8m2!3d43.604652!4d1.444209[Toulouse, France] with the link:https://www.meetup.com/fr-FR/Toulouse-Jenkins-Area-Meetup/events/237089783/[Toulouse JAM].\n\nAfter a warm-up on the previous Tuesday where Micha\u00ebl Pailloncy had given a talk at the local link:https://www.meetup.com/fr-FR/Toulouse-DevOps/events/237859268/[Toulouse Devops user group about Jenkins Pipeline ecosystem], we were ready for more digging :-).\n\nimage:workshop-overview-1.jpg[width=\"30%\"]\nimage:workshop-overview-2.jpg[width=\"30%\"]\nimage:workshop-overview-3.jpg[width=\"30%\"]\n\n== The agenda\n\nWe had planned the day in two parts:\n\n* Morning would be a more driven workshop with slides & exercises to be completed\n* Pizzas & beverages to split the day :-)\n* Afternoon would be somehow like an link:https://en.wikipedia.org/wiki/Unconference[Unconference], where people basically decide by themselves what they want to work on.\n\nWe planned to have 30 attendees. We ended up having 25.\nWe considered having more people, but finally decided that for a first time it would be better to start not too big.\n\n== Infrastructure\n\nInfrastructure was sponsored by link:https://www.digitalocean.com/[DigitalOcean].\n\nFor each attendee, link:https://github.com/ToulouseJAM/jam-workshop-infra[we provisioned]:\n\n* One Controller, preconfigured to be able to dynamically provision agents.\n* One staging _environment_\n* One production _environment_\nfootnote:[For the sake of the simplicity of the workshop, those _environments_ were actually a single VM: the goal was here to illustrate what we could do using Jenkins Pipeline, discussing scalability or more involved deployment techniques was obviously out of scope.]\n* One SonarQube instance\n\n== Workshop content & infrastructure\n\nAfter an initial quick link:https://docs.google.com/presentation/d/1FKkraQdr4oxRephVnItUmOUe9pBeC0dRfZXCxqoubg0/edit[presentation to settle context and remind some general things about Continuous Delivery and Jenkins], we started the workshop per se.\n\nIt is composed of 3 parts, link:https://github.com/ToulouseJAM/workshop-resources[which are readable here] footnote:[in French only for now, but translating it into English to make it possibly shared and reusable among JAMs is being discussed], but very few people were able to start the part 3.\n\n== Hackergarten / Unconference\n\nSo we let people decide what they wanted to work on during the afternoon.\n\nimage:subdividing-per-interest.jpg[role=\"right\",width=\"50%\"] We decided to use post-its: each attendee would write down what they wanted to work on, one idea per post-it (max 2 per person).\nThen, we dropped those onto a white-board and tried grouping those by theme.\n\nIn the end, overall, the following themes went out:\n\n* Hack on Jenkins development & Contribute to Jenkins\n* Complete the workshops\n* Work on use-case oriented things\n* Work on Docker & Pipeline join usages\n\n=== Hackergarten\n\nimage:hackergarten.jpg[role=right,width=40%]\n\nMany link:https://accounts.jenkins.io/[Jenkins accounts] were created, and many JIRA and pull requests were filed.\nIt was nice to see people asking questions like: \"so, should I create a JIRA issue for this?\" or \"how do I interact with people\".\nPretty generic \"how do I work on open source software\" questions sometimes, but important because you felt like people were genuinely interested and needed not much to start contributing.\n\nHere are the pull requests filed during this afternoon:\n\n* link:https://github.com/jenkinsci/blueocean-pipeline-editor-plugin/pull/30[blueocean-pipeline-editor-plugin#30]\n* link:https://github.com/jenkinsci/jenkins/pull/2785/[jenkins#2785]\n* link:https://github.com/jenkinsci/jenkins/pull/2786/[jenkins#2786]\n* link:https://github.com/jenkinsci/jenkins/pull/2787/[jenkins#2787]\n* link:https://github.com/jenkinsci/jenkins/pull/2788/[jenkins#2788]\n\nYou can see that though most of the PRs were typo-related, the one that got merged first was the one about code :-).\n\nimage:bobblehead.jpg[role=right,width=30%] So, link:https://github.com/jviolas[Jeremie Violas] wins the Bobble Head as link:https://twitter.com/toulousejam/status/839606221338464256[promised]!\n\n==== Why so many typo-related PRs?\n\nSimply because people were somehow encouraged to find some to get used to the\nround trip of: fixing an issue and filing the associated pull request, rinse &\nrepeat.\n\nI do think this is also a pretty nice and simple first step to understand how\nto build Jenkins and start interacting with the community.\n\n== The result\n\nPeople seemed pretty happy and we got some nice comments like \"now I have a clearer vision of what this Pipeline thing is about\".\nSome attendees also dropped nice comments on the meetup page.\nSo it's cool because when you're doing such things on your free time, it's the main reward you can get.\n\nIf you're an attendee to such events, don't forget to thank people organizing\nthose, and more importantly to provide constructive feedback.  We are generally\neager to know what could be done better for next time.\n\n== Conclusion\n\nOverall we are very happy with the energy of that day, and we definitely plan to set up a new session in the next few months, probably with a bit more people.\n\nSome thoughts:\n\n* Infrastructure: when you plan to have many VM per attendee, double-check the limits your Cloud Provider may have by default. I had bumped it to 250 the day before the workshop, and asked for another one to 500 *during* the workshop (though in the end, 250 was probably enough, but this'll give room for the next time with more people :-)).\n\n* Logistics: warning, secret ahead: this is very time consuming.\nNot necessarily the amount of work itself, more that it implies very big latency.\nFor instance, give it 2 to 3 weeks minimum to have answers about sponsoring in general. Pinging again in case of no answer after 2 days would probably be seen as rude, and possibly lead to make things worse for obvious reasons, so plan ahead.\n\n== Thank you\n\n* link:https://www.digitalocean.com[DigitalOcean] for sponsoring the Infrastructure\n** We got way more than 100 VMs running at the same time during the day thanks to their help!\n* link:https://www.harrycow.com/[HarryCow Coworking] for hosting the event\n* To link:https://www.cloudbees.com/[CloudBees] for sponsoring the food for all the participants\n** Also for providing a bunch of goodies: stickers and T-Shirts for everybody\n* link:https://github.com/[GitHub] for providing stickers\n"
  },
  {
    "question_id": "doc_17",
    "source_file": "benchmark_data/source_files/doc_17_2-222-1.txt",
    "question": "I ran the script `hudson.security.csrf.GlobalCrumbIssuerConfiguration.DISABLE_CSRF_PROTECTION = true` in the Jenkins script console to allow disabling CSRF protection, but the setting didn't change. What final step is required to apply this change and modify the crumb issuer configuration?",
    "ground_truth_context": "==== Global build discarder configuration lost on restart\n\nThe global build discarder configuration is saved when the administrator modifies it, but is not loaded when Jenkins restarts.\nThe default global build discarder configuration is used when Jenkins restarts.\n\nOn every restart, Jenkins 2.222.1 will start with the default build discarder configured.\nThat means:\n\n* Any custom global build discarder configuration is lost on restart\n* Users who don't want background build discarders get the default one\n\n==== Old builds may be deleted by global build discarders\n\nJenkins will by default periodically run build discarders configured in projects, even when no builds are currently running.\n**This may delete old builds of projects that have been configured with a more aggressive build discarder configuration since the last build was run.**\n\nWe recommend reviewing project configurations for aggressive build discarder settings before upgrading Jenkins if this change in behavior could result in unexpected data loss.\n\nNOTE: We recommend creating backups of your Jenkins configuration and data regularly.\n\n\n\n==== Always enabled CSRF Protection\n\nJenkins will automatically enable CSRF protection with the default crumb issuer if it was disabled before.\nThe ability to not have CSRF protection enabled has been deprecated and removed from the UI.\n\nAPI clients should authenticate using API tokens, which doesn't require CSRF crumbs since 2.96.\n\nSet the system property `hudson.security.csrf.GlobalCrumbIssuerConfiguration.DISABLE_CSRF_PROTECTION` to `true` on startup to disable CSRF protection as well as the configuration UI for it.\nThis is an unsupported option and may be removed in the future.\n\nWhile Jenkins is running, the configuration UI can be locked/unlocked by running one of the following commands in the script console:\n\n----\n// to allow disabling\nhudson.security.csrf.GlobalCrumbIssuerConfiguration.DISABLE_CSRF_PROTECTION = true\n\n// to force enabled\nhudson.security.csrf.GlobalCrumbIssuerConfiguration.DISABLE_CSRF_PROTECTION = false\n----\n\nThis will not immediately change the configured crumb issuer; the _Configure Global Security_ form must be submitted once to change the setting accordingly.\n\n\n\n==== Removed agent protocols\n\n_Inbound TCP Agent Protocol_ versions 1, 2, and 3 (also known as _JNLP Protocols_ or _Java Web Start Protocols_) have been removed.\nThese protocols have been deprecated link:/blog/2017/08/11/remoting-update/[since Jenkins 2.75 in 2017].\n\nplugin:ssh-slaves[SSH Build Agents Plugin] uses the latest `agent.jar`, but other agent types may need to have their `agent.jar` updated manually.\n//The following agent types should be updated:\n//\n//TODO Oleg to rewrite\n//TODO Oleg to rewrite\n\n\n\n==== Redesigned password form field\n\nTo reduce the number of times that browser password auto-fill will inappropriately fill in saved credentials, the password form fields used in Jenkins configuration forms have been redesigned.\nIn case this change causes problems, it can be reverted by setting the system property `hudson.Functions.hidingPasswordFields` to `true`.\n\n\n\n==== Dangerous permissions deprecation\n\nlink:https://github.com/jenkinsci/jep/blob/master/jep/223/README.adoc[JEP-223], link:https://issues.jenkins.io/browse/JENKINS-60266[JENKINS-60266]\n\nIn 2017 the `Overall/RunScripts`, `Overall/UploadPlugins`, and `Overall/ConfigureUpdateCenter` were announced as potentially dangerous permissions and hidden from view in plugin:matrix-auth[Matrix Authorization Plugin] and plugin:role-strategy[Role-based Strategy Plugin] to prevent accidental misconfigurations (link:/security/advisory/2017-04-10/#matrix-authorization-strategy-plugin-allowed-configuring-dangerous-permissions[2017-04-10 security advisory]).\n\nThese permissions are now deprecated and no longer used in Jenkins core.\nConfigurations which grant any of these permissions while not granting `Overall/Administer` will no longer work as before, as Jenkins now requires `Overall/Administer` permission for features previously governed by these permissions.\nCustom authorization strategies that grant `Overall/Administer` without implying one or more of those permissions will no longer work as expected as a result.\nPlugins are also expected to switch from requiring these deprecated permissions to requiring `Overall/Administer` instead, resulting in further unexpected behavior changes in these configurations.\n\n\n==== Remove network discovery services \n\nhttps://issues.jenkins.io/browse/JENKINS-33596[JENKINS-33596], https://issues.jenkins.io/browse/JENKINS-60913[JENKINS-60913]\n\nNetwork discovery features, DNS multicast and UDP broadcast, were previously disabled and discouraged because of various problems, including link:/security/advisory/2020-01-29/#SECURITY-1641[SECURITY-1641 in Jenkins Security Advisory 2020-01-29].\nThey have now been removed without replacement.\n\nplugin:swarm[Swarm Plugin] needs to be updated to version 3.18 or above, otherwise the error described in https://issues.jenkins.io/browse/JENKINS-61029[JENKINS-61029] occurs. This also removes the network discovery capability of the plugin.\n\n\n\n==== Header and Breadcrumb Layout Improvements\n\nlink:https://github.com/jenkinsci/jenkins/pull/4463[PR-4463], link:https://issues.jenkins.io/browse/JENKINS-60920[JENKINS-60920]\n\nInstances with plugins that depend on specific details of the Jenkins UI (like plugin:simple-theme-plugin[Simple Theme plugin]) may experience issues with this release and may need to be updated.\nIn the case of the Simple Theme plugin, theme maintainers may need to adapt the theme to the UI changes.\n\n\n\n==== Removal of jenkins-slave.xml resource file\n\nlink:https://github.com/jenkinsci/jenkins/pull/4330[PR-4330]\n\nThe resource file `jenkins-slave.xml` has been removed as it's been unused in Jenkins core since 2017.\nplugin:windows-slaves[WMI Windows Agents Plugin] needs to be updated to version 1.3.1 or newer (released in March 2017).\n"
  },
  {
    "question_id": "doc_18",
    "source_file": "benchmark_data/source_files/doc_18_2024-03-06.txt",
    "question": "I am currently using version 3.0.1 of the Delphix plugin and have configured it to disable SSL/TLS certificate validation for connections to the Data Control Tower. According to the advisory for SECURITY-3215, what change in the plugin's behavior should I expect after upgrading to version 3.0.2, and what specific step must I take to ensure my connections continue to work as they did before the upgrade?",
    "ground_truth_context": "    PLUGIN_NAME 2.133.vfb_8a_7b_9c5dd1 and earlier, except 2.84.86.vf9c960e9b_458, bundles versions of Jenkins/Trilead SSH2 that are susceptible to https://www.cve.org/CVERecord?id=CVE-2023-48795[CVE-2023-48795] (https://en.wikipedia.org/wiki/Terrapin_attack[Terrapin]).\n    This vulnerability allows a machine-in-the-middle attacker to reduce the security of an SSH connection.\n\n    PLUGIN_NAME 2.141.v284120fd0c46 updates the bundled Jenkins/Trilead SSH2 library to version `build-217-jenkins-274.276.v58da_75159cb_7`, which by default removes the affected ciphers and encryption modes.\n  plugins:\n  - name: trilead-api\n    previous: 2.133.vfb_8a_7b_9c5dd1\n    fixed: 2.141.v284120fd0c46\n- id: SECURITY-3301\n  reporter: Kevin Guerroudj, CloudBees, Inc.\n  title: Improper input sanitization in PLUGIN_NAME\n  cve: CVE-2024-28149\n  cvss:\n    severity: High\n    vector: CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:U/C:H/I:H/A:H\n  description: |-\n    link:/security/advisory/2018-04-16/#SECURITY-784[SECURITY-784 / CVE-20218-1000175] is a path traversal vulnerability in PLUGIN_NAME 1.15 and earlier.\n    The fix for it retained compatibility for older reports as a fallback.\n\n    In PLUGIN_NAME 1.16 through 1.32 (both inclusive) this fallback for reports created in PLUGIN_NAME 1.15 and earlier does not properly sanitize input.\n    This allows attackers with Item/Configure permission to do the following:\n\n    * Implement stored cross-site scripting (XSS) attacks.\n    * Determine whether a path on the Jenkins controller file system exists, without being able to access it.\n\n    PLUGIN_NAME 1.32.1 removes support for reports created before PLUGIN_NAME 1.15.\n    Those reports are retained on disk, but may no longer be accessible through the Jenkins UI.\n  plugins:\n  - name: htmlpublisher\n    previous: '1.32'\n    fixed: 1.32.1\n- id: SECURITY-3302\n  reporter: Kevin Guerroudj, CloudBees, Inc.\n  title: Stored XSS vulnerability in PLUGIN_NAME\n  cve: CVE-2024-28150\n  cvss:\n    severity: High\n    vector: CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:U/C:H/I:H/A:H\n  description: |-\n    PLUGIN_NAME 1.32 and earlier does not escape job names, report names, and index page titles shown as part of the report frame.\n\n    This results in a stored cross-site scripting (XSS) vulnerability exploitable by attackers with Item/Configure permission.\n\n    PLUGIN_NAME 1.32.1 escapes job names, report names, and index page titles when creating a new report.\n    PLUGIN_NAME 1.32.1 checks reports created in earlier releases for the presence of unsafe characters in the report frame, and refuses to show these frames if unsafe characters are identified.\n  plugins:\n  - name: htmlpublisher\n    previous: '1.32'\n    fixed: 1.32.1\n- id: SECURITY-3303\n  reporter: Kevin Guerroudj, CloudBees, Inc.\n  title: Path traversal vulnerability in PLUGIN_NAME\n  cve: CVE-2024-28151\n  cvss:\n    severity: Medium\n    vector: CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:N/A:N\n  description: |-\n    PLUGIN_NAME 1.32 and earlier archives invalid symbolic links in report directories on agents and recreates them on the controller.\n    Attackers with Item/Configure permission can use them to determine whether a path on the Jenkins controller file system exists, without being able to access it.\n\n    PLUGIN_NAME 1.32.1 does not archive symbolic links.\n  plugins:\n  - name: htmlpublisher\n    previous: '1.32'\n    fixed: 1.32.1\n- id: SECURITY-3300\n  reporter: Anders Hammar\n  title: Incorrect trust policy behavior for pull requests from forks in PLUGIN_NAME\n  cve: CVE-2024-28152\n  cvss:\n    severity: Medium\n    vector: CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:L/A:L\n  description: |-\n    Multibranch Pipelines with Bitbucket branch source can be configured to discover pull requests from forks.\n    The trust policy is set to \"Forks in the same account\" by default.\n\n    In PLUGIN_NAME 866.vdea_7dcd3008e and earlier, except 848.850.v6a_a_2a_234a_c81, this trust policy allows changes to Jenkinsfiles from users without write access to the project when using Bitbucket Server.\n    This allows attackers able to submit pull requests from forks to change the Pipeline behavior.\n\n    In PLUGIN_NAME 871.v28d74e8b_4226, the \"Forks in the same account\" trust policy does not extend trust to Jenkinsfiles modified by users without write access to the project.\n\n    NOTE: Pipelines using Bitbucket Cloud are unaffected by this issue.\n  plugins:\n  - name: cloudbees-bitbucket-branch-source\n    previous: 866.vdea_7dcd3008e\n    fixed: 871.v28d74e8b_4226\n- id: SECURITY-3344\n  reporter: tkmwrbl\n  title: Stored XSS vulnerability in PLUGIN_NAME\n  cve: CVE-2024-28153\n  cvss:\n    severity: High\n    vector: CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H\n  description: |-\n    PLUGIN_NAME 5.4.5 and earlier does not escape vulnerability metadata from Dependency-Check reports on the Jenkins UI.\n\n    This results in a stored cross-site scripting (XSS) vulnerability exploitable by attackers able to control workspace contents or CVE metadata.\n\n    PLUGIN_NAME 5.4.6 escapes vulnerability metadata from Dependency-Check reports.\n  plugins:\n  - name: dependency-check-jenkins-plugin\n    previous: 5.4.5\n    fixed: 5.4.6\n- id: SECURITY-3180\n  title: Sensitive information exposure in build logs by PLUGIN_NAME\n  cve: CVE-2024-28154\n  cvss:\n    severity: Medium\n    vector: CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:N/A:N\n  description: |-\n    PLUGIN_NAME has a global option to log the JSON payload it sends to RabbitMQ in the build log.\n    This includes the build parameters, some of which may be sensitive, and they are not masked.\n\n    In PLUGIN_NAME 1.4.0 and earlier, this option is enabled by default.\n    This results in unwanted exposure of sensitive information in build logs.\n\n    PLUGIN_NAME 1.4.1 disables the global option to log the JSON payload it sends to RabbitMQ by default.\n    This option is disabled when updating from a previous release and needs to be re-enabled by administrators who want to use this feature.\n  plugins:\n  - name: mq-notifier\n    previous: 1.4.0\n    fixed: 1.4.1\n- id: SECURITY-3144\n  reporter: Kevin Guerroudj, CloudBees, Inc.\n  title: Missing permission checks in PLUGIN_NAME\n  cve: CVE-2024-28155\n  cvss:\n    severity: Medium\n    vector: CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:N/A:N\n  description: |-\n    PLUGIN_NAME 1.0.16 and earlier does not perform permission checks in several HTTP endpoints.\n\n    This allows attackers with Overall/Read permission to obtain information about available scan config names, engine group names, and client names.\n\n    PLUGIN_NAME 1.0.17 requires Item/Configure permission for the affected HTTP endpoints.\n  plugins:\n  - name: jenkinsci-appspider-plugin\n    previous: 1.0.16\n    fixed: 1.0.17\n- id: SECURITY-3215\n  reporter: Daniel Beck, CloudBees, Inc.\n  title: SSL/TLS certificate validation disabled by default in PLUGIN_NAME\n  cve: CVE-2024-28161\n  cvss:\n    severity: Medium\n    vector: CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:L/I:L/A:N\n  description: |-\n    PLUGIN_NAME provides a global option for administrators to enable or disable SSL/TLS certificate validation for Data Control Tower (DCT) connections.\n\n    In PLUGIN_NAME 3.0.1 this option is set to disable SSL/TLS certificate validation by default.\n\n    In PLUGIN_NAME 3.0.2 this option is set to enable SSL/TLS certificate validation by default.\n\n    NOTE: PLUGIN_NAME 3.0.2 inverts the semantics of the existing option.\n    Administrators who update from version 3.0.1 to 3.0.2 will need to toggle this option to have the previously configured behavior.\n  plugins:\n  - name: delphix\n    title: Delphix\n    previous: 3.0.1\n    fixed: 3.0.2\n- id: SECURITY-3330\n  reporter: Yaroslav Afenkin, CloudBees, Inc.\n  title: Improper SSL/TLS certificate validation in PLUGIN_NAME\n  cve: CVE-2024-28162\n  cvss:\n    severity: Medium\n    vector: CVSS:3.1/AV:N/AC:H/PR:N/UI:R/S:U/C:L/I:L/A:N\n  description: |-\n    PLUGIN_NAME provides a global option for administrators to enable or disable SSL/TLS certificate validation for Data Control Tower (DCT) connections.\n\n    In PLUGIN_NAME 3.0.1 through 3.1.0 (both inclusive) an option change from disabled validation to enabled validation fails to take effect until Jenkins is restarted.\n\n    PLUGIN_NAME 3.1.1 applies the configuration change immediately when switching from disabled validation to enabled validation.\n  plugins:\n  - name: delphix\n    title: Delphix\n    previous: 3.1.0\n    fixed: 3.1.1\n- id: SECURITY-3200\n  reporter: Andrea Chiera, CloudBees, Inc.\n  title: CSRF vulnerability and missing permission check in PLUGIN_NAME\n  cve: CVE-2024-2215 (CSRF), CVE-2024-2216 (permission check)\n  cvss:\n    severity: Medium\n    vector: CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:L/A:L\n  description: |-\n    PLUGIN_NAME 2.11 and earlier does not perform a permission check in an HTTP endpoint implementing a connection test.\n\n    This allows attackers with Overall/Read permission to connect to an attacker-specified TCP or Unix socket URL.\n    Additionally, the plugin reconfigures itself using the provided connection test parameters, affecting future build step executions.\n\n    Additionally, this endpoint does not require POST requests, resulting in a cross-site request forgery (CSRF) vulnerability.\n\n    As of publication of this advisory, there is no fix.\n    link:/security/plugins/#unresolved[Learn why we announce this.]\n  plugins:\n  - name: docker-build-step\n    previous: '2.11'\n- id: SECURITY-3280\n  reporter: Daniel Beck, CloudBees, Inc.\n  title: Stored XSS vulnerability in PLUGIN_NAME\n  cve: CVE-2024-28156\n  cvss:\n    severity: High\n    vector: CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:U/C:H/I:H/A:H\n  description: |-\n    PLUGIN_NAME 1.14-860.vd06ef2568b_3f and earlier does not escape Build Monitor View names.\n\n    This results in a stored cross-site scripting (XSS) vulnerability exploitable by attackers able to configure Build Monitor Views.\n\n    As of publication of this advisory, there is no fix.\n    link:/security/plugins/#unresolved[Learn why we announce this.]\n  plugins:\n  - name: build-monitor-plugin\n    previous: 1.14-860.vd06ef2568b_3f\n- id: SECURITY-3249\n  reporter: Yaroslav Afenkin, CloudBees, Inc.\n  title: Stored XSS vulnerability in PLUGIN_NAME\n  cve: CVE-2024-28157\n  cvss:\n    severity: High\n    vector: CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:U/C:H/I:H/A:H\n  description: |-\n    PLUGIN_NAME 0.8 and earlier does not sanitize Gitbucket URLs on build views.\n\n    This results in a stored cross-site scripting (XSS) vulnerability exploitable by attackers able to configure jobs.\n\n    As of publication of this advisory, there is no fix.\n    link:/security/plugins/#unresolved[Learn why we announce this.]\n  plugins:\n  - name: gitbucket\n    previous: '0.8'\n- id: SECURITY-3325\n  reporter: Wadeck Follonier, CloudBees, Inc.\n  title: CSRF vulnerability and missing permission checks in PLUGIN_NAME\n  cve: CVE-2024-28158 (CSRF), CVE-2024-28159 (permission check)\n  cvss:\n    severity: Medium\n    vector: CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:L/A:N\n  description: |-\n    PLUGIN_NAME 1.0.1 and earlier does not perform a permission check in an HTTP endpoint.\n\n    This allows attackers with Item/Read permission to trigger a build.\n\n    Additionally, this endpoint does not require POST requests, resulting in a cross-site request forgery (CSRF) vulnerability.\n\n    As of publication of this advisory, there is no fix.\n    link:/security/plugins/#unresolved[Learn why we announce this.]\n  plugins:\n  - name: svn-partial-release-mgr\n    previous: 1.0.1\n- id: SECURITY-3248\n  reporter: Yaroslav Afenkin, CloudBees, Inc.\n  title: Stored XSS vulnerability in PLUGIN_NAME\n  cve: CVE-2024-28160\n  cvss:\n    severity: High\n    vector: CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:U/C:H/I:H/A:H\n  description: |-\n    PLUGIN_NAME 1.1.6 and earlier does not sanitize iceScrum project URLs on build views.\n\n    This results in a stored cross-site scripting (XSS) vulnerability exploitable by attackers able to configure jobs.\n\n    As of publication of this advisory, there is no fix.\n    link:/security/plugins/#unresolved[Learn why we announce this.]\n  plugins:\n  - name: icescrum\n    previous: 1.1.6\n"
  },
  {
    "question_id": "doc_19",
    "source_file": "benchmark_data/source_files/doc_19_jenkinsfile-runner-action-for-github-actions.txt",
    "question": "I'm setting up a workflow using `jenkinsci/jfr-container-action@master` and noticed the example requires a `container` block at the job level that specifies the `ghcr.io/jenkinsci/jenkinsfile-runner:master` image. Based on the document, what is the technical reason for this container declaration, and what is the primary advantage of using this action compared to the `jfr-static-image-action`?",
    "ground_truth_context": "\n=== Abstract\n\nJenkinsfile Runner Action for GitHub Actions provides the customized containerized environment and useful GitHub Actions for users to run the Jenkins pipeline inside GitHub Actions. \nIn more detail, if using these actions, any GitHub project which has a `Jenkinsfile` can execute its workflow in the GitHub Actions runner.\nIt aims at applying Jenkins in the GitHub Actions in a Function-as-a-Service context.\nThis feature is based on the Jenkinsfile Runner, which is a command line tool for the Jenkins pipeline execution engine.\nThe user can define the Jenkins pipeline environment by extending several Vanilla images and configuring the Jenkins Configuration-as-Code plugin.\nYou can check the link:https://jenkinsci.github.io/jfr-action-doc[central documentation page] for more details about these actions.\n\n=== Deliverables\n\nTo meet the potential needs of users and balance the design trade-off,\nthis project provides five actions.\nYou can use the following action URL in your workflow definitions.\n\n* `jenkinsci/jfr-setup-action@master`\n* `jenkinsci/jfr-plugin-installation-action@master`\n* `jenkinsci/jfr-runtime-action@master`\n* `jenkinsci/jfr-container-action@master`\n* `jenkinsci/jfr-static-image-action@master`\n\nIt also provides one central documentation page and one demo repository to help users understand the definitions and examples.\n\n* link:https://jenkinsci.github.io/jfr-action-doc[Central documentation page]\n* link:https://github.com/jenkinsci/jfr-action-demo[Demo repository]\n\nThere is a blog about the developing progress of these Jenkinsfile Runner Actions.\nIt's useful for users to get started easier and learn their underlying principles.\n\n* link:/blog/2022/09/07/jenkinsfile-runner-as-github-actions/[A near Feature-complete version of Jenkinsfile Runner Actions as GitHub Actions]\n\n=== Rationale\n\nThe Jenkins pipeline environment includes the Jenkins core war package, the Jenkinsfile Runner, and at a minimum a required set of plugins to run the pipeline.\nAll the dependencies are incorporated into the containers.\nAs the GitHub Actions support using the predefined containers and building custom images, the containers - which include the Jenkins runtime - are able to start inside the GitHub Actions.\n\n=== Implementation\n\nJenkinsfile Runner Action for GitHub Actions defines the dependencies in the prebuilt container or download at the runtime, \nand wraps the entrypoint in one GitHub Action so that the users can call the running environment and the related GitHub Action in their workflow definitions. \nThe decoupling of environment declaration and Jenkinsfile Runner Action enables the users to utilize other useful GitHub Actions. This project will provide several vanilla images including necessary dependencies to run the Jenkins pipeline.\nUsers can extend these images to set up their customized environment.\nWhat's more, the user can install the plugins, which is enabled by Plugin Installation Manager Tool, and then configure Jenkins, which is enabled by Configuration-as-Code plugin.\nWe'll also provide examples about how to store the pipeline artifacts,\nhow to use the Jenkins secrets and environmental variables, how to use the cache to accelerate the pipeline, etc.\nBy providing these examples and iterating the current actions,\nwe want the Jenkins pipeline to fit into the Cloud Native model gradually in the GitHub Actions context.\n\n=== Examples\n\nWe recommend using either of Jenkinsfile Runner Actions based on the container idea or actions based on the runtime downloading idea.\n\n* `jfr-container-action` - If the job in workflow uses this action, it can run the pipeline by specifying `Jenkinsfile` and integrate with other GitHub Actions such as `actions/setup-java`. \nAs it's based on the idea of link:https://docs.github.com/en/actions/using-jobs/running-jobs-in-a-container[Running jobs in a container],\nthe user needs to declare the image usage of `ghcr.io/jenkinsci/jenkinsfile-runner:master` at the start of the job.\nThe users can call this action by using `jenkinsci/jfr-container-action@master`. \nAn example about how to use this action can be found at link:https://github.com/Cr1t-GYM/jenkins-action-poc#container-job-action[in the POC project].\nIts function invocation in the workflow definition looks like the following:\n[source,yaml]\n----\nname: CI\non: [push]\njobs:\n  jfr-container-action-pipeline:\n    runs-on: ubuntu-latest\n    container:\n      image: ghcr.io/jenkinsci/jenkinsfile-runner:master\n    steps:\n      - uses: actions/checkout@v2\n      - name: Jenkins pipeline in the container\n        uses:\n          jenkinsci/jfr-container-action@master\n        with:\n          command: run\n          jenkinsfile: Jenkinsfile\n          pluginstxt: plugins.txt\n          jcasc: jcasc.yml \n----\n\n* `jfr-static-image-action` - This action can also run the pipeline.\nHowever, because of the late-start nature of the Jenkins container, this action is expected to experience strong isolation from the host machine.\nTherefore, the users cannot use other GitHub Actions except using `actions/checkout` to set up the workspace. The users can call this action by using `jenkinsci/jfr-static-image-action@master`.\nAn example about how to use this action can be found at link:https://github.com/Cr1t-GYM/jenkins-action-poc#docker-container-action[in the POC project].\nIts function invocation in the workflow definition looks like the following:\n[source,yaml]\n----\nname: CI\non: [push]\njobs:\n  jfr-static-image-action-pipeline:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Jenkins pipeline in the container\n        uses:\n          jenkinsci/jfr-static-image-action@master\n        with:\n          command: run\n          jenkinsfile: Jenkinsfile\n          pluginstxt: plugins.txt\n          jcasc: jcasc.yml \n----\n\n* `jfr-runtime-action` - This action will run the pipeline in the host machine directly.\nThe users need to use `jenkinsci/jfr-setup-action@master` to download and set up the necessary dependencies in advance.\nIf the users want to install extra plugins, they can use `jenkinsci/jfr-plugin-installation-action@master`.\nThe main advantage of `jfr-runtime-action` is that it can run in all kinds of runners provided by GitHub Actions.\nThe disadvantage is that it may suffer from the outage of downloading center.\nThe users can call this action by using `jenkinsci/jfr-runtime-action@master`.\nIts function invocation in the workflow definition looks like the following:\n[source,yaml]\n----\nname: CI\non: [push]\njobs:\n  jfr-runtime-action-pipeline:\n    strategy:\n      matrix:\n        os: [ ubuntu-latest, macOS-latest, windows-latest ]\n    runs-on: ${{matrix.os}}\n    name: jfr-runtime-action-pipeline\n    steps:\n      - uses: actions/checkout@v2\n      - name : Setup Jenkins\n        uses:\n          jenkinsci/jfr-runtime-action@master\n      - name: Jenkins plugins download\n        uses:\n          jenkinsci/jfr-plugin-installation-action@master\n        with:\n          pluginstxt: plugins.txt\n      - name: Run Jenkins pipeline\n        uses:\n          jenkinsci/jfr-runtime-action@master\n        with:\n          command: run\n          jenkinsfile: Jenkinsfile\n----\n\n=== Chat\n\nWe use the `#gsoc-jenkinsfile-runner` channel in the CDF Slack workspace.\n\nlink:/chat/#continuous-delivery-foundation[Explanations about the CDF Slack] (the invitation link is at the end of the paragraph).\n\n=== Office hours\n\n* (General) Official weekly Jenkins office hours: Thursdays 3pm to 3:30pm UTC\n* (Project-based) link:https://us05web.zoom.us/j/81912236313?pwd=WGtHTHZnSHFhS3dYTmVHUXdrK05Sdz09[Weekly project-specific office hours]: Mondays 12pm to 12:30pm UTC\n\n=== Project Links\n\nHere come some useful links:\n\n* link:https://jenkinsci.github.io/jfr-action-doc[Central documentation page]\n* link:https://github.com/jenkinsci/jfr-setup-action[jfr-setup-action repository]\n* link:https://github.com/jenkinsci/jfr-plugin-installation-action[jfr-plugin-installation-action repository]\n* link:https://github.com/jenkinsci/jfr-runtime-action[jfr-runtime-action repository]\n* link:https://github.com/jenkinsci/jfr-container-action[jfr-container-action repository]\n* link:https://github.com/jenkinsci/jfr-static-image-action[jfr-static-image-action repository]\n* link:https://github.com/jenkinsci/jfr-action-demo[Demo repository]\n* link:https://docs.google.com/presentation/d/1t2vuNn1NFpDusnw0m4vdFw6WBQMeU6kccv_K1v2L6R0/edit#slide=id.g13dcaed2105_0_8/[Midterm Presentation Slides]\n* link:https://github.com/jenkinsci/jenkinsfile-runner/[Jenkinsfile runner]\n* link:https://github.com/jenkinsci/configuration-as-code-plugin/[Configuration as code plugin]\n* link:https://docs.github.com/en/actions/creating-actions/creating-a-docker-container-action#introduction/[GitHub Docker container action]\n"
  },
  {
    "question_id": "doc_20",
    "source_file": "benchmark_data/source_files/doc_20_about_chirag.txt",
    "question": "Based on the project plan for the domain-specific Jenkins LLM, what specific types of XML metadata files from ci.jenkins.io are being analyzed in addition to build logs, and who is the contributor working on this project for Google Summer of Code 2025?",
    "ground_truth_context": "Hello, Jenkins Community!\nI\u2019m Chirag Gupta, and I\u2019m incredibly excited to announce that I\u2019ve been selected for the Google Summer of Code 2025 program to work with the Jenkins project! It\u2019s an honor to contribute to such a cornerstone of the open-source CI/CD landscape.\nMy project, \"Domain-specific LLM based on actual Jenkins usage using ci.jenkins.io data,\" aims to create a specialized Large Language Model (LLM) to assist Jenkins users in diagnosing build failures more effectively. The core idea is to leverage the wealth of real-world data from ci.jenkins.io to fine-tune an LLM, making it adept at understanding Jenkins-specific issues. You can check out my project for more details.\nDiving In: The Community Bonding Period\n\nThe past few weeks of the community bonding period have been an invaluable learning experience, focused on laying a solid foundation for the coding phases ahead:\nDeep Dive into ci.jenkins.io Data: The dataset is the lifeblood of the project. I\u2019ve been exploring its structure, which includes a vast array of build logs, XML metadata (build.xml, changelog.xml, config.xml), and other artifacts. Understanding the sheer scale (approx. 400,000 files!) and the diversity within this data is crucial. My initial analysis, as outlined in my proposal, has focused on identifying key characteristics, potential challenges (like log noise and token inflation), and patterns that will inform our data preprocessing and fine-tuning strategies.\nUnderstanding the Jenkins Ecosystem: Beyond the data, I\u2019ve been deepening my understanding of Jenkins CI/CD principles, common failure scenarios, and existing tools like the Build Failure Analyzer and Log Parser. This broader context is essential for building a truly useful LLM.\nCollaboration with Mentors: I\u2019ve had insightful discussions with my mentors, Kris Stern, Shivay Lamba, Bruno Verachten, Harsh Pratap Singh, and Vutukuri Sreenivas. Their expertise and guidance have been instrumental in refining the project\u2019s technical roadmap, from model selection (exploring options like Phi-4 and Qwen) to planning our evaluation strategies.\nThe bonding period has truly highlighted the importance of high-quality, structured data for effective LLM training. The ci.jenkins.io dataset, with its real-world complexities, offers both a significant challenge and a fantastic opportunity.\nWhat Lies Ahead?\n\nAs we transition into the coding period, the immediate focus will be on:\nImplementing robust log cleaning and preprocessing pipelines.\nSystematically parsing metadata to create a comprehensive index of builds and their outcomes.\nBeginning the critical task of structuring the data into a format suitable for fine-tuning our chosen LLM, including generating QA pairs.\nPreparing for and executing the initial fine-tuning runs.\nI\u2019m incredibly excited to move forward and start bringing this project to life. I believe that an LLM tailored for Jenkins can significantly enhance the user experience by providing more intuitive and actionable insights into build issues, and also reduce the time taken by people to parse their build failures.\nA heartfelt thank you to my mentors and the entire Jenkins community for this amazing opportunity and for the warm welcome. I\u2019m eager to learn, contribute, and share my progress with all of you.\nLet\u2019s build a smarter Jenkins together!\n\n\nChirag Gupta\nChirag is a final-year student at BITS Pilani \u2013 Goa Campus, pursuing a dual major in Mathematics and Electronics & Instrumentation. He views AI and NLP not just as fields of study, but as his personal kitchen for innovation. He treats data like ingredients and algorithms like recipes, constantly experimenting to create impactful solutions.\nThis passion led him to be selected as a Google Summer of Code (GSoC) 2025 contributor for Jenkins, where he is working on the Domain-specific LLM based on actual Jenkins usage using ci.jenkins.io data project.\nBeyond his technical pursuits, you can find Chirag either in an actual kitchen experimenting with new culinary dishes, or in his digital one, perfecting the recipe for a smarter AI."
  }
]